{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"virtual thread 탄생 배경 전통적인 java thread는 작업 task에 따라 리소스를 할당하여 사용할 수 있도록 제공되어, 긴 세월 java application의 핵심 요소 자리잡고 있다. 이는 운영 체제의 thread에 직접 매핑된며, 새 thread를 생성하려면 JNI를 통한 system call 과정이 필요하여, 시스템에 따라 제한된…","fields":{"slug":"/java-virtual-thread/"},"frontmatter":{"date":"April 28, 2024","title":"java virtual thread 구조, 이해, 비교","tags":["java","virtual thread"],"series":"java"},"rawMarkdownBody":"## virtual thread 탄생 배경\n전통적인 java thread는 작업 task에 따라 리소스를 할당하여 사용할 수 있도록 제공되어, 긴 세월 java application의 핵심 요소 자리잡고 있다. 이는 운영 체제의 thread에 직접 매핑된며, 새 thread를 생성하려면 JNI를 통한 system call 과정이 필요하여, 시스템에 따라 제한된 수의 thread만 지원할 수 있다. 결과적으로 개발자는 동시성을 관리하기 위해 여러 프레임워크나 라이브러리, webflux와 같은 시스템에 의존해야 했다. 이를 해결 하기 위해 JDK19부터 Project Loom 이라는 주제로 java의 경량 thread 모델에 대한 개발이 진행 되었으며, JDK21에 virtual thread가 정식 릴리즈 되었다.\n\n## 기존 thread\n![](java-virtual-thead-01.png)\njava의 thread는 native thread 모델로, 유저 thread를 만들게되면 Java Native Interface(JNI)를 통해 thread를 할당 받고 이를 JVM의 platform thread에 매핑한다. 이때 thread를 할당 받기 위해서는 OS로 부터 system call 과정이 필요하고, 이는 많은 비용을 발생 시킨다. 그리고 thread의 I/O, sleep, interrupt 등의 상황은 thread를 blocking/wait 시키게 되며, 그 사이에 다른 thread가 커널 thread를 점유하여 작업을 수행하게 된다. 이 과정을 `context switching`라고 한다. \n\n\n기존 thread 모델은 프로세스를 만들어 사용하는것에 비해 저렴한 비용과 context swiching 비용으로 요청량이 많은 서비스에 다양하게 활용되고 있다. 하지만 매우 트래픽이 많은 대규모의 서비스는 thread의 요청에 한계가 있고, 서버 증설 등 물리적 자원에 의존하고 있다. 서버 메모리가 4GB이면 1MB thread 요청도 한번에 최대 4천개를 처리하는게 한계이기 때문이다. 물론 실제로는 다른 자원의 요청을 생각하면 이보다 더 낮게 처리해할 것이다. 따라서 요청 처리량, context switching등에 사용되는 비용을 줄일 필요성이 지속적으로 제기되었고, 이를 위해 도입된 기술이 virtual thread이다.\n\n## virtual thread\n![](java-virtual-thead-02.png)\n\nvirtual thread에서는 forkjoin poll에 의해서 기존 platform thread들이 carrier thread로 관리된다. 마치 JVM이 직접 관리하는 thread poll이라고 생각해도 된다. JVM heap내에서 직접 thread의 추가/삭제 등 관리에 대한 자원을 관리하며, N개의 virtual thread 매핑되어 context swiching 비용이 매우 저렴하다. \n\n|비교|Thread|Virtual Thread|\n|------|---|---|\n|memory 사용|미리 할당된 stack|필요 할 때 heap|\n|stack 크기|~2MB|~10KB|\n|생성 시간|~1ms|~1µs|\n|context swiching 비용|~100µs|~10µs, ns|\n\n기존 java의 thread는 기본적으로 최대 2MB의 스택 메모리 사이즈를 가지기 때문에, context swiching 시 메모리 이동량이 크다. 그리고 thread의 생성을 위해 OS커널과 통신하여 스케줄링해야 하므로, system call을 이용한 생성 비용도 적지 않다. 하지만 virtual thread는 carrier thread 생성을 제외하면 JVM에 의해 생성되기 때문에 thread의 생성 시간이나 context swiching 비용이 매우 적다.\n\n### 동작원리\n```java\nVirtualThread(Executor scheduler, String name, int characteristics, Runnable task) {\n    super(name, characteristics, /*bound*/ false);\n    Objects.requireNonNull(task);\n\n    // choose scheduler if not specified\n    if (scheduler == null) {\n        Thread parent = Thread.currentThread();\n        if (parent instanceof VirtualThread vparent) {\n            scheduler = vparent.scheduler;\n        } else {\n            scheduler = DEFAULT_SCHEDULER;\n        }\n    }\n\n    this.scheduler = scheduler;\n    this.cont = new VThreadContinuation(this, task);\n    this.runContinuation = this::runContinuation;\n}\n```\n```java\nprivate static ForkJoinPool createDefaultScheduler() {\n    ForkJoinWorkerThreadFactory factory = pool -> {\n        PrivilegedAction<ForkJoinWorkerThread> pa = () -> new CarrierThread(pool);\n        return AccessController.doPrivileged(pa);\n    };\n    ...\n}\n```\n\nvirtual thread를 생성할 때 특정 스케줄러에 대한 정보를 따로 주지 않으면 DEFAULT_SCHEDULER에 의해서 스케줄 되며, 이때 만들어지는 스케줄러는 carrier thread를 forkjoin poll로 관리하도록 만들어진다.\n\n![](java-virtual-thead-04.png)\n\n이때 각각의 carrier thread에는 work queue가 있으며, 각각의 queue에 있는 runContinuation들은 forkjoin poll에 의해 work stealing 방식으로 동작한다. 즉, runContinuation들의 동작에 sleep, interrupt 등의 작업이 있으면 park(), unpark() 과정의 반복으로 작업 된다. 이는 실제 thread가 멈추는게 아닌, 각 virtual thread가 yeild 된다. 따라서 더 이상의 blocking 연산은 실행중인 thread를 차단하지 않으며, 더 많고 작은 virtual thread의 요청으로 carrier thread에 의해 병렬적으로 처리 될 수 있다.\n\n```java\npublic static void park(Object blocker) {\n    Thread t = Thread.currentThread();\n    setBlocker(t, blocker);\n    try {\n        if (t.isVirtual()) {\n            VirtualThreads.park();\n        } else {\n            U.park(false, 0L);\n        }\n    } finally {\n        setBlocker(t, null);\n    }\n}\n```\n```java\npublic static void unpark(Thread thread) {\n    if (thread != null) {\n        if (thread.isVirtual()) {\n            VirtualThreads.unpark(thread);\n        } else {\n            U.unpark(thread);\n        }\n    }\n}\n```\npark(), unpark() 메소드를 보면 JDK21부터 isVirtual() 분기를 통해 제공된다. 기존의 U.park(), U.unpark()가 LockSupport.java에서 native method로 system call에 의해 제공 사항은 제거함으로써 빠르게 context swiching이 가능하게 되었다.\n\n![](java-virtual-thead-03.png)\n그래서 thread에 blocking 연산이 들어와도 각 virtual thread의 작업 스케줄링이 forkjoin poll 내 carrier thread에서 관리되기 때문에 적은 context swiching 시간을 통한 높은 처리량을 가질 수 있다.\n\n## 성능 테스트\n### 환경\n* OS: macOS Ventura 13.6.3\n* CPU: M2\n* Memory: 32GB\n* Version: JDK21 / Springboot 3.2.x\n\n좋은 컴퓨터만 가진 클라우드 흙수저라, 로컬에서 진행했다.\n\n### springboot\n```yml\nspring:\n  threads:\n    virtual:\n      enabled: true\n```\nspringboot 3.2.x 이상 버전에서 virtual thread를 적용하는 방법은 진짜 심플하다. 개발팀에서 호환성에 신경써놓은 덕분에 정말 편하게 적용한다. property file에 thread enable을 true 하면 thread가 virtual로 동작한다. 이하 버전에서는 @Bean으로 등록해서 사용해야한다.\n\n```kotlin\n@RestController\nclass CodeController {\n    @GetMapping(\"/io-bound\")\n    fun ioBound() {\n        Thread.sleep(500) // db hard select\n        Thread.sleep(100) // get hard api call\n        Thread.sleep(300) // post hard api call\n    }\n\n    @GetMapping(\"/cpu-bound\")\n    fun cpuBound(): Long {\n        return (0 .. 100_000_000).sum().toLong()\n    }\n}\n```\n간단하게 I/O, CPU bound 테스트를 진행해볼 예정이다. I/O 테스트는 post API를 진행할 때 DB, API call 등의 무거운 작업들로 I/O 시간이 꽤 걸리는 API라고 가정한다. 그리고 CPU 테스트는 단순 계산을 반복 수행하도록 했다. 이는 실제 상황에서는 결과가 절대적으로 다를 것이니, 테스트로만 봐주면 좋을것 같다. 모든 테스트는 reqeust user thread를 점진적으로 올리면서 테스트 했으며, ramp-up 시간은 3s로 고정했다.\n\n|I/O bound Test  | User  | Throughput | Time |\n|----------------|------|------------|------|\n| Thread         | 300  | 77/s         | 3s    |\n| Thread         | 1500  | 200/s        | 7s    |\n| Thread         | 3000 | 118.3/s      | 25s   |\n| Virtual Thread | 300  | 77/s         | 3s    |\n| Virtual Thread | 1500  | 384.3/s      | 3s    |\n| Virtual Thread | 3000 | 728/s        | 3s    |\n| Virtual Thread | 6000 | 865.8/s      | 6s    |\n\n\n|CPU bound Test  | User  | Throughput | Time |\n|----------------|------|------------|------|\n| Thread         | 30  |7.1/s          |4s     |\n| Thread         | 150  |7.8/s         |19s     |\n| Thread         | 600 |7.6/s       |79s    |\n| Virtual Thread | 30  | 7.2/s         | 4s    |\n| Virtual Thread | 150  | 8.2/s      | 18s    |\n| Virtual Thread | 600 | 7.5/s        | 78s    |\n\n\n* I/O bound \n    * thread와 virtual thread 둘다 tomcat thread poll이 처리 가능한 범위 내에선 같은 성능을 보인다.\n    * thread는 spring boot 기본 tomcat thread poll size(200)에 의해 최대 처리량 이상의 요청이 오자 급격하게 처리량이 떨어짐과 동시에 처리 속도가 떨어졌다.\n    * virtual thread는 경우 3000 user(1000tps)를 가볍게 수행했으며, 이후 추가로 6000 user 테스트 진행 후, 처리량이 늘긴 했으나 이전 테스트와 비교하여 비례적으로 처리량이 올라가진 않았고 처리시간도 조금 밀렸다. 아마 처리량은 수행하는 로직이나 환경에따라 다를 것이다.\n* CPU bound\n    * CPU Bound 작업에서는 일반 thread랑 거의 차이가 없거나, 오히려 일반 thread가 성능상 우위를 보이기도한다.\n    * 경량 스레드가 결국 platform 스레드 위에서 동작하기 때문에, thread 생성 비용에 virtual thread 생성 및 스케줄링 비용까지 포함되어 성능 낭비가 발생한다.\n    * I/O Bound 작업과 같이 context switching이 빈번하지 않는 경우에는 크게 이점이 없다.\n\n### vs kotlin coroutines\n```kotlin\n@RestController\nclass CodeController {\n    @GetMapping(\"/io-bound\")\n    fun ioBound() {\n        Thread.sleep(500) // db select\n        Thread.sleep(100) // get api call\n        Thread.sleep(300) // post api call\n    }\n\n    @GetMapping(\"/io-bound-coroutine\")\n    suspend fun ioBoundCoroutine() {\n        CoroutineScope(Dispatchers.IO).async {\n            delay(500) // db select\n            delay(100) // get api call\n            delay(300) // post api call\n        }.await()\n    }\n}\n```\n\n|I/O bound Test  | User  | Throughput(/s) | Time(s) |\n|----------------|------|------------|------|\n| Virtual Thread | 300  | 77         | 3    |\n| Virtual Thread | 1500  | 384.3      | 3    |\n| Virtual Thread | 3000 | 728        | 3    |\n| Virtual Thread | 6000 | 865.8      | 6    |\n| Coroutines     | 300  | 76.9       | 3    |\n| Coroutines     | 1500  | 384.3      | 3    |\n| Coroutines     | 3000 | 768.2      | 3   |\n| Coroutines     | 6000 | 869.2      | 7   |\n\nkotlin coroutine과 비교하여 비슷한 동작으로 테스트를 진행했다. I/O 테스트만 진행했고, 결과는 비슷했다. 아주 미세한 차이로 coroutine의 처리량이 좋아보이는것 같다. 사실 둘 다 Continuation을 구현한 구현체라 거의 비슷한 성능을 보이는것 같다. kotlin에서는 yeild 대신 suspend 라는 중단 지점을 컴파일 시점에서 알 수 있으니, 좀 더 최적화 되어 있지 않을까 생각이 든다.\n\n기존 java 사용자라면 대량 트래픽의 gateway 로써 또는 I/O 작업에 대해 vitual thread를 도입하는게 성능 개선에 큰 영향을 줄 수 있을것 같다. 그리고 가장 큰 장점은 기존 java thread 로직과 일부만 수정하면 거의 대부분 호환 가능하여, 빠르게 고가용성의 서버로 전환할 수 있을것 같다. 그리고 kotlin 유저는 여전히 coroutine을 사용해도 좋을 것 같다. 성능 성능도 좋을 뿐더러, 자식/부모 scope와 같이 구조화된 coroutine을 사용할 수도 있고, 특정 scope 실행을 취소 시켜버리거나 에러를 핸들링하기 쉽다는 장점도 존재하기 때문이다.\n\n## virtual thread 사용 주의 사항\n* CPU bound를 위해서 사용하면 안된다. I/O 작업 없이 CPU 작업만 수행하는 경우 기존 platform thread 보다 성능이 떨어진다.\n* Thread Local을 사용을 피해야한다. 이는 여러 thread가 있을때 각 thread만을 위한 저장 공간이라 생각하면 되며, virtual thread가 무수히 많이 엄청 작은 단위로 생성되기 때문에 자칫하면 메모리 누수, 에러를 야기할 수 있다.\n* Pinned issue가 발생될 요소를 피해야한다. virtual thread 내에서 synchronized, parallelStream, 혹은 native method를 사용하면 virtual thread가 carrier thread에 고정되는 문제가 있다. 이런 경우, virtual thread의 장점인 non-blocking의 경량 thread 방식으로 동작하지 않는다. synchronized 대신 ReentrantLock을 사용하는 것이 좋다.\n\n## 결론\nvirtual thread는 기존 java thread에 매우 높은 호환성을 갖고 높은 처리량을 가진 구조라 생각한다. kotlin의 coroutine도 안정화 기간이 있었던 만큼, virtual thread도 더욱 안정화되어 실무에서 곧 만날 날이 멀지 않을것 같다.\n\n##\n***\n###\n* https://techblog.woowahan.com/15398/\n* https://nangmandeveloper.tistory.com/6\n* https://perfectacle.github.io/2022/12/29/look-over-java-virtual-threads/"},{"excerpt":"docker 설치 생략 Dockerfile 작성 적용할 application에 Dockerfile 생성 최신 aws cli 설치 cicd를 구축해놓으면 필요 없지만, cli로 aws에 접속하여 ECR에 이미지를 push 해보려면 필요하다. https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/getting-st…","fields":{"slug":"/aws-ecs/"},"frontmatter":{"date":"April 05, 2024","title":"AWS ECS with git action 간단 체크포인트","tags":["aws","ecs","ecr"],"series":"aws"},"rawMarkdownBody":"\n## docker 설치\n생략\n\n## Dockerfile 작성\n적용할 application에 Dockerfile 생성\n\n## 최신 aws cli 설치\ncicd를 구축해놓으면 필요 없지만, cli로 aws에 접속하여 ECR에 이미지를 push 해보려면 필요하다.\n* https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/getting-started-install.html\n\n## VPC, subnet 생성\n기본 베이스로 private subnet 2개, public subnet 2개로 세팅 하면 된다.\n\n## ECR 생성\n![](aws-ecs-01.png)\n\n## ECR push\nDockerfile이 있는 경로로 이동하여 ECR에 이미지를 build 및 push 진행하면 된다.\n\n만약 push할 때 권한 에러가 발생하면 access key를 발급하여, ~/.aws/config에 profile을 등록하여 ECR에 로그인할 때 profile 옵션을 주고 로그인하여, push를 진행하면 된다.\n```sh\nvi ~/.aws/config\n```\n```sh\n[profile wookey]\nregion = ap-northeast-2\naws_access_key_id = [public key]\naws_secret_access_key = [private key]\n```\n\n\n이후 순서대로 진행하여 aws ECR에 docker 이미지를 올린다. 미리 생성해둔 ECR 레포지토리를 선택하면 `푸시 명령보기`가 활성되고, 아래 내용은 해당 모달창에 있는 사항을 그대로 옮긴것이다.\n* login\n```sh\naws ecr get-login-password --profile [본인이 설정한 profile 명] --region ap-northeast-2 | docker login --username AWS --password-stdin [aws 유저 아이디].dkr.ecr.ap-northeast-2.amazonaws.com\n```\n\n* build image\n```sh\ndocker build --platform=\"linux/amd64\" -t [docker image 이름] .\n```\n\n* tag\n```sh\ndocker tag [docker image 이름:tag] [aws 유저 아이디].dkr.ecr.ap-northeast-2.amazonaws.com/[docker image 이름:tag]\n```\n\n* push\n```sh\ndocker push [aws 유저 아이디].dkr.ecr.ap-northeast-2.amazonaws.com/[docker image 이름:tag]\n```\n\n## ECS 클러스터 생성\nfargate로 클러스터를 생성해준다. 간단하게 진행하는거면 ec2보다 간단하고 비용적으로도 합리적일 수 있다.\n\n## ECS 태스크 정의\nECR이미지 정보 입력 및 애플리케이션 컨테이너에 사용될 포트(8080)를 매핑한다.\n\n만약 환경변수가 필요하다면 직접 값으로 넣어줘도 되고, ValueForm으로 S3, SSM 등 적절한 도구를 선택해서 arn url 형태로 넣어도 된다.\n\ncpu 및 메모리는 0.5 vCPU, 1 GB로 간단하게 구성했다.\n\n## ECS 서비스 생성\n태스크의 서비스를 생성한다. 이 또한 fargate로 생성했다.\n\n네트워크 정보는 public으로 등록하며, 선택적으로 로드밸런서 및 auto 오토스케일링 등록을 할 수 있다.\n\n만약 로드밸런스를 연결한다면 보안 그룹에 80 포트를 열어두도록 한다.\n\n서비스 생성 및 컨테이너가 정상 기동되면 아래와 같이 정상적으로 태스크가 실행중인 모습이 나온다.\n\n![](aws-ecs-02.png)\n\n## CICD with git action\n먼저 AWS연결을 위한 access key를 등록한다.\n\n![](aws-ecs-03.png)\n\n이후 action을 등록할 git repository에서 Action 탭 이동 후 워크플로우를 등록한다. \n\nECS를 검색하면 deploy를 위한 서비스를 지원하며, Configure을 누르면 yml 파일을 하나 커밋하여 레포에 등록하도록 한다.\n\n아래는 간단하게 등록한 파일이니, env 정보만 변경해서 사용하면 된다.\n\n참고로 `ECS_TASK_DEFINITION` 값은 ECS task의 json파일을 다운받고, 이를 애플리케이션의 root(Dockerfile과 동일)에 두면 된다.\n\n```sh\nname: Deploy to Amazon ECS\n\non:\n  push:\n    branches: [ \"master\" ]\n\nenv:\n  AWS_REGION: ap-northeast-2\n  ECR_REPOSITORY: [레포지토리 명]\n  ECS_SERVICE: [ecs 서비스 명]\n  ECS_CLUSTER: [ecs 클러스터 명]\n  ECS_TASK_DEFINITION: [task json file 이름(확장자 포함)]\n  CONTAINER_NAME: [ecs task 컨테이너 명]\n\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Set up JDK 17\n        uses: actions/setup-java@v3\n        with:\n          java-version: '17'\n          distribution: 'adopt'\n\n      - name: Grant execute permission for gradlew\n        run: chmod +x gradlew\n\n      - name: build with gradle\n        run: ./gradlew clean build -x test\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Login to Amazon ECR\n        id: login-ecr\n        uses: aws-actions/amazon-ecr-login@v1\n\n      - name: Build, tag, and push image to Amazon ECR\n        id: build-image\n        env:\n          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}\n          IMAGE_TAG: ${{ github.sha }}\n        run: |\n          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .\n          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\n          echo \"image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\" >> $GITHUB_OUTPUT\n\n      - name: Fill in the new image ID in the Amazon ECS task definition\n        id: task-def\n        uses: aws-actions/amazon-ecs-render-task-definition@v1\n        with:\n          task-definition: ${{ env.ECS_TASK_DEFINITION }}\n          container-name: ${{ env.CONTAINER_NAME }}\n          image: ${{ steps.build-image.outputs.image }}\n\n      - name: Deploy Amazon ECS task definition\n        uses: aws-actions/amazon-ecs-deploy-task-definition@v1\n        with:\n          task-definition: ${{ steps.task-def.outputs.task-definition }}\n          service: ${{ env.ECS_SERVICE }}\n          cluster: ${{ env.ECS_CLUSTER }}\n          wait-for-service-stability: true\n```\n\n정상적으로 ECS에 CI/CD가 적용된 모습이다.\n\n![](aws-ecs-04.png)\n\n###\n***\n####\n* <https://ksh-coding.tistory.com/134##2-2.%20Task%20%26%20Task%20Definition-1>\n* <https://kobumddaring.tistory.com/76>\n* <https://velog.io/@ekxk1234/ECS-%EC%B2%B4%ED%97%98%EA%B8%B0>\n"},{"excerpt":"AWS EC2에 Jenkins를 설치 및 어플리케이션 서버를 위한 추가적인 ec2 서버를 구성하면 좋지만, jenkins를 설치하기에는 프리티어 메모리 문제도 있으며, 추가적인 ec2 인스턴스를 기동시 비용 문제가 발생될 수 있다. 그래서 jenkins는 로컬에서 설치하며 어플리케이션 서버는 ec2로 구성하여 AWS 프리티어에서 가능한 수준의 간단한 CI…","fields":{"slug":"/jenkins-cicd/"},"frontmatter":{"date":"March 24, 2024","title":"간단한 jenkins docker CI/CD 구성","tags":["jenkins","cicd"],"series":"cs"},"rawMarkdownBody":"\n\nAWS EC2에 Jenkins를 설치 및 어플리케이션 서버를 위한 추가적인 ec2 서버를 구성하면 좋지만, jenkins를 설치하기에는 프리티어 메모리 문제도 있으며, 추가적인 ec2 인스턴스를 기동시 비용 문제가 발생될 수 있다. 그래서 jenkins는 로컬에서 설치하며 어플리케이션 서버는 ec2로 구성하여 AWS 프리티어에서 가능한 수준의 간단한 CI/CD 구축을 해본다.\n\n## local docker 설치\n도커 설치법은 생략한다. 도커 데스크탑까지 설치하면 좋다.\n\n## docker jenkins pull\n```sh\ndocker pull jenkins/jenkins:lts\n```\n\n## docker jenkins run\n```sh\ndocker volume create volume-jenkins\n```\n```sh\ndocker network create cicd-net\n```\n\n```sh\ndocker run -d -it \\\n--name jenkins \\\n--net cicd-net \\\n-p 8080:8080 -p 50000:50000 \\\n-v volume-jenkins:/var/jenkins_home \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\njenkins/jenkins:lts\n```\n\ndocker 컨테이너 종료 및 삭제 이후에도 설정을 유지하려면 volume 설정을 해주면 좋다. 그리고 docker 엔진은 host OS의 /var/run/docker.sock 아래에 마운트 된 unix 소켓을 사용한다.\ndocker.sock은 도커 컨테이너 내부에서 데몬과 상호 작용을 할 수 있게 해주는 unix 소캣이다.\n\n만약 권한 문제가 발생한다면 아래와 같이 권한을 주면 된다.\n```sh\nsudo chmod 666 /var/run/docker.sock\n```\n\n## jenkins 접속 및 설치\n\n![](jenkins-cicd-01.png)\n\n`http://localhost:8080/`에 접속하면 설치를 위한 초기 패스워드를 입력이 필요하다.\n\n\n```sh\ndocker exec -i -t --user root jenkins /bin/bash\n```\n\ndocker 컨테이너에 root 권한으로 접속한다.\n\n```sh\ncat /var/jenkins_home/secrets/initialAdminPassword\n```\n\n초기 패스워드 정보는 위 경로에서 확인할 수 있으며, 해당 값을 입력 후 설치를 진행한다.\n\n![](jenkins-cicd-02.png)\n\nInstall suggested plugins 를 클릭하여 기본 플러그인을 설치하면 위 처럼 설치가 진행된다.\n이후, 계정 및 간단한 이름을 등록하면 젠킨스를 시작할 수 있다.\n\n## jenkins 설정\n### jenkins private key 등록\njenkins에 ssh 접속을 위한 과정이다. jenkins 내에서 자격 등록을 위해 private key를 등록하고, public key를 git에 등록할 예정이다.\n\n```sh\ndocker exec -i -t --user root jenkins /bin/bash\n```\n\n이미 접속해있다면 상관없고, jenkins 컨테이너에 접속 한다.\n\n```sh\nssh-keygen\n```\n\nssh key를 생성한다. 명령어 입력 후 엔터 계속 클릭하면 생성이 된다.\n\n```sh\ncd /root/.ssh/\ncat id_rsa\ncat id_rsa.pub\n```\n\n위 경로에 private key `id_rsa` 및 public key `id_rsa.pub` 가 각각 잘 생성되었는지 확인한다.\n\n![](jenkins-cicd-06.png)\n\n```\nSetting > Developer settings > Personal access tokens > tokens(classic) > Generate new token(classic)\n```\n\n위 경로에서 ssh private 자격을 등록한다. `SSH Username with private key` 타입으로 등록하며, ID는 아무거나 작성해도 좋다. 나는 ssh로 작성했다. 그리고 private key를 작성할때는 `id_rsa` 파일의 전체 정보를 넣으면 된다. 반드시 `-----BEGIN OPENSSH PRIVATE KEY-----` 문구 부터 `-----END OPENSSH PRIVATE KEY-----` 까지 끝까지 다 넣어주도록 한다.\n\n#### github jenkins public key 등록\n방금 등록한 private ssh와 대응되도록 git에는 public ssh를 등록한다.\n```\ngithub > 등록할 레포지토리 > Settings > Deploy keys > Add deploy key\n```\n\n이름은 편하게 짓고, jenkins 컨테이너의 `id_rsa.pub` 파일 내용을 그대로 넣어주면 정상적으로 등록된다.\n\n### github developer token 발급\ngithub에서 아래 경로로 이동 후 토큰을 발급한다. 이제는 jenkins에서 git에 연결하고 개발 관련 컨트롤을 하기 위함이다.\n\n```\n전체 메뉴의 Setting > Developer settings > Personal access tokens > tokens(classic) > Generate new token(classic)\n```\n\n![](jenkins-cicd-03.png)\n\n토큰의 권한은 레포를 관리할 수 있는 최소한만 줘도 된다. 토큰 이름은 jenkins로 지었으며, 토큰 만료기간은 따로 설정하지 않았다.\n\n![](jenkins-cicd-04.png)\n\n\n신규 발급된 토큰의 private key는 잘 저장해두고 복사한다.\n\n#### jenkins git-hub credentials 등록\n마찬가지로 jenkins에서도 해당 토큰을 연결해야한다. 서로 상호 연결한다고 생각하면 된다.\n\n```\nJenkins 대시보드 > Jenkins 관리 > Security > Credentials > global > Add Credentials\n```\n\n![](jenkins-cicd-05.png)\n\n`Username with password`로 설정 후 본인의 git 아이디를 username에, 패스워드는 로그인할때 패스워드가 아닌, 방금 위에서 발급받은 token을 넣는다! git auth 정책이 바뀌어 일반 비밀번호를 넣으면 auth 에러가 발생하니, 반드시 유의할것!!!\n\n### jenkins docker-hub credentials 등록\n도커 이미지를 push 하기 위해서는 jenkins에 도커 자격 증명이 필요하다. github 계정 등록과 같은 방법으로 docker hub 계정을 등록하면 된다.\n\n```\nJenkins 대시보드 > Jenkins 관리 > Security > Credentials > global > Add Credentials\n```\n\n`Username with password`로 설정 후 본인의 docker 아이디를 username에, 패스워드를 입력 후 ID에는 아무값이나 구분자로 넣어준다.\n\n#### ec2 jenkins public key 등록\napplication 서버로 사용할 ubuntu ec2에도 public key가 있다. 해당 부분은 아래 ec2 생성 후 다시 보는걸 추천한다. 이후 ec2에 접속 후 `authorized_keys` 를 ssh 경로에 만들어, jenkins의 public key를 등록한다. jenkins 컨테이너 내에서 만든 `id_rsa.pub` 파일을 그대로 넣으면 된다.\n\njenkins 컨테이너의 public key 내용 복사\n```sh\ncat /root/.ssh/id_rsa.pub\n```\n\nec2 서버에 authorize_keys 파일에 내용 붙여넣기\n```sh\nvi ~/.ssh/authorized_keys\n```\n\n### ssh agent 플러그인 설치\n![](jenkins-cicd-07.png)\n![](jenkins-cicd-09.png)\n\njenkins에서 직접 붙여쓰는 자격 증명과 별개로 ec2에 직접 ssh로 연결하기 위한 `SSH Agent` 플러그인, docker 파이프라인을 위한 `Docker Pipeline`을 available plugins에서 설치한다.\nDocker Pipeline은 미리 설치해놔서 검색 사진이 없다ㅎ\n\n### jenkins docker in docker 설치\njenkins 내에서 docker image build를 통해 docker hub에 push 하는 작업을 위해 docker 설치가 필요하다.\n\n```sh\ndocker exec -i -t --user root jenkins /bin/bash\n```\n터미널에서 jenkins 컨테이너 접속 후 아래 명렁어에 따라 docker를 설치를 한다. docker 컨테이너 내에서 docker를 설치해야하는 아이러니한 상황이긴하다. 이를 docker in docker라고 한다.\n\n```sh\napt-get update -y\n```\n```sh\napt-get install -y\\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n```\n```sh\nmkdir -p /etc/apt/keyrings\n```\n```sh\ncurl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n```\n```sh\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n```sh\napt-get update -y\n```\n```sh\napt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y\n```\n\n```sh\ndocker --version\n```\n\ndocker 설치가 완료 되었으면 버전이 뜰 것이다. 확인해보면 된다. 여기까지 진행했으면, jenkins에서 설정해야하는 사항은 끝이다. \n\n## app server ec2\n\n### ec2 생성\nspringboot application server를 띄울 ec2 하나를 띄운다. 나는 ubuntu os로 만들었으며, 어떠한 것으로 하든 상관 없다. 그 외 EC2 생성 방법은 생략하며, 키페어를 저장하고 위치만 잘 확인해두도록 한다.\n\n![](jenkins-cicd-08.png)\n\n다만 보안그룹 설정 시, 인바운드 설정이 필요하다. nginx를 통해 들어올 TCP 80포트 및 application server의 blue green 배포를 통해 들어올 8080, 8081 포트는 열어둬야 한다. 또한 ec2에 ssh 연결을 해야하므로 ssh 연결을 위한 22번 포트도 반드시 열어둬야한다. https 443 포트는 선택이다.\n\n### ec2 docker 설치\nec2에는 docker-compose 명령어를 통해 blue green 배포를 한다. 따라서 docker 및 docker-compose 설치가 필요하다. 설치 내용은 생략한다.\n\n### deploy.sh\njenkins에서 ssh 연결 후 실행시킬 deploy 쉘 스크립트가 필요하다. 이때 nginx가 설치(생략)되어 있어야하며 blue가 켜져있으면 green을, green이 켜져있으면 blue를 배포하는 간단한 스크립트이다. ec2의 root 경로에 작성했다.\n\n{컨테이너명} 부분은 필히 본인이 사용할 이름으로 변경해야한다! ex) {컨테이너명} -> test-container\n\n```sh\n## 1\nEXIST_BLUE=$(docker-compose -p {컨테이너명}-blue -f docker-compose.blue.yaml ps | grep Up)\n\nif [ -z \"$EXIST_BLUE\" ]; then\n    docker-compose -p {컨테이너명}-blue -f ~/docker-compose.blue.yaml up -d\n    BEFORE_COMPOSE_COLOR=\"green\"\n    AFTER_COMPOSE_COLOR=\"blue\"\n    BEFORE_PORT_NUMBER=8081\n    AFTER_PORT_NUMBER=8080\nelse\n    docker-compose -p {컨테이너명}-green -f ~/docker-compose.green.yaml up -d\n    BEFORE_COMPOSE_COLOR=\"blue\"\n    AFTER_COMPOSE_COLOR=\"green\"\n    BEFORE_PORT_NUMBER=8080\n    AFTER_PORT_NUMBER=8081\nfi\n\necho \"${AFTER_COMPOSE_COLOR} server up(port:${AFTER_PORT_NUMBER})\"\n\n## 2\nfor cnt in {1..10}\ndo\n    echo \"서버 응답 확인중..(${cnt}/10)\";\n    UP=$(curl -s http://localhost:${AFTER_PORT_NUMBER}/actuator/health | grep 'UP')\n    if [ -z \"${UP}\" ] \n        then\n\t    sleep 10\n\t    continue       \n        else\n            break\n    fi\ndone\n\nif [ $cnt -eq 10 ]\nthen\n    echo \"서버가 정상적으로 구동되지 않았습니다.\"\n    exit 1\nfi\n\n## 3\nsudo sed -i \"s/${BEFORE_PORT_NUMBER}/${AFTER_PORT_NUMBER}/\" /etc/nginx/conf.d/service-url.inc\nsudo nginx -s reload\necho \"Deploy Completed!!\"\n\n## 4\necho \"$BEFORE_COMPOSE_COLOR server down(port:${BEFORE_PORT_NUMBER})\"\ndocker-compose -p {컨테이너명}-${BEFORE_COMPOSE_COLOR} -f docker-compose.${BEFORE_COMPOSE_COLOR}.yaml down\n```\n\n#### docker-compose\n위 쉴에서 구동할 blue, green docker-compose 파일이 필요하다. docker-compose.blue.yaml, docker-compose.green.yaml 각각의 compose 파일을 작성했다. deploy.sh 파일과 같은 ec2 root 경로에 작성했다.\n\n```sh\nversion: '3.1'\n \nservices: \n  api:\n    image: {dockerID}/{컨테이너명}\n    container_name: {컨테이너명}-blue\n    environment:\n      - LANG=ko_KR.UTF-8\n      - UWSGI_PORT=8080\n    ports:\n      - '8080:8080'\n```\n\n```sh\nversion: '3.1'\n \nservices: \n  api:\n    image: {dockerID}/{컨테이너명}\n    container_name: {컨테이너명}-green\n    environment:\n      - LANG=ko_KR.UTF-8\n      - UWSGI_PORT=8081\n    ports:\n      - '8081:8080'\n```\n\n## jenkins pipeline\n```sh\npipeline {\n    agent any\n\n    environment {\n        gitCredential = 'git'\n        dockerCredential = 'docker-hub'\n        sshCredential = 'ssh'\n    }\n\n    stages {\n        stage('Prepare') {\n            steps {\n                echo 'Clonning Repository'\n                git branch: 'master', \n                url: '{연결할 git 레포지토리 http url}',\n                credentialsId: gitCredential\n            }\n            \n            post {\n                success { \n                    echo 'Successfully Cloned Repository'\n                }\n                failure {\n                    error 'This pipeline stops here...'\n                    \n                }\n            }\n        }\n\n        stage('Bulid Gradle') {\n          steps {\n            echo 'Bulid Gradle'\n            dir('.'){\n                sh './gradlew clean build'           \n\t\t\t}\n          }\n          post {\n          \tsuccess { \n              echo 'Successfully Project Build'\n            }\n            failure {\n              error 'This pipeline stops here...'\n            }\n          }\n        }\n        \n        stage('Bulid Docker') {\n          steps {\n            echo 'Bulid Docker'\n            script {\n                dockerImage = docker.build(\"{도커아이디}/{컨테이너명}\", \"--platform linux/x86_64 .\")\n            }\n          }\n          post {\n\t        success { \n              echo 'Successfully Docker Build'\n            }\n            failure {\n              error 'This pipeline stops here...'\n            }\n          }\n        }\n\n        stage('Push Docker') {\n          steps {\n            echo 'Push Docker'\n            script {\n                docker.withRegistry('', dockerCredential) {\n                    dockerImage.push() \n                }\n            }\n          }\n          post {\n          \tsuccess { \n              echo 'Successfully Docker push'\n            }\n            failure {\n              error 'This pipeline stops here...'\n            }\n          }\n        }\n        \n\t\tstage('Docker Run') {\n            steps {\n                echo 'Pull Docker Image & Docker Image Run'\n                sshagent (credentials: [sshCredential]) {\n                    sh \"ssh -o StrictHostKeyChecking=no ubuntu@{ec2 IP주소} './deploy.sh'\"\n                }\n            }\n        }\n    }\n}\n```\n\n위 스크립트에 `{XXX}` 해놓은 부분은 본인이 사용하고자 하는 명명에 맞게 변경해서 사용해야한다. 그대로 사용하면 절대안된다ㅎ \n참고로 jenkins 컨테이너 내에 pull 받은 git repo는 /var/jenkins_home/workspace 경로에 있다.\n\n![](jenkins-cicd-10.png)\n\n중간중간 에러 있어서 9트에 완료.."},{"excerpt":"spring에서는 Bean을 IoC(Inversion of Control) 컨테이너에 의해 관리된다. spring에서 객체는 IoC 컨테이너로부터 의존성을 주입 받을 수 있으며, 다양한 방법으로 의존성을 주입받을 수 있다. 그 중 @Autowired에 대해 알아본다. IoC 컨테이너 Ioc는 spring에만 있는 개념은 아니며, 의존 관계를 역전하여 의존…","fields":{"slug":"/spring-autowired/"},"frontmatter":{"date":"November 04, 2023","title":"spring @Autowired 간단 정리","tags":["spring","autowired"],"series":"spring"},"rawMarkdownBody":"\nspring에서는 Bean을 IoC(Inversion of Control) 컨테이너에 의해 관리된다. spring에서 객체는 IoC 컨테이너로부터 의존성을 주입 받을 수 있으며, 다양한 방법으로 의존성을 주입받을 수 있다. 그 중 @Autowired에 대해 알아본다.\n\n## IoC 컨테이너\nIoc는 spring에만 있는 개념은 아니며, 의존 관계를 역전하여 의존성을 주입하는 방식을 뜻한다. 이때 spring에서 IoC를 제공하는 객체가 Ioc 컨테이너이다.\n\n### DI\nIoC 컨테이너는 bean의 생명주기를 관리하며, 객체의 생명주기 및 의존성을 관리한다. 의존성은 말 그대로 특정 객체에서 다른 객체 정보를 필요로 하여 서로 의존 관계에 있는 것들 뜻한다. 이를 spring에서는 IoC 컨테이너에 의해 DI(Dependency Injection) 의존성 주입을 받게 된다. spring에서는 그저 DI를 원하는 객체에 `@Autowired`와 같은 표기를 통해서 Ioc 컨테이너에게 의존성 주입 대상임을 알려주기만 하면 된다.\n```java\npublic class StudentService {\n    @Autowired\n    private StudentRepository studentRepository\n    ...\n\n    public void register() {\n        ...\n    }\n}\n```\n\n## Autowired\n@Autowired는 spring에서 가장 일반적으로 사용되는 어노테이션으로, 의존성 주입을 위해 사용된다. @Autowired는 타입(Type)을 기반으로 자동으로 의존성을 주입한다. spring은 클래스의 생성자, 필드, 메서드 등에서 @Autowired이 적용된 대상을 찾고, 해당하는 의존성을 자동으로 주입한다.\n\n### Injections\n@Autowired로 의존성을 주입 받는 방법은 생성자, setter, 필드 주입 방식이 있다.\n\n`Constructor Injection`\n```java\npublic  class  ExampleCase {\n    private final ChocolateService chocolateService;\n    private final DrinkService drinkService;\n    \n    @Autowired\n    public ExampleCase(ChocolateService  chocolateService, DrinkService  drinkService) {\n   \t    this.chocolateService = chocolateService;\n   \t    this.drinkService = drinkService;\n    }\n}\n```\n\n`Setter Injection`\n```java\npublic  class  ExampleCase{\n    private ChocolateService chocolateService;\n    private DrinkService drinkService;\n\n    @Autowired\n    public void setChocolateService(ChocolateService chocolateService){\n        this.chocolateService = chocolateService;\n    }\n\n    @Autowired\n    public void setDrinkService(DrinkService  drinkService){\n        this.drinkService = drinkService;\n    }\n}\n```\n\n`Field Injection`\n```java\npublic  class  ExampleCase{\n    @Autowired\n    private ChocolateService  chocolateService;\n\n    @Autowired\n    private DrinkService  drinkService;\n}\n```\n\n일반적으로 `Constructor Injection`의 생성자 주입 방식을 선택한다. 이유는 아래와 같다.\n\n1. SRP(single responsibility principle)\n필드 주입 방식은 의존성 주입 방식이 매우 간단하다는 장점이 있다. 이는 양날의 검으로 너무 쉽게 의존성을 주입하다보니, 막무가내로 하나의 객체에 책임을 부여하도록 개발할 수 있는 것이다. 즉, 객체지향 원칙중 단일 책임의 원칙에 어긋나게 개발할 위험에 노출시킬 수 있다. 생성자에 의존관계를 기입하면 한눈에 파악하기 좋을 뿐더러, 너무 많아진 파라미터는 심리상 뭔가 잘못됨(?)을 느낄 수 있게 해준다.\n\n2. DI 컨테이너의 결합성과 테스트 용이성\nField Injection을 사용하면 필요한 의존성을 가진 클래스를 곧바로 인스턴스화 시킬 수 없다. 이유는 final 선언시 필드값을 초기화 해야하기 때문이다. 객체는 생성과 동시에 생성에 필요한 파라미터와 함께 초기화 하여 메모리에 올라가게 되는데, 필드를 초기화 할 수 없는 객체가 되어 단위테스트와 같은 mocking 객체를 만들 수 없다. 또한 final 키워드가 붙지 않기 때문에 객체 생성 이후 불변성을 보장할 수 없게된다.\n\n3. 순환 의존성\nConstructor Injection에서 순환 의존성(A객체 <-> B객체 서로간에 참조)을 가질 경우 순환참조 관련된 오류가 발생되어, 순환 의존성을 알 수 있다. 하지만 Field Injection의 경우 해당 객체가 생성되는 시점에 알 수 있기 때문에 런타임간에 오류가 발생될 수 있다.\n\n### Inject, Resource, Quirifire, Primay\n@Autowired는 타입(Type)을 기반으로 자동으로 의존성을 주입한다. Spring은 클래스의 생성자, 필드, 메서드 등에서 @Autowired 적용된 대상을 찾고, 해당하는 의존성을 자동으로 주입한다. 그 외 @Inject, @Resource, @Quirifire, @Primay 방법도 간단하게 알아보자.\n\n* `Inject`<br>\n@Inject는 JSR-330(Java Dependency Injection specification)에 정의된 어노테이션이다. 즉, spring이 아닌 java 스펙에서 제공하는 DI 어노테이션인 것이다. @Autowired와 기능적으로 동일하다. Spring에서도 @Inject을 지원하며, @Autowired와 동일하게 타입(Type)을 기반으로 자동 의존성 주입을 수행한다.\n\n* `Resource`<br>\n@Resource은 @Inject와 마찬가지로 java 스펙에서 제공하는 JSR-250(Java Common Annotations specification)에 정의된 어노테이션으로, 이름(Name)을 기반으로 의존성 주입을 수행한다. @Resource은 주입할 빈을 지정할 때 이름을 사용하며, 기본적으로 필드 이름과 동일한 이름의 빈을 찾아서 주입한다. 또한 name 속성을 사용하여 다른 이름의 빈을 명시적으로 지정할 수도 있다.\n\n* `@Qualifier`<br>\n@Qualifier은 같은 타입(Type)의 여러 빈 중에서 특정 빈을 선택할 때 사용한다. spring에서 같은 타입의 여러 빈을 찾았을 때, 어떤 빈을 주입해야 할지 명확하게 판단할 수 없는 경우 @Qualifier을 함께 사용하면 된다. @Qualifier은 주입할 빈을 식별하는 데 사용되는 추가적인 정보를 제공한다. 예를 들어, @Qualifier(\"myBean\")과 같이 사용하여 myBean이라는 특정 빈을 주입할 수 있다.\n\n* `@Primary`<br>\n@Primary은 같은 타입(Type)의 여러 빈 중에서 기본 빈(Default Bean)을 지정할 때 사용한다. Spring은 @Primary이 적용된 빈을 우선적으로 선택하여 주입하며, 여러 개의 빈이 있을 때 기본 빈을 명시적으로 지정하고자 할 때 사용한다.\n\n\n## 결론\n실무에서 개발을 하더라도 bean의 타입과 이름을 겹칠 정도의 개발을 할 일은 거의 없다고 봐도 무관하다. 새로운 공통 컴포넌트나 프레임워크를 만들지 않는 이상 말이다.\n> Spring에서 앵간하면 이상한 주입 방식 쓰지말고, 장점 많은 Constructor(생성자) Injection 방식의 @Autowired로 의존성을 주입받자.\n\n\n##\n***\n###\n* https://velog.io/@aidenshin/%ED%95%84%EB%93%9C%EC%A3%BC%EC%9E%85-%EC%83%9D%EC%84%B1%EC%9E%90-%EC%A3%BC%EC%9E%85%EB%B0%A9%EC%8B%9D%EC%9C%BC%EB%A1%9C-%EB%B3%80%EA%B2%BD"},{"excerpt":"소프트웨어 시스템 소프트웨어(soft ware)는 부드러운(soft)와 제품(ware)의 합성어이다. 즉 소프트웨어를 만드는 이유는 기계의 행위를 쉽게 변경할 수 있도록 하기 위해서다. 그게 아니라면 하드웨어라 불렀을 것이다. 소프트웨어는 반드시 부드러워야 하며, 이는 곧 변경하기 쉬어야 한다는 것을 뜻한다. 새로운 기능이나 변경이 쉬운 소프트웨어를 개발…","fields":{"slug":"/clean-architecture/"},"frontmatter":{"date":"October 16, 2023","title":"clean architecture 클린 아키텍처 리뷰","tags":["clean architecture"],"series":"book"},"rawMarkdownBody":"\n![](clean-architecture-01.png)\n\n## 소프트웨어 시스템\n소프트웨어(soft ware)는 부드러운(soft)와 제품(ware)의 합성어이다. 즉 소프트웨어를 만드는 이유는 기계의 행위를 쉽게 변경할 수 있도록 하기 위해서다. 그게 아니라면 하드웨어라 불렀을 것이다. 소프트웨어는 반드시 부드러워야 하며, 이는 곧 변경하기 쉬어야 한다는 것을 뜻한다. 새로운 기능이나 변경이 쉬운 소프트웨어를 개발하기 위해 시스템 아키텍처는 독립적이어야 한다.\n\n## 구조, 객체, 함수형 프로그래밍\n* 구조적 프로그래밍은 제어흐름의 직접적인 전환에 부과되는 규율\n* 객체 지향 프로그래밍은 제어흐름의 간접적인 전환에 부과되는 규율\n* 함수형 프로그래밍은 변수 할당에 부과되는 규율\n\n각 패러다임은 우리가 코드를 작성하는 방식의 형태를 한정 시킬뿐 변한게 없다. 또한 1946년 엘런 튜링이 최초의 코드를 작성할 때 사용한 소프트웨어 규칙과 지금의 규칙은 조금도 다르지 않다.\n즉 도구와 하드웨어는 변했지만 소프트웨어는 그대로이다. 그대로 소프트웨어는 순차(sequence), 분기(selection), 반복(iteration), 참조(indirection)으로 구성될 뿐 그 이상 그 이하도 아니다.\n\n## SOLID\n* SRP는 하나의 일만 해야한다는 의미로 잘못 알고 있는 경우가 많다. 단일 모듈은 변경의 이유가 오직 하나 뿐이어야 한다는 뜻이다. 즉, 단일 모듈은 오직 하나의 사용자 또는 이해관계자에 대해서만 책임져야 한다.\n* OCP의 목표는 시스템을 확장하기 쉬운 동시에 변경으로 인해 시스템이 너무 많은 영향을 받지 않도록 하는데 있다. 이러한 목표를 달성하려면 시스템 컴포넌트 단위를 분리하고, 저수준 컴포넌트에서 발생한 변경으로부터 고수준 컴포넌트를 보호할 수 있는 형태의 의존성 계층구조가 만들어지도록 해야한다.\n* LSP는 아키텍처 수준까지 확장할 수 있고, 반드시 확장해야한다. 치환 가능성을 조금이라도 위배하면 시스템 아키텍처가 오염되어 상당량의 별도 메커니즘을 추가해야 할 수 있기 때문이다.\n* ISP는 불필요한 인터페이스 상속 관계에 의해 잠재되는 문제 상황들이 생길 수 있다. 불필요한 짐을 실은 무언가에 의존하면 예상치 못한 문제에 빠질 수 있다는 것이다.\n* DIP는에서 말하는 '유연성이 극대화된 시스템'이란 소스 코드 의존성이 추상(abstract)에 의해 의존하며 구체에는 의존하지 않는 시스템이다. 이를 위해서는 안정된 추상화를 지향해야하며, 변동성이 큰 구체 클래스를 참조, 파생하지 말아야 한다.\n\n## 아키텍처\n### 경계선 긋기\n소프트웨어 아키텍처에서 경계선을 그리려면 먼저 시스템을 컴포넌트 단위로 분할해야 한다. 일부 컴포넌트는 핵심 업무 규칙에 해당하며, 나머지는 플러인으로 핵심 업무와는 직접적인 관련이 없지만 필수 기능을 포함한다. 그런 다음 컴포넌트 사이의 화살표가 특정 방향, 즉 핵심 업무를 향하도록 이들 컴포넌트의 소스를 배치한다. 이는 의존성 역전 원칙과 안정된 추상화 원칙을 응용한 것이다. 의존성 화살표는 저수준 세부사항에서 고수준의 추상화를 향하도록 배치된다.\n\n### 소리치는 아키텍처\n좋은 아키텍처는 유스케이스를 그 중심에 두기 때문에 프레임워크나 도구, 환경에 전혀 구애받지 않고 유스케이스를 지원하는 구조를 아무런 문제 없이 기술할 수 있다. 좋은 아키텍처는 유스케이스에 중점을 두며, 관심사에 대한 결합은 분리시킨다. 아키텍처는 시스템을 이야기해야하며, 시스템에 적용한 프레임워크에 대해 이야기해서는 안된다. 당신이 헬스 케어 시스템을 구축하고 있다면 새로 들어온 개발자는 소스를 보고 \"오 헬스 케어 시스템이군!\" 해야만 한다.\n\n## 클린 아키텍처\n![clean-architecture](clean-architecture-02.png)\n\n클린 아키텍처에서 소스코드의 의존성은 반드시 안쪽으로, 고수준의 정책을 향해야한다. 우리는 외부 원에 위치한 어떤 것도 내부의 원에 영향을 주지 않도록 설계해야 한다.\n### 엔티티\n엔티티는 전사적인 핵임 업무 규칙을 캡슐화하며, 외부의 무언가가 변경되더라도 엔티티가 변경될 가능성은 지극히 낮아야 한다. 즉, 가장 고수준인 규칙을 캡슐화 하는 것이다. 운영 관점에서 특정 애플리케이션이 무언가 변경이 필요하더라도 엔티티 계층에는 절대로 영향을 주어서는 안된다.\n\n### 유스케이스\n유스케이스 계층의 소프트웨어는 애플리케이션에 특화된 업무 규칙을 포함한다. 또한 유스케이스 계층의 소프트웨어는 시스템의 모든 유스케이스를 캡슐화하고 구현한다. 유스케이스는 엔티티로 들어오고 나가는 데이터 흐름을 조정하며, 엔티티가 자신의 핵심 업무 규칙을 사용해서 유스케이스의 목적을 달성하도록 이끈다. 하지만 이 계층에서 발생한 변경이 엔티티에 절대 영향을 줘서는 안된다. 운영 관점의 변경은 유스케이스가 영향 받으며, 이 계층의 소프트웨어에도 경향을 줄 것이다.\n\n### 인터페이스 어댑터\n인터페이스 어댑터 계층은 일련의 어댑터들로 구성된다. 어댑터는 데이터를 유스케이스와 엔티티에게 가장 편리한 형식에서 데이터베이스나 웹 같은 외부 에이전시에게 가장 편리한 형식으로 변환한다. 또한 이 계층에는 데이터를 외부 서비스와 같은 외부적인 형식에서 유스케이스나 엔티티에서 사용되는 내부적인 형식으로 변환하는 또 다른 어댑터가 필요할 수 있다.\n\n## 한줄 리뷰\n> 유연하고 변경에 강한 소프트웨어를 개발하기 위해, 클린 아키텍처는 고수준의 도메인 중심에서 경계를 명확히 할 수 있는 방법을 가이드 한다.\n\n"},{"excerpt":"AOP AOP(Aspect Oriented Programming)는 컴퓨터 패러다임의 일종으로, 관점 지향 프로그래밍이라 불린다. 이러한 AOP의 메커니즘은 프로그램을 관심사(Concerns) 기준으로 크게 핵심 관심사와 횡단 관심사로 분류한다.  핵심 관심사는 해당 프로그램의 핵심적인 기능, 즉 비즈니스 로직을 뜻한다. 그에 빈해 횡단 관심사는 보안, …","fields":{"slug":"/srping-aop/"},"frontmatter":{"date":"October 07, 2023","title":"spring AOP의 proxy","tags":["spring","aop","proxy"],"series":"spring"},"rawMarkdownBody":"## AOP\nAOP(Aspect Oriented Programming)는 컴퓨터 패러다임의 일종으로, 관점 지향 프로그래밍이라 불린다. 이러한 AOP의 메커니즘은 프로그램을 관심사(Concerns) 기준으로 크게 핵심 관심사와 횡단 관심사로 분류한다.\n\n![](spring-aop-01.png)\n\n핵심 관심사는 해당 프로그램의 핵심적인 기능, 즉 비즈니스 로직을 뜻한다. 그에 빈해 횡단 관심사는 보안, 프로파일링, 로그, 트랜잭션은 비즈니스 기능은 아니지만, 요구 상황에 따라서 다수의 비즈니스 기능에 포함되며, 비즈니스 로직과는 다른 관심의 영역을 뜻한다. 여담으로 핵심 관심사를 모듈화 한것을 OOP, 부가적인 횡단 관심사를 모듈화 한것들 AOP라고 표현할 수 있을것 같다.\n\n### 관련 용어\n* Target: 어떤 대상에 부가 기능을 부여할 것인지\n* Advice: 어떤 부가 기능을 부여할 것인지\n* Join Point: 어디에 적용할 것인지\n* Point Cut: 실제 Advice가 적용될 시점을 의미. Spring AOP에서는 advice가 적용될 메서드를 선정.\n\n### @Transactional\n트랜잭션 처리를 위해 아래와같은 트랜잭션 처리 동작 코드를 작성할 수 있다. \n\n```java\npublic class TransactionProxy {\n    private final TransactonManager manager = TransactionManager.getInstance();\n    ...\n\n    public void transaction() {\n        try {\n            manager.begin();\n\n            target.logic(); // 비즈니스 로직(target)\n\n            manager.commit();\n        } catch (Exception e) {\n            manager.rollback();\n        }\n    }\n}\n```\n\n하지만 모든 트랜잭션 처리 코드에 이와 같은 로직을 작성하게 되면, 비즈니스 로직에 집중이 되지 않고 중복적인 코드를 발생시키게 된다. 그래서 spring에서는 트랜잭션 처리 로직을 횡단으로 적용할 수 있도록 `@Transactional` AOP Proxy를 지원한다.\n\n## AOP Proxy\nspring AOP에는 JDK Proxy, CGLib Proxy의 두가지 방법이 있다. 두 방식의 가장 핵심적인 차이는 인터페이스의 유무이다.\n\n![](spring-aop-02.png)\n\n### JDK Proxy\nJDK Proxy의 경우 AOP를 적용하여 구현된 클래스의 인터페이스를 프록시 객체로 구현해서 코드를 끼워넣는 방식이다.\n* Relfection API을 사용해 느리다.\n* 인터페이스가 반드시 필요하다.\n\n### CGLIB\nCGLib은 Code Generator Library의 약자로, 클래스의 바이트코드를 조작하여 Proxy 객체를 생성해주는 라이브러리이다. springboot2 부터는 외부 라이브러리가 아닌, core 모듈에 기본 탑제 되어있다.\n\n* 바이트 코드를 조작해서 빠르다.\n* 클래스만 있어도 작동한다.\n* 상속을 이용해서 프록시를 생성하기 때문에, 당연하게도 메서드에 final, private를 붙이면 안된다.\n\n## 결론\nspring AOP는 사용자의 특정 호출 시점에 IoC 컨테이너에 의해 AOP를 할 수 있는 Proxy Bean을 생성해준다. 이는 동적으로 생성된 Proxy Bean의 타겟 메소드가 호출되는 시점에 부가적인 기능을 추가할 메소드를 주입해준다. \n> AOP Proxy의 런타임 위빙(Weaving)을 통해 개발자는 불필요한 횡단 로직을 간결화 하고 AOP Proxy에 의해 비즈니스 모듈에 집중하는 코드를 개발할 수 있다."},{"excerpt":"proxy  프록시(proxy)는 , 의 의미를 가지고 있다. 일상에 비유해보자. 전세집 부동산 계약을 하기위해 부동산 공인중개사를 필요로 하는 상황을 가정해보자. 이는 집주인과 나 사이에 부동산 공인중개사가  역할로 부동산 거래를 도맡는 것이다.\n나는 집주인과 직접 연락하지 않고 전세집 거래를 진행할 수 있으며, 더욱 안전하게 업무를 진행할 수 있다. …","fields":{"slug":"/proxy/"},"frontmatter":{"date":"September 23, 2023","title":"간단 nginx proxy 정리","tags":["proxy"],"series":"cs"},"rawMarkdownBody":"\n## proxy\n![](proxy-01.png)\n\n프록시(proxy)는 `대리`, `대신`의 의미를 가지고 있다. 일상에 비유해보자. 전세집 부동산 계약을 하기위해 부동산 공인중개사를 필요로 하는 상황을 가정해보자. 이는 집주인과 나 사이에 부동산 공인중개사가 `프록시` 역할로 부동산 거래를 도맡는 것이다.\n나는 집주인과 직접 연락하지 않고 전세집 거래를 진행할 수 있으며, 더욱 안전하게 업무를 진행할 수 있다. 또한 집주인에게 궁금한 정보가 있을때 공인중개사가 해당 내용을 안다면, 집주인까지 연락을 가지않고도 빠르게 정보를 얻을 수도 있다. 이 처럼 프록시는 중간자의 역할로 여러가지 기능을 수행할 수 있다. 프록시의 개념이 사용되는곳 마다 조금씩 다를 수 있지만, 중간에서 대리자 역할을 수행하는 것은 동일하다. 이번에는 웹서버의 프록시에 대해 함께 알아보자.\n\n### proxy server\n프록시 서버(proxy server)는 브라우저 또는 모바일 기기인 클라이언트와 인터넷과 사이에 둘 수도 있는 `foward proxy`, 인터넷과 웹서버 사이에 둘 수 있는 `reverse proxy`가 있다. 그림과 함께 특징 및 장점에 대해서 알아보자.\n\n### foward proxy\n![](proxy-04.png)\n\n포워드 프록시(foward proxy)는 클라이언트의 요청을 앞에서 대신받아 서버로 요청하는 형태로 동작한다. 이로써 각 클라이언트의 요청은 서버로부터 받게되면 이후 같은 요청에 대해서는 프록시 서버가 기억하고 이를 서버에 닿지 않고 결과를 반환해줄 수 있다. 이는 곧 `캐시`의 역할을 할 수 있는 것이다. 또한 클라이언트는 자신의 IP정보나 OS정보등 http 통신간에 서버로 전달되는 정보를 숨기고싶을 수 있다. 이때 프록시 서버가 클라이언트의 요청을 가로채어 정보를 변환시켜 서버에 요청할 수 있다. 이로써 클라이언트의 정보는 `익명성`의 효과를 얻을 수 있는 것이다.\n\n### reverse proxy\n![](proxy-03.png)\n\n리버스 프록시(reverse proxy)는 서버로 요청온 정보를 대신 받아 각 서버들에게 전달하는 형태로 동작한다. 동일한 요청에 대해 서버의 부하를 거치지 않고 응답할 수 있는 `캐시`의 역할은 동일하다. 그리고 클라이언트는 각 서버에 요청을 할 때 리버스 프록시에서 지정한 IP주소 및 port로 요청을 하기 때문에 실제 서버의 IP주소 및 기타 정보들이 노출되지 않을 수 있다. 이는 곧 `보안`의 효과를 얻을 수 있는 것이다. 또한 리버스 프록시가 요청의 대리자 역할을 수행함으로써 여유있는 서버에서 정보를 얻어오도록 설계할 수 있다. 이는 곧 `로드밸런서`의 역할을 리버스 프록시에게 위임할 수 있는 것이다. 각 서버 단위에서 L4(OS layer4) 로드밸런싱, `/product`, `/coupon`등 어플리케이션 게이트웨이 역할로 L7(OS layer7) 로드밸런싱을 수행할 수 있는 것이다.\n\n## 결론\n그 외에도 spring AOP, 프록시 디자인패턴 등 중계자의 역할로 여러 기술이나 개념적으로도 많이 사용된다. 관심 있는 주제들을 찾아서 함께 공부해보면 좋을것 같다.\n> 그래서 프록시라는 단어는 말 그대로 대리자, 중계자의 역할이다. 부동산 공인중개사의 역할을 생각하면 어렵지 않게 이해할 수 있다.\n\n##\n***\n###\n* <https://blog.hidemyass.com/en/what-is-a-web-proxy>\n* <https://research.aimultiple.com/forward-vs-reverse-proxy/>"},{"excerpt":"대용량 트래픽 처리 은 말 그대로 단위 시간의 수 많은 요청을 뜻한다. 구글이나 페이스북과 같은 기업들은 초당 수십억 건 이상의 요청이 올 수 있으며, 일반 국내 기업에서도 초당 수천에서 수만 이상의 요청이 올 수 있다. 어느정도 트래픽이 대용량일지 정의한 수치는 따로 없다. 그냥 내 개인적인 생각이라면, 인프라 또는 데브옵스 조직이 있는 회사라면 어느정…","fields":{"slug":"/high-traffic/"},"frontmatter":{"date":"August 19, 2023","title":"말도 많고 탈도 많은 대용량 트래픽는 대체 어떻게 처리할까?","tags":["cs","traffic"],"series":"cs"},"rawMarkdownBody":"\n\n## 대용량 트래픽 처리\n`대용량 트래픽`은 말 그대로 단위 시간의 수 많은 요청을 뜻한다. 구글이나 페이스북과 같은 기업들은 초당 수십억 건 이상의 요청이 올 수 있으며, 일반 국내 기업에서도 초당 수천에서 수만 이상의 요청이 올 수 있다. 어느정도 트래픽이 대용량일지 정의한 수치는 따로 없다. 그냥 내 개인적인 생각이라면, 인프라 또는 데브옵스 조직이 있는 회사라면 어느정도 시스템 규모 및 트래픽이 있고, 이에 따른 전체적인 시스템 및 트래픽 관리를 하는게 아닐까 싶다.\n\n![](high-traffic-01.png)\n\n수천 수만의 대용량 트래픽을 단순하게 생각하면, 하나의 트래픽을 짧은 시간에 아주 많이 처리하는 것이다. 결국 하나의 트래픽은 하나의 네트워크 통신에 의해 처리된다. 즉, TCP/IP 통신간에 병목이 발생될 수 있는 부분을 최적화 한다면 곧 대용량 트래픽을 처리할 수 있는 방법이 아닐까 싶다. 개발자로써 우리가 할 수 있는 역할은 `application layer`에서 병목을 최소화 시키고 최적화할 수 있는 방법을 찾는 것이다.\n\n\n## scale in/out\n뭐든 그렇듯 장비빨이 최고다. 가장 쉽지만 비용을 고려해야하는 방법이다. 트래픽 대군에 맞서 싸우기 위해 장비를 강화(sacle in)하거나 비슷한 장비를 여러개 장착(sacle out)하는 것을 선택해야 한다. 둘중 쉬운 방법은 성능이 빵빵한 장비를 사용하는 `sacle in`이다. 하지만 일정 성능 이상부터는 기하급수적으로 비싸진다. 그래서 일반적으로 가성비 좋은 장비를 여러대 장착시키는 형태의 `sacle out`을 많이 선택한다. 그렇다면 장비를 얼마나 늘리면 되는걸까? 트래픽의 정도를 예측하기 위해서는 `대역폭(bandwidth)`을 계산 해야한다. \n\n### bandwidth\n`대역폭`은 서버에서 전송 가능한 데이터의 양을 의미하며, 초당 전송 가능한 데이터의 양을 측정한 값이다. 즉, 서버가 어느정도의 대역폭이 확보되어 있냐에 따라 일단 대량의 요청을 버틸 수 있냐 없느냐가 결정 되는 것이다. 트래픽 대군이 몰려올때 맞서 싸울 아군의 전력이 얼마나 확충되어 있는지를 알아야한다.\n\n서버 개발자들에게는 긴장의 순간들이 있다. 바로 이벤트, 프로모션 등의 순간 트래픽이 많을 수 있는 페이지다. 이러한 경우 서버가 안정적으로 트래픽을 받을 수 있는 상태인지 확인해야한다. 즉, 대역폭을 확인하는 것이다. 예시로 티몬의 룰렛 서비스를 보자. 해당 페이지를 예시로 드는 이유는 몇년 전 과거, 주니어 개발자였던 내가 만든 페이지기 때문이다. (머쓱)\n\n![](high-traffic-06.png)\n\nchrome의 Network 탭의 하단에서 정적 콘텐츠를 모두 합산하여 해당 페이지의 네트워크 전송량이 얼마인지 대략 알 수 있다. 예시 페이지는 `2MB`로 나오고 있다. 해당 값은 HTTP 캐시를 모두 비운 최초 로드값이다. 만약 해당 페이지에 `2만명`의 유저가 동시에 `1번`만 `1분` 내에 접근 한다면 해당 페이지는 정상적으로 운영될 수 있을까? 물론 정답은 알 수 없다. 왜냐면 해당 페이지를 내가 개발 할 때로부터 수년이 지난 지금, 해당 웹서버의 스펙을 모르기 때문이다. 그렇다면, AWS EC2기준 어느정도 스펙의 타입을 선택하면 될 지 역산해보자.\n> 2MB * 20,000명 * 1회 = 40,000MB(=40GB)\n\n단순 트래픽은 총 40GB 발생하며, 이를 1분내에 완료 가능한지 확인하려면 대역폭으로 환산해야한다. 참고로 Bytes에서 bit로 변환하기 위해 트래픽 총량에 8을 곱해야한다.\n> 40GB * 8 / 60s = 5.33Gbps\n\n\n![](high-traffic-05.png)\n\n위 시나리오 정도의 트래픽을 감당하기 위해선 적어도 AWS EC2 기준 m5, c5 정도 스펙은 가용해야 적어도 트래픽을 수용은 할 수 있다고 예상해볼 수 있다. 물론 이는 다른 장애 및 병목 포인트는 고려하지 않고, 단순히 서비스 페이지 전송량으로만 계산한 것이다. 그렇다면 조금 더 전송량이 높은 페이지를 개발하고, 사용자 수가 많아지면 더 높은 고가용성 서버를 사용해야할까? 무조건 정답은 아니다. sacle out을 하는 이유는 가성비 좋은 장비를 여러대두어 부하를 분산시키기 위함이다.\n\n![](high-traffic-07.png)\n\n고가용성 장비에 대한 금전적 부담 때문에 스펙을 낮추어 t3를 사용하면 어떨까? (이론상 CPU, Memory의 변화는 무시) 최대 5Gbps를 갖는 t3 대역폭 스펙으로는 시나리오 결과의 5.33Gbps의 대역폭을 버틸 수는 없다. 하지만 해당 t3서버를 2대 두고 로드밸런서를 통해 부하를 분산한다면 어떨까? 이론상 최대 10Gbps 대역폭을 수용할 수 있게 되는 것이다.\n\n\n### load balancer\nsacle out으로 서버를 증설했다면 `로드밸런서`를 통해 트래픽을 분산시켜 서버의 부하를 줄일 수 있다. 로드밸런서을 이용하면 한 서버가 다운되더라도 이중화시킨 다른 서버에서 서비스를 지속하여, 사용자들이 문제를 인지하지 못하게 할 수 있다. 이는 곧 부하분산 뿐 아니라, 장애대응 효과까지 덤으로 얻을 수 있다.\n\n![](high-traffic-04.png)\n\n로드밸런서는 대표적으로 TCP/UDP 기반의 L4, HTTP/HTTPS 기반의 L7 계층의 로드밸런서가 있다. AWS에는 L7 `ALB(Application Load Balancer)` 서비스를 제공한다. ALB는 HTTP/HTTPS 기반으로 동작하여 URI 경로, host 이름, HTTP header, query 문자열 등 다양한 속성을 기반으로 요청을 분배하여 L4 로드밸런서에 비해 세밀한 부하 분산이 가능하다. 그외 방화벽과 결합, 프록시 서버의 역할 등의 기능도 수행할 수 있다.\n\n### HTTP\n하나의 트래픽은 곧 TCP/IP HTTP 통신을 통해 처리되는 것이라 했다. 결국 HTTP 통신간에 지연을 줄일 수 있다면, 단위 시간에 처리할 수 있는 요청 수도 많아질 수 있다. 방법은 단순하다. `HTTP version`을 상향 시키는 것이다. \n\n![](high-traffic-08.png)\n\n만약 가용중인 웹서버가 HTTP/1.1을 사용하고 있다면, HTTP/2.0으로 버전을 올리는것 만으로도 성능이 향상될 수 있다. HTTP/2.0은 한번의 연결로 여러 요청을 처리할 수 있는 `멀티플렉싱`을 제공함으로써, 단위 시간에 더욱 많은 요청을 처리할 수 있기 때문이다. 다만 자신이 사용중인 웹서버 및 클라이언트(브라우저)에서 HTTP/2.0을 지원하는지 확인해야한다. nginx 기준으로는 1.9.5 버전 이상에서 HTTP/2.0를 지원한다. 참고로 구글에서 개발한 UDP 기반의 HTTP/3.0도 이미 시장에서 상용되고 있으니 관심 있으면 더 깊게 찾아봐도 좋다.\n\n## storage\n웹서버의 성능을 높이거나 갯수를 늘려도 데이터 저장소에 의해 트래픽을 처리하지 못할 수 있다. 네트워크 시간중 I/O 처리를 얼마나 안정적이고 빠르게 처리하냐에 따라 서버 가용성에 큰 도움이 된다. 가장 쉽게 접근하는 RDBMS인 DB의 부하 분산 방법부터 알아보자.\n\n### DB\n![](high-traffic-03.png)\n\n* sharding: 대량의 데이터를 가진 테이블을 수평적으로 여러 DB로 분할하여 저장하는 방식이다. 읽기 및 쓰기를 여러 분할한 샤드로 분산처리할 수 있다. 다만 join 연산은 서로 다른 DB에서는 할 수 없으니, join이 필요 없는 단일 도메인 대상의 테이블에 적합하다.\n* partitioning: 대량의 데이터를 가진 테이블을 수직(또는 수평)으로 여러 테이블로 분할하여 저장하는 방식이다. 다만 말그대로 테이블을 쪼개는 만큼, join할 key를 설정해야하며 join 연산을 해야하는 비용이 발생될 수 있다.\n* index: 인덱스는 검색, 정렬, 그룹 등을 도와주는 DB에서 중요한 역할을 하는 자료구조이다. 샤딩과 파티셔닝을 하게되면 대량의 테이블이 경량해질 수 있다. 이는 곧 자연스럽게 인덱스 성능이 올라가는 효과를 볼 수 있다.\n\n### cache\n일반적으로 mysql과 같은 DB는 디스크 기반의 데이터 스토리지이기 때문에 메모리에 비해서 훨씬 느린 속도로 데이터를 탐색한다. 그래서 반복되는 요청 리소스는 메모리 `캐시`를 통해 처리하여, 서버 부하를 줄일 수 있다. 메모리 캐시는 일반적으로 redis와 같은 nosql을 활용할 수 있다.\n\n![](high-traffic-02.png)\n\n캐시는 적용하고자 하는 도메인 데이터의 성질 local cache, global cache 전략중에 선택할 수 있다.\n\n* local cache: 기동중인 서버 내에 캐시 메모리를 사용하는 것이다. 사실상 오버헤드가 없다. 서버가 여러대면 각 서버마다 독립적인 캐시 메모리를 할당 받기 때문에 가장 빠르게 응답을 받을 수 있다. 다만 캐시의 동기화가 복잡할 수 있고, 각 서버간에 일관성이 깨질 수 있다.\n* global cache: 여러대의 서버가 있다면, 별도의 캐시 서버두고 동기화된 메모리를 공유하는 것을 뜻한다. local cache에 비하면 동기화 문제는 없으나 네트워크 I/O 과정이 있기에 속도차이는 발생할 수 있다.\n\n### CDN\n일반적인 데이터는 서버의 메모리 캐시를 통해 처리한다면, 컨텐츠 정보는 `CDN(Content Delivery Network)`을 통해 저장 또는 캐시 할 수 있다. \n\n![](high-traffic-10.png)\n\nCDN은 서버와 사용자 사이에서 동영상이나 웹사이트 이미지와 같은 컨텐츠 정보를 빠르게 전달하기 위한 일종의 캐시 서버이다. 컨텐츠 정보에 특화되어 관리되므로 안정적으로 컨텐츠 정보를 전달할 수 있다. 또한 웹 서버의 컨텐츠 트래픽을 부하분산 함으로써 웹 서버 자체에 대한 대역폭 소비를 줄여 성능과 가용성 측면에서 많은 이득을 볼 수 있다. 논외로, 세계에서 가장 점유율이 높은 CDN은 Akamai이며, AWS에는 CloudFront 라는 서비스로 제공한다.\n\n\n## application\n개발자가 직접적으로 고민해야 할 영역이다. 항상 시스템을 모니터링하고 테스트하면서 병목이 발생될 수 있는 부분을 리펙토링 하도록 노력해야한다. 경량한 서비스를 만들기 위해서는 도메인 목적에 맞게, 단일 책임 기반의 시스템 설계 및 개발이 필요하다.\n\n### big O\n시간복잡도가 O(n^2) 이상이거나 입력 크기가 큰 데이터를 처리해야 하는 로직이라면, 항시 경계 해야한다. 자고로 10,000건의 데이터를 중첩된 for loop로 개발하게 되면 100,000,000(1억)건의 반복을 동기적으로 수행해야 한다. 물론 처음부터 대량 정보에 대해 중첩된 반복으로 개발하진 않을것이다. 하지만 시스템에 관심을 기울이지 않는다면, 어느새 늘어나있는 테이블 데이터에 의해 내가 만든 비즈니스 로직이 전체 네트워크에 병목을 줄 수 있다.\n\n### pool size\n여러 도구에 따라 pool(대기열)을 지원하는 시스템이 있다. 특히 대용량 트래픽을 처리하기 위해서는 충분한 CPU, 메모리, 디스크 리소스를 확보하여 `thread pool` 및 `DB connection pool` 값을 적절하게 설정해야 한다.\n\n![](high-traffic-09.png)\n\n* thread pool: 애플리케이션에서 처리해야 할 작업을 동시에 처리할 수 있도록 지원하는 스레드의 집합이다. 너무 적게 설정하면 대기중인 작업이 많아지게 되어 처리 속도가 느려질 수 있다. 반대로 너무 많이 설정하면 스레드는 별도의 스택 공간을 갖기 때문에 메모리를 많이 잡아먹으며, 잦은 context switching이 발생하여 CPU 오버헤드 등의 문제가 발생할 수 있다. 참고로 spring boot의 기본 WAS인 tomcat의 경우 default thread pool size는 200이다.\n* DB connection pool: DB에 동시 연결이 가능한 수 이다. java의 DB connection 과정은 I/O과정에 부하가 큰 작업이다. 그래서 미리 connection pool을 통해 서버 연결간에 connection을 확보하고, 재활용 함으로써 서버의 부하를 줄일 수 있다. 너무 적게 설정하면 대기 시간이 발생하여 애플리케이션의 처리 속도가 느려질 수 있고, 너무 많이 설정하면 메모리 소모가 클 것이다. 참고로 spring boot의 경우 HikaraCP를 기본 커넥션 관리 라이브러리로 사용한다.\n\n### CQRS\n애플리케이션 서버를 경량화하고 목적에 맞는 커넥션(read, write)을 관리함으로써 시스템 자원을 효율적으로 사용할 수 있다. 이는 곧 대용량 트래픽을 처리에 큰 효과를 발휘할 수 있다 있다. 이러한 시스템은 명령(command)과 조회(query)를 분리하는 것을 중심으로 설계 된 `CQRS(Command Query Responsibility Segregation)` 소프트웨어 아키텍처 패턴을 통해 구현할 수 있다.\n\n![](high-traffic-11.png)\n\nCQRS 패턴은 데이터의 변경을 명령(command)하는 시스템과 조회(query) 및 처리하는 시스템을 분리하는 것이 핵심이다. 각각 분리된 시스템은 분산 시스템으로써의 장점을 갖을 뿐 아니라, 확장성 및 유지보수성 등 여러가지 측면에서 이점이 있다. 일반적으로 이벤트 기반의 시스템(kafka, rabbitMQ 등) 및 DDD(Domain-driven Design) 개념과 함께 사용한다. \n\nREST API와 같은 직접적인 http connection에 의한 처리를 하지 않기 때문에, query의 역할을 하는 시스템에서의 장애를 command 시스템에서 알아내기 위해 예외적인 개발이 필요할 수 있다. 또한 비즈니스 처리가 동기적으로 진행되어야 할 DB동작과 엮이게 된다면 transaction 처리에 어려움이 발생할 수 있다.\n\n### non blocking/async\n`non blocking`과 `async`를 조합하면 대량의 요청에 대해 병렬적으로 처리하여 시스템 처리량을 향상시킬 수 있다. non blocking이 비동기로 동작하는 것이 아닌가? 라고 생각하는 경우가 많다. 비동기 동작은 asynchronous이다. 두 개념은 다른것이며, 설명은 아래와 같다.\n\n* non-blocking: A 함수가 B 함수를 호출 할 때, B 함수가 제어권을 바로 A 함수에게 넘겨주면서, A 함수가 다른 일을 할 수 있도록 하는 것.\n* asynchronous: A 함수가 B 함수를 호출 할 때, B 함수의 결과를 B 함수가 처리하는 것.\n\n사실 이런 딱딱한 설명으로는 이해하기 힘들 수 있다. 그림을 보면서 이해해보자.\n\n![](high-traffic-12.png)\n\n커피 가계 직원은 커피를 주문한 손님이 다른일을 할 수 있도록 `non blocking`으로 주문 후 이후 행동에 대한 제어권을 손님에게 주는 것이다. 손님은 잠깐 나갔다 오던 의자에 앉아 있던 화장실을 다녀오던 하고싶은 일을 하면된다. 그리고 커피를 직원이 손님에게 가져다 주지 않고, 진동벨을 통해 손님이 받으러 간다. 즉, 손님이 주문 결과 나온 커피를 직접 받도록 `async`로 동작한다. 그래서 스타벅스는 non blocking/async로 동작하기 때문에 주문 순환이 빠르다. 그래서 대량의 손님(트래픽)을 빠른 시간에 처리할 수 있는 것이다. \n\n하지만 첫번째 손님이 5분이 걸리는 음료를 주문하고, 세번째 손님이 1분이 걸리는 음료를 주문한다면 어떨까? 세번째 주문한 손님의 진동벨이 먼저 울릴 수 있다. 하지만 진동벨은 울리고 있지만, 전화를 하던 도중이라 나중에 음료를 받으러 갈 수도 있다. 즉, async에 대한 동작은 커피(결과)에 대한 제어권이 손님에게 있기 때문에 최종적인 결과에 대한 순서를 보장할 수 없다.\n\n\n## 결론\n대용량 트래픽을 처리할 수 있는 방법은 사실 소개한 방법들 외에도 너무나 많다. 실제로 상황에 처해보면 예상치 못한 곳에서 수 많은 체크 포인트들이 발생할 수 있다. 결국 주어진 상황에서 최선의 방법을 찾아서 대응 해야한다.\n> 대용량 트래픽 처리는 서버 개발자들의 워너비이자 숙명이다.\n\n##\n***\n###\n* <https://vince-kim.tistory.com/m/39>\n* <https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html>\n* <https://blog.naver.com/PostView.nhn?blogId=dilrong&logNo=221689556862>\n* <https://jaehoney.tistory.com/155>\n* <https://imagekit.io/blog/what-is-content-delivery-network-cdn-guide/>\n* <https://poiemaweb.com/js-async>\n* <https://aws.amazon.com/ko/blogs/korea/new-application-load-balancer-simplifies-deployment-with-weighted-target-groups/>"},{"excerpt":"servelt 클라이언트의 HTTP request에 대해 response 처리를 담당하는 java 프로그램이다. 정적인 웹 서버에서 동적인 페이지를 제공할 수 있도록 도와주는 어플리케이션이라 보면 된다. 서블릿은 절대 spring을 위해 만들어진 개념이 아니다. 웹 애플리케이션 개발 시 불필요한 request, reponse 로직을 추상화하고 개발자들이 …","fields":{"slug":"/servelt/"},"frontmatter":{"date":"July 05, 2023","title":"spring servelt은 무엇인가?","tags":["spring","servelt"],"series":"spring"},"rawMarkdownBody":"\n## servelt\n클라이언트의 HTTP request에 대해 response 처리를 담당하는 java 프로그램이다. 정적인 웹 서버에서 동적인 페이지를 제공할 수 있도록 도와주는 어플리케이션이라 보면 된다. 서블릿은 절대 spring을 위해 만들어진 개념이 아니다. 웹 애플리케이션 개발 시 불필요한 request, reponse 로직을 추상화하고 개발자들이 구현체만 만들어 사용할 수 있도록 제공하는 표준 개발 방식일 뿐이다.\n\n### servelt container\n서블릿 컨테이너는 말그대로 서블릿을 담고 관리해주는 컨테이너로, 서블릿의 생명주기를 관리해주는 역할을 한다. 우리가 흔히 아는 `tomcat`이 바로 java 기반의 서블릿 컨테이너이자 WAS이다.\n\n![](servlet-01.png)\n\n서블릿 컨테이너는 클라이언트의 요청을 받으면 HttpServletRequest, HttpServletResponse 객체를 생성하며 POST, GET 등의 HTTP method에 따라 동적인 페이지를 생성하여 응답한다. \n각 요청에 따라 생성된 서블릿은 `싱글톤` 객체로 관리하며, 최초 요청시 `init()`을 통해 인스턴스를 생성하고 이후 요청에는 재활용한다. 그리고 서버 종료와 같은 종료시 `destroy()`를 통해 인스턴스를 메모리에서 해제한다. 또한 클라이언트 요청마다 새로운 쓰레드를 생성하며, 동시에 여러 요청을 처리할 수 있도록 `멀티쓰레드`를 지원한다. 이는 곧 적절한 쓰레드풀 설정이 필요한 이유이다.\n\n### front controller\n서블릿 요청을 각 서블릿이 모든 역할을 처리하면 비즈니스 로직 외 공통적인 처리에 중복적인 개발 요소가 많아진다. 이에 따라 전방에서 각 요청의 역할을 controller에게 위임 해주는 방법을 `front controller pattern`이라고 한다.\n\n![](servlet-03.png)\n\n\n## spring framework\nspring framework는 serlvet을 이용하여 웹 개발을 편하게 만들 수 있도록 제공한다. spring framework에서는 `dispatcher servlet`을 통해 웹 요청을 처리하며, 이는 fron controller pattern의 구현체다. 그 외에도 `handler mapping`, `handler adapter`, `view resolver`등 에게 역할을 위임 한다.\n\n![](servlet-02.png)\n\nspring MVC에서는 `dispatcher-servlet.xml`을 통해 직접 서블릿 설정이 가능하다.\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n \n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\n       http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd\">\n    <mvc:annotation-driven />\n    <context:component-scan base-package=\"com.hipcoding.board.controller\"/>\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <property name=\"prefix\" value=\"/WEB-INF/views/\" />\n        <property name=\"suffix\" value=\".jsp\" />\n    </bean>\n</beans>\n```\n\nspring boot는 내부적으로 내장 tomcat을 가지고 있다. 즉 spring boot가 실행되면서 내부적으로 tomcat(servlet container)이 실행된다.\n```\n2023-03-08 10:50:42.413  INFO 11287 --- [(2)-172.30.1.48] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'\n2023-03-08 10:50:42.413  INFO 11287 --- [(2)-172.30.1.48] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'\n2023-03-08 10:50:42.416  INFO 11287 --- [(2)-172.30.1.48] o.s.web.servlet.DispatcherServlet        : Completed initialization in 3 ms\n```\n\n\n## 결론\nspring boot로 개발하다보면 dispatcher servlet을 직접 건드릴 일이 사실상 없다. 그러다보면 자연스럽게 servlet에 대한 개념을 잊고 개발하기 십상이다.\n> 아무리 웹 개발 프레임워크가 좋아졌지만, 서블릿은 여전히 HTTP 웹 어플리케이션 개발의 핵심이다.\n\n##\n***\n###\n* <https://erainnovator.com/servlet-life-cycle/>\n* <https://docs.spring.io/spring-framework/docs/3.0.0.RC2/spring-framework-reference/html/ch15s02.html>\n* <https://terasolunaorg.github.io/guideline/5.0.1.RELEASE/en/Overview/SpringMVCOverview.html#overview-of-spring-mvc-processing-sequence>\n\n"},{"excerpt":"TPC/UDP 먼저 HTTP 관련 정보에 단골로 등장하는 내용인 TPC/UDP를 아주 얕게 설명한다. TPC/UDP의 동작 방식이나 차이점 등은 교수님 강의에서도 필수로 등장한다. 간단하게 그림으로 살펴보자.  TCP 통신에는 라고 부르는 과정이 데이터 통신에 선행된다. 이는 서버와 클라이언트 간에 와 패킷을 통해 서로의 연결에 대한 신뢰성을 확보하는 과…","fields":{"slug":"/http-protocol/"},"frontmatter":{"date":"June 18, 2023","title":"HTTP 프로토콜 진화 과정","tags":["http"],"series":"cs"},"rawMarkdownBody":"\n\n## TPC/UDP\n먼저 HTTP 관련 정보에 단골로 등장하는 내용인 TPC/UDP를 아주 얕게 설명한다. TPC/UDP의 동작 방식이나 차이점 등은 교수님 강의에서도 필수로 등장한다. 간단하게 그림으로 살펴보자.\n\n![](http-protocol-01.png)\n\nTCP 통신에는 `3 handshake`라고 부르는 과정이 데이터 통신에 선행된다. 이는 서버와 클라이언트 간에 `SYN`와 `ACK`패킷을 통해 서로의 연결에 대한 신뢰성을 확보하는 과정을 포함한다. 결국 TCP가 UDP에 비해 느린 이유는 신뢰성을 보장하기 위한 통신 과정이 포함 되기 때문이다. 이번 포스팅에서는 TPC/UDP에 대해 아래 표 내용으로 얕게 정리한다.\n\n| | TCP | UDP |\n| --- | --- | --- |\n| 연결 방식 | 연결형 서비스 | 비연결형 서비스 |\n| 패킷 교환 | 가상 회선 방식 | 데이터그램 방식 |\n| 전송 순서 보장 | 보장함 | 보장하지 않음 |\n| 신뢰성 | 높음 | 낮음 |\n| 전송 속도 | 느림 | 빠름 |\n\n\n## HTTP/0.9\n초기단계 HTTP 프로토콜은 매우 단순하다. 초기에는 버전 번호가 없었고, HTTP/0.9는 차후 버전과 구별하기 위해 그냥 0.9로 부른 것이다.\n\n```\nGET /mypage.html\n```\nHTTP/0.9의 요청은 단일 라인으로 구성되며 연결 가능한 HTTP method는 `GET`이 유일하다. 지극히 단순하다.\n\n```\n<HTML>\nA very simple HTML page\n</HTML>\n```\n응답 또한 극도로 단순했으며, 오로지 html 파일 내용 그 자체로 구성된다. HTTP 헤더도 없을뿐 아니라, 오류 코드 또한 없다.\n\n## HTTP/1.0\nHTTP/1.0에서는 HTTP/0.9에 비해 브라우저 및 서버에 대해서 모두 확장성 있게 진화했다.\n```\nGET /mypage.html HTTP/1.0\nUser-Agent: NCSA_Mosaic/2.0 (Windows 3.1)\n```\n요청 `header` 개념이 추가되었다. 메타데이터를 전송할 수 있게 된 것이다. \n\n```\n200 OK\nDate: Tue, 15 Nov 1994 08:12:31 GMT\nServer: CERN/3.0 libwww/2.17\nContent-Type: text/html\n<HTML>\nA page with an image\n  <IMG SRC=\"/myimage.gif\">\n</HTML>\n```\n응답 정보에도 마찬가지로 `header` 개념이 추가되었다. 응답값에 상태코드가 붙기 시작했으며, `Content-Type` 도입으로 html 이외의 문서 전송도 가능해졌다.\n\n![](http-protocol-02.png)\n\nHTTP/1.0 에서는 커넥션 하나당 하나의 요청과 응답만 처리 가능했다. 그래서 요청마다 커넥션을 맺고 닫고를 반복하는 구조이다. 즉, 매번 새로운 요청마다 새로운 연결로 인해 성능이 떨어지고 서버에 부하가 생길 수 있다.\n\n## HTTP/1.1\nHTTP/1.1은 HTTP의 첫번째 표준 버전이다. \n\n![](http-protocol-06.png)\nHTTP/1.0의 단기 커넥션 방식에서 HTTP/1.1로 진화하면서 persistent connection(영속적인 커넥션), pipelining(파이프라이닝)을 지원하게 되었다. 위 그림은 각 방식에 따른 커넥션 연결 및 요청 방식과 네트워크 타임 감소를 한번에 볼 수 있다.\n\n### persistent connection\n![](http-protocol-03.png)\n\nHTTP/1.1에서는 HTTP/1.0에서의 불필요한 커넥션 문제를 해결 하기위해 persistent connection이 도입 되었다. 지정한 timeout 동안 커넥션을 닫지 않는 방식이다. 영속적인 커넥션은 연결 정보를 열어두고 여러 요청을 재사용 함으로써 새로운 TCP 핸드쉐이크 비용을 아끼고 TCP 성능을 향상 시킬 수 있었다. 물론 연결을 유지하려는 시간이 길어질수록 서버에 부하가 생기기 때문에 연결을 유지하는 시간을 제한하고 있으며, 이를 `Keep-Alive`라고 부른다.\n\n영속 커넥션 방법도 단점이 있다. 커넥션이 유후 상태일때에도 서버 리소스를 소비하며, 과부하 상태에서는 DOS 공격을 받을 수 있다. 이러한 경우에는 커넥션이 유휴 상태가 되자마자 닫히는 비영속 커넥션을 사용하는 것이 더 나은 성능을 보일 수 있다.\n\n### pipelning\n![](http-protocol-04.png)\nHTTP은 순차적으로 요청, 응답하는 프로세스를 가졌다. 즉, 현재 요청에 대한 응답을 받고 나서야 다음 요청을 실시 한다. 이는 먼저 오는 요청에 지연이 있다면 다음 요청들은 모두 지연이 걸려, 전체 네트워크 시스템에 상당한 부하와 딜레이를 발생시킬 수 있는 것이다. 파이프라이닝은 영속적인 커넥션으로 연결하여, 응답을 기다리지 않고 요청을 연속적으로 보내는 기능이다. 이것은 커넥션 지연을 회피하는 방법이다. 이론적으로 여러개의 HTTP 요청을 하나의 TCP 메세지 안에 채워서 발송하는 것이다. HTTP의 요청 사이즈가 계속 커지고 있지만, 일반적인 TCP에서는 최대 세그먼트 크기 내에서 몇개의 간단한 요청을 포함해서 보내기에는 여유로웠다.\n\n하지만 파이프라이닝 방법은 여러가지 버그와 구현의 복잡성 등 다양한 문제로 모던 브라우저들에서 기본적으로 활성화 되어 있지 않는 기능이다. 이를 대체하기 위해 HTTP/2.0 에서는 `멀티플렉싱` 방식으로 대체 되었다. 또한 파이프라이닝 방식으로는 `HOLB` 및 `중복헤더` 문제는 해결하지 못했다.\n\n### HOLB 문제\n![](http-protocol-05.png)\nHOLB는 `head of line blocking`을 뜻한다. 영속적인 커넥션 내에서 여러 요청을 timeout 시간동안 연속적으로 받을 수 있으나, 특정 요청의 응답이 밀리게 되면 뒤따라오는 모든 요청들의 응답은 밀릴 수 밖에 없는 문제점이 있다. 파이프라이닝 방법을 사용하더라도 하나의 TCP요청 내 여러 요청을 병렬적으로 보내어도, 결국 여러 요청중 하나의 응답이 늦어지면 전체적으로 해당 커넥션 자체의 응답은 늦어질 수 밖에 없는 문제가 있다.\n\n### 중복헤더 문제\nHTTP/1.1은 초기 HTTP와 다르게 헤더에 많은 메타 정보가 들어간다. 요청이 연속적으로 이루어질 때 동일한 헤더의 값도 연속적으로 보내며, 이는 곧 통신간에 쓸데없는 데이터를 중복으로 보내게 되는 문제가 있다.\n\n## HTTPS\n한편, HTTP의 보안 강화를 위한 HTTPS(HTTP Secure)가 등장한다. 본 포스팅에서는 HTTPS에 대해서 자세히 다루지는 않는다.\n\n![](http-protocol-07.png)\n\nHTTPS 프로토콜은 HTTP 프로토콜의 보안을 강화하기 위해 `SSL(Secure Sockets Layer)` 보안 소켓 계층을 사용하는 프로토콜이다. 즉, HTTPS는 HTTP에 SSL을 추가한 것으로, HTTP 요청에 암호화와 인증 등의 보안 기능을 제공하여 데이터의 안전성을 보장한다. 따라서, HTTPS는 인터넷 상에서 데이터를 안전하게 전송하는 데 매우 중요한 역할을 한다. \n\n`TLS(Transport Layer Security)` 또한 SSL과 마찬가지로 보안을 위한 암호화 프로토콜이다. 다만 암호화 방식과 보안 강도가 다르기 때문에 보안 수준의 차이는 있다. SSL3.0, TLS1.0, 1.1같은 오래된 버전은 보안 취약점이 발생될 가능성이 높기 때문에 포스트 작성 기준 TLS 1.2, 1.3을 권장한다.\n\n들리는 말로는 구글에서 SEO를 진행할 때, HTTPS로 호스팅된 사이트의 페이지에 대해 SEO 우선순위를 높여준다고 한다. 보안성 높은 페이지를 제공함에 있어 가산점을 주는듯 하다.\n\n## HTTP/2.0\n![](http-protocol-08.png)\n\n네이버의 포털의 메인 페이지다. 오른쪽 메인 페이지의 호출 정보를 보면 Protocol 메뉴에 `h2`라는 것이 보인다. 현재 우리나라에서 가장 많은 접속량의 네이버 메인 포탈에서 HTTP/2.0 프로토콜을 사용한다. HTTP/2.0는 HTTP/1.x의 다음 버전으로, 웹 성능과 안전성을 개선하기 위해 설계 되었다.\n\n### binary protocol\n![](http-protocol-09.png)\n\nHTTP/2.0 에서는 HTTP 메세지의 전송 방식을 변경한다. 기존 HTTP/1.x에서 text 형태로 처리하던 메세지를 HEADERS/DATA 각각을 frame이라는 단위로 분할하고 binary로 인코딩한다. 이는 곧 text가 아닌 binary로 변환 함으로써 컴퓨터 입장에서는 메세지의 파싱 처리가 더욱 빨라진다. 이는 곧, 전송속도 향상 및 오류 발생 가능성을 낮추는 효과를 볼 수 있다.\n\n### multiplexing\nHTTP/2.0에는 HTTP/1.x의 메세지 라는 단위 외에 frame, stream 이라는 단위가 추가 되었다.\n* frame: HTTP/2.0 통신상 가장 작은 정보의 단위이며, Header or Data\n* message: HTTP/1.x 와 마찬가지로 요청 혹은 응답의 단위이며, 다수의 frame로 이루어짐\n* stream: 클라이언트와 서버사이 맺어진 연결을 통해 양방향으로 주고받는 하나 혹은 복수의 message\n> frame < message < stream\n\n![](http-protocol-10.png)\n\n1개의 stream을 보면 GET요청이므로 header stream 하나를 메세지로 보내고 header, data frame을 각각가진 메세지를 응답 받고 있다. 그리고 아래 N개의 stream을 보면, 복수 요청 및 응답 메세지들이 하나의 stream에서 존재하는 모습을 볼 수 있다. 이처럼 HTTP/2.0에서는 HTTP/1.x와 다르게 요청과 응답은 하나의 메세지만 담당하는 것이 아닌 하나의 stream이 다수의 요청과 응답을 받을 수 있는 구조로 바뀐 것이다. 즉, 이를 `멀티플렉싱(multiplexting)`이라 한다. \n\n![](http-protocol-12.png)\n멀티플렉싱은 TCP 연결에서 여러개 요청과 응답을 병렬로 처리 하는 방식이다. 이를 통해 모든 요청과 응답을 하나의 TCP 연결을 통해 모든 요청과 응답을 처리할 수 있다. 덕분에 HTTP/1.x 에서 발생하던 고질적인 지연 문제인 HOLB도 자연스럽게 해결되었다.\n\n### server push\nHTTP/2.0에서는 `서버 푸시(Server Push)`라는 기능을 제공한다. 이 기능은 서버가 클라이언트의 요청에 대한 응답으로 요청한 리소스를 보내는 것뿐만 아니라, 클라이언트가 요청하지 않은 리소스를 미리 보내주는 기능이다.\n\n![](http-protocol-13.png)\n\n클라이언트가 요청한 `/page.html`을 받고, 이후 서버에서는 요청간에 `script.js`와 `style.css`가 필요할 것 이라 예측하고 이를 미리 보내준다. 이러한 서버푸시 기능을 통해 추가적인 통신 단계를 줄여, 불필요한 네트워크 지연을 줄일 수 있다. 이를 통해 웹 페이지의 로딩 속도를 더욱 빠르도록 지원 할 수 있다.\n\n\n### header compression\nHTTP/1.1에서는 요청 및 응답 헤더에 많은 정보가 포함되는데, 이러한 헤더 정보는 매 요청마다 반복적으로 전송되기 때문에 중복이 발생하며, 이로 인해 데이터 전송 속도가 느려지는 문제가 발생한다. HTTP/2.0에서는 이러한 문제를 해결하기 위해, `헤더 압축(Header Compression)` 방법을 통해 데이터를 전송한다. 이를 위해, HPACK이라는 새로운 헤더 압축 방식을 사용한다. 이때 `Huffman Encoding` 알고리즘이 사용된다.\n\n![](http-protocol-14.png)\n\n첫번째 `request1` 요청에 6개 필드를 header frame에 담아 stream1 통해 보내고, 두번째 `reuqest2`에서는 중복되지 않는 path 정보만 header frame에 담아 stream3을 통해 보냈다. 이렇듯 HTTP/2.0에서는 중복헤더 데이터를 전송하지 않음으로써 매 요청마다 오버헤드를 크게 줄일 수 있다. 결국 이러한 헤더 압축 방법을 통해 데이터 전송 속도를 높일 수 있다.\n\n## HTTP/3.0\nHTTP/2.0이 나온지 얼마 되지 않아, 세번째 HTTP 메이저 버전인 HTTP/3.0이 구글에 의해 공개 되었다.\n\n![](http-protocol-16.png)\n\n먼저 TCP의 헤더를 보자. TCP는 기본적인 신뢰성을 위한 기능 외에 옵션을 추가할 수 있도록 헤더에 필드를 제공한다. 옵션은 무한정 제공할 수는 없으니 설계상 320bits로 정해놓았다. TCP의 단점을 보안하기 위해 나중에 정의된 MSS(Maximum Segment Size), WSCALE(Window Scale factor), SACK(Selective ACK) 등 많은 옵션들이 필드를 차지하고 있다. 즉, 사실상 더이상 커스텀할 수 있는 옵션 자리가 많지 않은 상황이다.\n\n반면에 UDP의 헤더 모습을 살펴보자. 한눈에 보아도 TCP와 UDP의 복잡함의 차이가 한눈에 보인다. 데이터 전송 자체에만 초점을 맞추고 설계 되었기 때문에 흰 도화지나 다름이 없는 상태이다. 그래서 구글이 HTTP/3.0을 설계할때 TCP가 아닌 UDP를 선택한 것이다. 이와 동시에 `QUIC(Quick UDP Internet Connections)`이라는 UDP기반의 전송 프로토콜을 함께 개발했다.\n\n![](http-protocol-17.png)\n\nHTTP/3.0 QUIC는 TCP를 사용하지 않기 때문에 3 way handshake 과정을 거치지 않는다. QUIC는 `0-RTT(Zero-Round Trip Time)`를 지원하여 최초 연결 설정 시간이 매우 짧다. 또한 TLS1.3와 결합하여 암호화된 연결을 제공한다. 즉, QUIC는 TCP에서 가지고 있는 고질적인 레이턴시 문제는 해결하면서 동시에 보안성을 강화시킨 UDP 기반 HTTP 프로토콜이다.\n\n## 결론\nHTTP는 내가 태어나기도 전부터 인터넷이 발달하는 그 순간에 만들어진 개념이다. TCP, UDP도 마찬가지로 꽤 예전에 만들어진 프로토콜이다. 반세기가 흘러 지금도 이러한 근본적인 HTTP에 대한 개념을 기반으로 확장성 있는 구조로 프로토콜이 발전하고 있는 것이다. 어찌보면 참으로 신기하다. 마치 역사적 가치와 의미를 보존하며 현대 문화에 맞게 모습과 기능을 발전시킨 한옥 같은 느낌이랄까...\n\n> 그래서 초기 HTTP 모습은 이론적으로만 봐왔지만, 계속 발전해나갈 HTTP의 모습을 응원하고 이에 발맞추어 같이 성장하고 싶다.\n\nps. `HTTP/3.0` 및 `QUIC`에 대한 내용은 다른 포스팅에서 자세히 정리 해야겠다.\n\n##\n***\n###\n* <https://www.linkedin.com/pulse/3-tcp-udp-there-way-handshake-cyber-security-basics-ertan-kaya>\n* <https://evan-moon.github.io/2019/10/08/what-is-HTTP3/>\n* <https://developer.mozilla.org/ko/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP>\n* <https://yozm.wishket.com/magazine/detail/1686/>\n* <https://heidyhe.github.io/https/>\n* <https://http2.tistory.com/13>\n* <https://www.popit.kr/%EB%82%98%EB%A7%8C-%EB%AA%A8%EB%A5%B4%EA%B3%A0-%EC%9E%88%EB%8D%98-http2/>\n* <https://donggov.tistory.com/188>\n"},{"excerpt":"kinesis 란 는 대규모의 실시간 데이터 스트리밍 처리를 지원하는 pub/sub 모델을 구현한 AWS 관리형 서비스이다. data strems kinesis data streams의 아키텍처 구조이다. 용어를 정리하면서 간단히 알아보자.  구성 설명 producer - data stream에 데이터를 보내는 주체의 서버 또는 애플리케이션 consume…","fields":{"slug":"/AWS-kinesis/"},"frontmatter":{"date":"May 29, 2023","title":"AWS kinesis basic","tags":["aws","kinesis"],"series":"aws"},"rawMarkdownBody":"\n\n## kinesis 란\n`kinesis`는 대규모의 실시간 데이터 스트리밍 처리를 지원하는 pub/sub 모델을 구현한 AWS 관리형 서비스이다.\n\n### data strems\nkinesis data streams의 아키텍처 구조이다. 용어를 정리하면서 간단히 알아보자.\n\n![](aws-kinesis-02.png)\n\n| 구성 | 설명 |\n| --- | --- |\n| producer | - data stream에 데이터를 보내는 주체의 서버 또는 애플리케이션 |\n| consumer | - data stream에서 데이터를 읽어들이고 처리하는 주체의 서버 또는 애플리케이션 |\n| stream | - 데이터 스트리밍을 처리하는 기본 단위이며, data recode로 구성 |\n| shard | - stream 내에서 data recode의 처리를 병렬화 하는 방법이며, stream을 구성하는 단위 <br> - stream은 하나 이상의 shard로 구성 |\n| data recode | - stream을 통해 전송되는 데이터 가장 작은 데이터 단위 <br> - sequence number, partition key, Blob로 구성됨 <br> - 일반적으로 json으로 작성하며, 최대 1MB까지의 크기를 가지고 shard를 통해 분산 처리 |\n| partition key | - stream 내에서 shard별로 데이터를 그룹화 하는데 사용 <br> - 동일한 partition key를 가진 data recode는 동일한 shard로 라우팅 <br> - MD5 hash 함수를 통해 data recode를 shard 매핑 |\n| sequence number | - 각 data recode의 유일한 식별자이며, 모든 데이터 레코드에는 시스템에서 자동으로 생성된 고유 번호 할당 <br> - sequence number는 각 shard에서 recode 순서를 유지하는데 사용 |\n\n### KPL/KCL\nAWS에서는 KPL, KCL을 지원하여 kinesis data stream을 쉽고 빠르게 구축 할 수 있도록 지원한다.\n\n* `KPL(Kinesis Producer Library)`은 kinesis data stream에 데이터를 추가할 수 있는 애플레케이션을 쉽게 구축 할 수 있도록 지원하는 라이브러리\n* `KCL(Kinesis Client Library)`은 kinesis data stream의 데이터를 읽고 처리하는 애플리케이션을 쉽게 구축할 수 있도록 지원하는 라이브러리\n\n\n## 용량 모드\nkinesis data stream을 생성할 때에는 두가지 비용의 용량모드를 선택할 수 있다.\n\n![](aws-kinesis-03.png)\n\n* 온디맨드(on-demand)\n    * stream 처리량이 불규칙하거나 예측할 수 없는 경우에 사용을 권장\n    * 데이터 처리량에 따라 shard의 수를 조정해주며, 처리한 데이터량에 따라 비용이 결정\n    * shard의 수를 직접 늘릴 수 없음\n* 프로비저닝(provisioned)\n    * stream 처리량을 어느정도 예측할 수 있는 경우에 사용을 권장\n    * shard 수를 직접 설정하여 stream을 생성하여, 미리 할당한 shard의 갯수에 따라 비용이 결정\n    * shard의 수를 직접 늘릴 수 있음\n\n요약하자면, 온디맨드 모드는 비교적 예측할 수 없는 데이터 stream 처리량에 적합하며, 프로비저닝 모드는 처리량을 예측할 수 있는 경우에 적합하다. 어떤 모드를 선택하든, 처리량에 따라 샤드당 시간당 요금이 발생하므로 처리할 데이터 양과 예상되는 비용을 고려하여 적절한 모드를 선택해야 한다.\n\n### 모드 변경\nkinesis data stream은 필요에 따라 라이브 서비스 중에도 즉각적으로 용량 모드를 변경할 수 있다. 아래의 예시는 AWS 블로그에서 예시 상황을 설명한 글이다.\n\n![](aws-kinesis-04.png)\n먼저 5개의 shard로 프로비저닝 모드로 생성된 stream이 있다고 한다. 처음 3분 동안 4MB/s의 로드를 전송하고 있고, 정상적으로 처리 하고 있다. 이후 타임스탬프 21:19에 로드를 12MB/s로 늘리며, stream이 더이상 로드를 처리할 수 없게되며 빨간색 선의 제한된 요청에 대한 수치가 높아지고 있는 모습이 보인다.\n이에 따라 타임스탬프 21:23에서 프로비저닝 용량모드에서 온디맨드 모드로 변경한다. stream에 영향을 주지 않고 즉시 적용할 수 있다.\n\n![](aws-kinesis-05.png)\n타임스탬프 21:24 시점부터 stream이 확장되면서 제한이 떨어지기 시작한다. 타임스탬프 21:26 시점에 stream 용량은 최초5개의 shard의 2배인 10개의 shard로 확장되고, 각 shard에서 로드가 0.5MB/s 미만의 수준으로 처리가능 할 때까지 stream은 계속 확장된다. \n\n![](aws-kinesis-06.png)\n이후 빨간색의 제한된 처리에 대한 수치가 사라지고, 안정적으로 서비스되고 있는 모습을 볼 수 있다. 이처럼 stream이 갑자기 대량의 로드를 받게되면 온디맨드 모드에서는 이를 처리할 수 있는 shard 용량을 확보할 수 있다.\n\n온디맨드 모드와 프로비저닝 모드 간을 하루에 두 번 전환할 수 있다. 프로비저닝된 모드에서 온디맨드 모드로 전환할 때 데이터 스트림의 shard 수는 동일하게 유지되며 그 반대의 경우도 마찬가지이다. 반대의 경우에는 kinesis data streams는 데이터 트래픽을 모니터링하고 트래픽 증가 또는 감소에 따라 온디맨드 data stream의 shard 수를 늘리거나 줄인다.\n\n## shard\n`shard`는 간단하게 stream을 구성하는 단위라고 위에서 설명했다. 좀 더 자세히 알아보자.\n\n### 처리량\nshard의 갯수는 곧 stream에서 단위시간에 처리할 수 있는 data recode의 갯수를 뜻한다. kinesis data stream에서 제공하는 shard 관련 처리량 스펙은 아래와 같다.\n* 단일 stream 기준 최대 설정 가능 shard 수는 200개(50개 이상부터는 AWS에 문의해야함)\n* 단일 shard 기준 읽기 처리량은 초당 5 transaction, 최대 2MB까지 지원\n* 단일 shard 기준 쓰기 처리량은 초당 1000개의 data recode 또는 초당 1MB 까지 지원\n\n### shard 갯수 설정\n용량모드 중 `프로비저닝` 모드에서는 최초 stream 생성시 shard의 수를 지정해줘야 한다. 그렇다면 적절한 shard의 수는 어떻게 알 수 있을까?\n\n* average_data_size_in_KB: 스트림에 쓰여지는 평균 데이터 레코드 수(KB), 1KB에 가깝게 반올림한 데이터 레코드 수\n* records_per_second: 스트림에서 초당 쓰고 읽는 데이터 레코드 수\n* incoming_write_bandwidth_in_KB: average_data_size_in_KB에 records_per_second를 곱한 값\n* outgoing_read_bandwidth_in_KB: incoming_write_bandwidth_in_KB에 number_of_consumers를 곱한 값\n\n```\nnumber_of_shards = max(incoming_write_bandwidth_in_KiB/1024, outgoing_read_bandwidth_in_KiB/2048)\n```\n\nAWS에서 가이드 하는 개수 설정 방법은 조금 복잡해 보일 수 있다. 로그 데이터 파이프라인 서비스나 대량의 스트리밍 서비스 등의 작업이 아닌 이상 단일 shard 정도로도 꽤나 준수한 처리량을 제공받을 수 있다.\n\n## 결론\nAWS kinesis는 운영 설정이나 관리 포인트를 대폭 감소시키고 각종 라이브러리까지 지원하여 쉽고 빠르게 대규모 스트리밍 서비스를 개발할 수 있도록 지원하고 있다. \n특히 AWS 관리형 서비스 답게 별도의 복잡한 설정이나 시스템 구축에 대한 허들 없이도 가능한 것이 매우 장점으로 보인다. 다만 굳이 [kafka](https://wo3okey.github.io/kafka/2023/02/22/kafka.html)와 비교하자면 kinesis는 shard에 대해 속도나 용량등의 제한적 처리량을 강제화하고 있는것은 사실이자 단점일 수 있다.\n> AWS를 사용하는 인프라 시스템에서 쉽고 빠르게 대규모 스트리밍, 이벤트 메세지 시스템 등을 구축하기에 kinesis 서비스는 꽤 좋은 선택지가 될 수 있다.\n\n##\n***\n###\n* <https://docs.aws.amazon.com/ko_kr/streams/latest/dev/introduction.html>\n* <https://docs.aws.amazon.com/ko_kr/streams/latest/dev/how-do-i-size-a-stream.html>\n* <https://www.softkraft.co/aws-kinesis-vs-kafka-comparison/>\n* <https://aws.amazon.com/ko/blogs/korea/amazon-kinesis-data-streams-on-demand-stream-data-at-scale-without-managing-capacity/>\n\n"},{"excerpt":"lucene lucene은 elasticsearch의 핵심이 되는 검색엔진 그 자체이며, java로 만들어진 고성능 정보검색 오픈소스 라이브러리이다. 결국 elasticsearch는 검색 및 색인 기능은 직접 구현한게 아닌 lucene을 사용한 것이다. 그 외 REST api, 분산처리, 고가용성을 위한 shard/replica 등의 시스템을 추가하여 지…","fields":{"slug":"/elasticsearch-change-shard/"},"frontmatter":{"date":"May 13, 2023","title":"elasticsearch shard 값은 왜 변경이 불가할까?","tags":["elasticsearch","shard","lucene"],"series":"elasticsearch"},"rawMarkdownBody":"\n## lucene\nlucene은 elasticsearch의 핵심이 되는 검색엔진 그 자체이며, java로 만들어진 고성능 정보검색 오픈소스 라이브러리이다. 결국 elasticsearch는 검색 및 색인 기능은 직접 구현한게 아닌 lucene을 사용한 것이다. 그 외 REST api, 분산처리, 고가용성을 위한 shard/replica 등의 시스템을 추가하여 지금의 elasticsearch 스펙이 완성된 것이다. \n\n## segment\n\n![elasticsearch shard](elasticsearch-change-shard-01.png )\n\nes의 index는 es shard 내 각자 lucene 라이브러리를 포함하고 있으며, lucene은 각각 독립적인 segment를 구성하고 있다. segment는 색인이 될 때 마다 새롭게 만드는 형태로 개발되어있다. 이때 segment는 내부에 역색인 구조로 데이터가 저장되어 있으며, lucene은 commit point라는 자료구조를 통해 segment들을 관리한다. 새로운 색인 작업이 생길때마다 segment를 새로 생성하며, 이를 commit point에 기록하는 형태이다. \n\n시스템에 따라 다를 수 있지만 대부분의 검색엔진을 사용하는 시스템은 새롭게 색인하는 데이터가 많다. 그때마다 segement 수는 빠르게 계속 증가할 것이다. 이때 너무 많은 segment가 생성되어 있으면 읽기 성능이 저하된다. 이를 방지하기 위해 lucene의 background에서 주기적으로 merge하는 과정이 수행된다. 이를 통해 segement 수를 조정하고, 읽기 성능을 안정적으로 지원할 수 있도록 한다. 이러한 주기적인 merge 과정이 있는 이유는, lucene은 한번 저장된 segment를 수정할 수 없도록 설계되었기 때문이다. 즉 주기적인 merge 작업에 의해 segment가 통합, 삭제 되기 전까지는 수정을 허용하지 않는 것이다. 그렇다면 segment는 왜 이런 immutability(불변성)의 특성을 갖도록 개발된 것일까?\n\n### segment immutability\n불변성은 역색인으로 생성된 segment들로 구성된 lucene의 입장에서는 매우 중요하다. 대용량 text를 다뤄야하는 역색인 구조에서는 이러한 불변성이 주는 장점이 매우 큰 역할을 하기 때문이다.\n\n1. 동시성 문제<br>\n데이터의 불변성이 보장된다면 멀티스레드 환경에서 lock이 필요없다. 수정이 불가능한 데이터는 스레드간의 충돌이 없을 뿐만 아니라 시스템이 단순해지고, 자연스럽게 성능적인 이점을 얻을 수 있다.\n\n2. 캐시 활용<br>\n데이터가 변경되지 않기 때문에 시스템에 생성되면 일정시간 유지된다. 만약 불변성이 보장되지 않는다면 데이터가 변경될 때마다 캐시를 갱신하는 등의 작업이 추가될 수 있는 비용이 포함될 수 있다. 그래서 불병성을 통해 성능적 이점 뿐 아니라 메모리 read를 통한 높은 캐시 hit를 꽤할 수 있다.\n\n그렇다고 장점만 존재하는것은 아니다. 불변성이라는 특성이 곧 수정이 불가하다는 뜻이다. 그말은 즉슨 일부 데이터가 변경되더라도 역색인 구조를 전부 다시 만들어야 한다는 의미이다. 하지만 매 색인마다 전체 역색인을 실시간으로 처리할 수 없다. 그래서 segment는 commit -> merge의 과정을 통해 생성, 통합 되는 것이다. 검색이라는 도메인 특성상 write보다 read 연산의 비중이 크기 때문에 불변성이 가져올 수 있는 장점이 단점보다 중요하다 생각되어 이러한 불변의 구조를 채택한 것으로 보인다.\n\n## shard 값 변경\nshard는 내부에 독립적인 lucene 라이브러리를 포함하며, lucene은 단일 머신 위에서만 동작하는 stand alone 검색엔진이다. 실제로 es로 검색 요청이 오게되면 1개의 query로 부터 1개의 shard로 시작하여 1개의 thread로 처리가 된다. 즉 lucene은 하나의 검색요청에 대해 별도의 처리 시스템을 갖는 개념이며, 이러한 특성 상 shard 내부의 lucene 입장에서는 함께 es index를 구성하고 있는 다른 shard의 존재를 알 수 없다. 즉 primary shard 갯수를 변경한다는 것은 각각의 독립적인 구조로 되어있는 lucene의 데이터를 모두 재구성 한다는 뜻이다. 하지만 위에서 얘기한 것처럼 lucene의 내부에는 다수의 segment로 이루어져 있고, 만약 쪼개어진 shard의 데이터를 처리하게 된다면 lucene은 역색인된 segement 조각들을 다시 재결합하고 색인하는 등의 리소스가 더 큰 작업이 소요될 것이다. 그래서 한번 생성된 index의 shard의 값은 변경하지 못하도록 막은 것이다.\n\n\n\n## 결론\nindex 생성 후 shard 변경을 하지 못하는 이유에 대한 의견은 아래와 같다.\n> elasticsearhc는 단일 머신에서 동작하는 lucene과 불변성의 특징을 살려 설계된 segment에 대한 장점을 살리기 위해 index가 생성된 후 shard 값을 변경할 수 없도록함\n\n### 그리고\n[`_reindex`](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html) API를 활용하면 index를 활용하면 shard의 값을 변경할 수 있도록 es에서 제공한다고 한다. 참고로 나는 shard 값 조정 시, 새로운 index를 생성/색인하고 alias를 교체하는 형태로 밖에 처리해보지 않았다. reindex API는 다음에 한번 사용해 봐야겠다.\n\n\n##\n***\n###\n* <https://brunch.co.kr/@alden/39>\n* <https://jaemunbro.medium.com/elastic-search-%EC%83%A4%EB%93%9C-%EC%B5%9C%EC%A0%81%ED%99%94-68062271fb64>\n* <https://fdv.gitbooks.io/elasticsearch-cluster-design-the-definitive-guide/content/a-few-things-you-need-to-know-about-lucene.html>\n* <https://blog.naver.com/occidere/222855956229>\n* <https://icarus8050.tistory.com/51>"},{"excerpt":"kafka 란 는 LinkedIn 에서 개발한 대용량 처리를 위한 분산형 스트리밍 플랫폼이다.  특징 높은 처리량과 낮은 지연시간 batch 처리 시스템을 통해 대량의 데이터를 높은 처리량으로 처리할 수 있도록 설계됨 메세지의 지연 시간이 매우 낮아 실시간 데이터 처리에 적합함 타 시스템과 비교하여 kafka의 producer, consumer 모두 압도…","fields":{"slug":"/kafka-basic/"},"frontmatter":{"date":"April 02, 2023","title":"kafka basic","tags":["kafka"],"series":"kafka"},"rawMarkdownBody":"\n## kafka 란\n`kafka`는 [LinkedIn](https://www.linkedin.com/) 에서 개발한 대용량 처리를 위한 분산형 스트리밍 플랫폼이다. \n\n\n### 특징\n* 높은 처리량과 낮은 지연시간\n    * batch 처리 시스템을 통해 대량의 데이터를 높은 처리량으로 처리할 수 있도록 설계됨\n    * 메세지의 지연 시간이 매우 낮아 실시간 데이터 처리에 적합함\n    * 타 시스템과 비교하여 kafka의 producer, consumer 모두 압도적인 처리량 성능을 보임\n![](kafka-03.png)\n\n* 확장성과 내고장성\n    * kafka는 다중 producer, 다중 consumer를 지원하여 동시에 메세지를 전송하거나 동시에 topic의 데이터를 읽을 수 있음\n    * producer, consumer뿐 아니라 kafka의 구성요소는 수평적 확장(scale-out)에 용이함\n    * broker의 장애나 네트워크 오류 등 시스템 문제에도 데이터 유실이 발생하지 않도록 내고장성을 보장\n\n* 파일시스템\n    * kafka는 데이터를 message queue에 보존하여 consumer는 장애가 발생해도 나중에 데이터를 처리할 수 있음\n    * kafka broker 파일시스템에 저장한 메세지는 관리자가 설정한 기간에 따라 저장, 사용 후 삭제됨\n    * 저장된 partition은 IO를 cache memory를 통해 처리하므로 성능적으로 유리함\n\n* 유연성\n    * producer, consumer, broker 등 다양한 구성 요소를 활용하여 유연한 데이터 처리 파이프라인 구성이 가능\n    * 다양한 기술과 연동이 가능하여 데이터 처리 시스템 구축시 중요한 역할 담당\n\n\n## kafka 구조\nkafka는 기본적으로 `pub/sub(펍/섭)` 이라고 하는 publish/subscribe 형태의 시스템 모델을 구현한 분산 이벤트 시스템이다. \n\n### pub/sub\npub/sub 모델은 데이터를 생산하는 주체인 `producuer`, 소비하는 주체인 `subscriber`, 그리고 이들 사이에 중재자 역할을 하는 `broker`로 구성된 낮은 결합도를 가진 구조를 뜻한다.\n\n![](kafka-01.png)\n\n### kafka architecture\npub/sub 모델 구조를 구현한 kafka의 기본적인 아키텍처 모습이다. 용어를 정리하면서 자세히 알아보자.<br>\n(topic: 1개, replica: 3, partition: 3)\n\n![](kafka-02.png)\n\n| 구성 | 설명 |\n| --- | --- |\n| producer | - 데이터를 생성하여 kafka cluster에 전송하는 application 서버 <br> - broker를 통해 미리 설정해둔 topic으로 데이터를 전송 |\n| consumer | - kafka cluster에서 데이터를 소비하는 application 서버이며 <br> - broker를 통해 미리 설정해둔 topic과 partiton의 데이터를 수신 |\n| broker | - kafka cluster의 중심 요소로, 데이터를 저장하고 처리하는 역할을 담당 <br> - 여러개의 물리 node에 설치될 수 있고 topic에 대한 message queue를 관리 |\n| topic | - kafka에서 데이터를 주고 받는 대상 <br> - 데이터를 관리하는 논리적 단위로 여러 partition으로 나누어져 있음  |\n| partition | - topic 내의 데이터를 저장하는 물리적 단위 <br> - partition은 데이터를 순서대로 저장하고 여러개의 broker에 분산하여 저장 <br> - partition에는 데이터의 상대적 위치를 표시하는 offset이 있으며, 이를 이용해 이전에 가져간 데이터 위치 정보를 알 수 있음 |\n| zookeeper | - kafka cluster의 구성 정보와 broker 상태 정보를 저장하는 분산 코디네이터 <br> - kafka cluster 전체의 안정성을 유지하는 역할을 담당 <br> - kafka cluster를 실행하기 위해서는 반드시 먼저 실행 되어야함 |\n| consumer group | - 각각의 consumer를 group 단위로 묶어, topic의 데이터를 병렬로 소비할 수 있도록 함 <br> - topic내 partition은 consumer group당 오로지 하나의 consumer만 소유권(ownership)을 갖고 소비할 수 있음 <br> - group내 consumer 추가/삭제 시 partition 소유권을 재분배하는 reblancing이 발생함 |\n| replication | - 가용성을 위해 여러 broker를 서버에 배포하고 partition을 복제하는 것 <br> - 위 구조의 주황색P partition을 `leader`이라 하며, 나머지는 `follow`이라 함 <br> - 데이터 읽고 쓰기는 오직 ledaer가 담당하며, follow는 leader와 동기화하며 leader의 장애시 follow 중 하나가 leader의 역할을 수행 |\n\n\nkafka의 구조에서 producer의 화살표가 broker를 향하는건 설명과 함께 이해가 되겠지만, consumer는 데이터를 수신하는 입장에서 화살표의 방향이 broker로 향하고 있다. 잘못 그린것이 아니다. 이는 consumer가 broker로 부터 pull 방식으로 데이터를 수신하기 때문이다.\n\n### push/pull\nconsumer가 broker로 부터 데이터를 가져오는 방법은 크게 push, pull 두가지의 방식으로 정리할 수 있다. push 방식은 broker가 데이터를 consumer에게 전달하기 위해 두 시스템 간의 연결을 유지하고 있어야 한다. 이는 곧 불필요한 커넥션 리소스를 갖게 된다. 반면에 pull 방식은 consumer가 일정 주기로 broker에게 요청하여 데이터를 가져오게 되므로 두 시스템간에 관계가 느슨해질 수 있다. 하지만 이는 곧 consumer가 요청하는 일정 주기간에 처리 지연이 발생하거나 처리량이 줄 수 있다. \n\n그렇다면 kafka는 왜 지연이 발생할 수 있는 pull 방식을 선택했을까? kafka에서는 pull방식의 단점을 극복하기 위해 consumer로 부터 batch 단위로 데이터를 가져오도록 처리하여 지연 문제를 완화 시켰다. 또한 consumer group를 이용하여 consumer간에 데이터 메세지를 공유하고 분배함으로써 높은 처리량과 빠른 속도를 통해 단점을 극복했다. 이러한 kafka의 구조를 통해 pull 방식의 장점을 극대화 하고 실시간 처리 시스템에 고가용성 데이터 파이프라인 아키텍처로 사용하고 있다.\n\n## 그래서?\n그래서 kafka의 고성능, 고가용성은 실로 유명하고 다양한 서비스들로 인해 증명 되어있다. message queue(MQ)만을 위해 쓰는 기업도 있는 반면, kafka의 성능과 장점을 극대화 시킬 수 있는 실시간 스트리밍, 로그분석 데이터 파이프라인과 같은 서비스 개발을 위해 많은 기업들이 kafka로 전환하거나 신규로 만들고있다. spring에서도 `spring-kafka`를 지원하여 쉽게 서비스를 개발할 수 있도록 지원하고 있다. 이는 다음번에 한번 정리 해봐야겠다.\n> 2023년 현재 글 작성 기준, kafka는 실시간 대용량 데이터 메세지 처리를 위한 분산 시스템계의 깡패이다.\n\n##\n***\n###\n* <https://notes.stephenholiday.com/Kafka.pdf>"},{"excerpt":"@Transactional은 spring에서 각 transaction를 묶어주고 관리해주는 역할을 하는 선언적 방법이다. @Transactional는 여러가지 속성과 옵션을 제공하며, 예시 코드들과 함께 알아본다.  transaction transaction은 DB의 상태 변경을 뜻한다. 코드도 git에 commit 하듯 DB도 변경점에 대한 savepo…","fields":{"slug":"/spring-transactional/"},"frontmatter":{"date":"March 11, 2023","title":"spring @Transactional 조금더 알아보기","tags":["spring","transactional"],"series":"spring"},"rawMarkdownBody":"\n\n@Transactional은 spring에서 각 transaction를 묶어주고 관리해주는 역할을 하는 선언적 방법이다. @Transactional는 여러가지 속성과 옵션을 제공하며, 예시 코드들과 함께 알아본다. \n\n## transaction\ntransaction은 DB의 상태 변경을 뜻한다. 코드도 git에 commit 하듯 DB도 변경점에 대한 savepoint를 남기며, 이는 rollback 가능한 지점을 뜻한다.\n\n흔히 `ACIS(애시드)`라고 불리는 transaction의 성질 4가지가 있다.\n\n* Atomicity(원자성): 한 transaction 내에서 실행한 작업들은 하나의 단위로 처리\n* Consistency(일관성): transaction은 일관성 있는 데이터베이스 상태를 유지\n* Isolation(격리성): 동시에 실행되는 transaction들이 서로 영향을 미치지 않도록 격리\n* Durability(영속성): transaction을 성공적으로 마치면 결과가 항상 저장\n\n## @Transactional\nspring에서는 transaction을 구현할 수 있도록 여러가지 형태로 지원한다. 그 중 가장 쉽게 사용할 수 있고 많이 사용하는 annotation 형태의 선언적 방법인 `@Transactional` 을 알아본다. spring에서 @Transactional을 사용하기 위한 방법, DB, ORM 설정 등의 내용은 다루지 않는다.\n\n### proxy\n@Transactional을 적용한 기본적인 예제 코드를 보자. 참고로 @Transactional는 proxy를 구현하기 위해 메소드 override가 필요하다. 즉, private 메소드는 @Transactional 적용이 불가하다.\n\n`@Transactional 적용`\n```kotlin\n@Service\nclass BreadBulkService(\n    val breadLogService: BreadLogService,\n    val breadService: BreadService\n) {\n    @Transactional\n    fun bulkSave() {\n        (1..10).forEach {\n            val bread = breadService.saveBread(it)\n            breadLogService.saveLog(bread)\n        }\n    }\n}\n```\nspring의 @Transactional은 `AOP`와 `Proxy`를 사용하여 transaction을 구현한다. proxy는 객체에 대한 대리자 역할을 하는 객체로, 실제 객체를 감싸서 호출되는 메서드의 호출을 가로채거나 다른 작업을 수행할 수 있다. 그렇다면 @Transactional 없이 proxy에 의해 구현되는 코드를 살펴보자.\n\n`transaction proxy`\n```kotlin\n@Service\nclass BreadBulkServiceProxy(\n    val breadLogService: BreadLogService,\n    val breadService: BreadService,\n    val transactionManager: PlatformTransactionManager\n) {\n    fun bulkSave() {\n        val transactionTemplate = TransactionTemplate(transactionManager)\n        transactionTemplate.execute { status ->\n            try {\n                (1..10).forEach {\n                    val bread = breadService.saveBread(it)\n                    breadLogService.saveLog(bread)\n                }\n                status.setRollbackOnly()\n            } catch (e: Exception) {\n                throw RuntimeException(\"Transaction failed\", e)\n            }\n        }\n    }\n}\n```\n\nspring에서는 AOP를 사용하여 @Transactional이 붙은 메서드를 찾아내고 이를 실행할 때 proxy를 생성하며, transaction 시작 및 메서드 실행 완료 후 commit 또는 rollback을 수행할 수 있는 코드를 생성한다. 이때, proxy 객체는 원본 객체와 같은 interface를 구현한다. 그래서 클라이언트 코드에서 @Transactional만으로 다른 별도의 처리 없이 transaction을 구현할 수 있다. 이렇게 AOP를 적용하여 구현된 클래스의 interface를 proxy 객체로 구현하여 코드를 끼워넣는 방식을 `JDK Proxy` 라고 한다. \n\n논외로, JDK Proxy는 replication을 사용하여 주입하는 방식으로 성능적으로 좋지 않다. 그래서 spring boot의 경우 기본적으로 proxy 객체를 생성할 때 CGLib(code generator library) 방식으로 byte 코드를 조작하여 proxy 객체를 생성하고 주입한다.\n\n### options\nspring @Transactional는 다양한 속성 정보를 설정 할 수 있다.\n\n* propagation: 동작 도중 다른 transaction을 호출할 때, 어떻게 할 것인지 지정하는 옵션(전파 수준)\n* isolation: transaction에서 일관성 없는 데이터 허용 수준을 설정(격리 수준)\n* noRollbackFor: 특정 예외 발생 시 rollback이 동작하지 않도록 설정\n* rollbackFor: 특정 예외 발생 시 rollback이 동작하도록 설정\n* timeout: 지정한 시간 내에 메소드 수행이 완료되지 않으면 rollback이 동작하도록 설정\n* readOnly: transaction을 읽기 전용으로 설정\n\n 여러 속성 중 transaction의 성질인 ACID와 긴밀하게 연관된 `propagation`, `isolation`에 대해서 좀 더 자세히 알아보자.\n\n## propagation\nspring에서 제공하는 @Transactional은 6개의 propagation 설정을 제공한다. 각각의 설정에 따른 동작을 위에서 언급한 예시 코드와 함께 알아보자. DB는 mysql, ORM은 JPA를 사용했다.\n\n제과(빵) 정보를 bulk 입력할때 bread 및 log를 단건으로 각각 입력하는 코드이다. 사실 실제 bulk 처리는 이렇게 건바이건 처리 하지 않지만, 부모/자식 transaction 처리를 간단하게 보여주기 위해 일부러 묶었다. 참고로 각각의 propagation 전파 설정을 코드로 설명할 때에는 function 부분만 기재한다.\n\n```kotlin\n@Service\nclass BreadBulkService(\n    val breadLogService: BreadLogService,\n    val breadService: BreadService\n) {\n    fun bulkSave(to: Int, from: Int) {\n        (to..from).forEach {\n            val bread = breadService.saveBread(it)\n            breadLogService.saveLog(bread)\n        }\n    }\n}\n```\n\n```kotlin\n@Service\nclass BreadService(\n    val breadRepository: BreadRepository\n) {\n    fun saveBread(key: Int): Bread {\n        return breadRepository.save(Bread(key, \"bread$key\"))\n    }\n}\n```\n\n```kotlin\n@Service\nclass BreadLogService(\n    private val breadLogRepository: BreadLogRepository\n) {\n    fun saveLog(bread: Bread) {\n        val log = BreadLog(log = BreadConverter.toResponse(bread).toString())\n        breadLogRepository.save(log)\n    }\n}\n```\n\n### REQUIRED\n부모 transaction이 존재한다면 부모 transaction에 합류 시키며, 그렇지 않다면 새로운 transaction을 만든다. 즉 부모 또는 자식에서 exception이 발생된다면 자식과 부모 transaction에 관련된 테이블의 savepoint는 모두 rollback 된다.\n\n```kotlin\n@Transactional(propagation = Propagation.REQUIRED)\nfun bulkSave() {\n    (1..10).forEach {\n        val bread = breadService.saveBread(it)\n        breadLogService.saveLog(bread)\n    }\n}\n```\n\n```kotlin\n@Transactional\nfun saveBread(key: Int): Bread {\n    return breadRepository.save(Bread(key, \"bread$key\"))\n}\n```\n\n```kotlin\n@Transactional(propagation = Propagation.REQUIRED)\nfun saveLog(bread: Bread) {\n    if (bread.id % 7 == 0) throw RuntimeException(\"7번째 강제 rollback\")\n\n    val log = BreadLog(log = BreadConverter.toResponse(bread).toString())\n    breadLogRepository.save(log)\n}\n```\n\n```\njava.lang.RuntimeException: 7번째 강제 rollback\n```\n부모 transaction 기준 자식에 있는 `log` transaction에서 강제로 발생시킨 예외에 의해 transaction 기준으로 부모 하위에 있는 `bread`, `log` 테이블 모두 rollback 되었다. 따로 코드상 언급하지 않지만, 부모 transaction인 `bulckSave` 메소드에서 예외를 발생 시켜도 마찬가지로 두 테이블 모두 rollback 된다. 이는 가장 기본적인 전파 옵션으로, propagation 설정을 따로 하지 않아도 `REQUIRED` 설정값으로 동작한다. 여러 write query가 진행될 때 예외 발생 시 일관성 있게 모든 테이블의 savepoint를 rollback 하고 싶을 때 사용하면 된다.\n\n### REQUIRES_NEW\n무조건 새로운 transaction을 생성한다. 즉 부모 또는 자식에서 exception이 발생된다면 각자에 해당되는 transaction만 rollback 한다. 사실상 각 transaction은 독립적인 구조라 생각하면 된다.\n\n```kotlin\n@Transactional\nfun bulkSave() {\n    (1..10).forEach {\n        val bread = breadService.saveBread(it)\n        breadLogService.saveLog(bread)\n    }\n}\n```\n\n```kotlin\n@Transactional\nfun saveBread(key: Int): Bread {\n    return breadRepository.save(Bread(key, \"bread$key\"))\n}\n```\n\n```kotlin\n@Transactional(propagation = Propagation.REQUIRES_NEW)\nfun saveLog(bread: Bread) {\n    if (bread.id % 7 == 0) throw RuntimeException(\"7번째 강제 rollback\")\n\n    val log = BreadLog(log = BreadConverter.toResponse(bread).toString())\n    breadLogRepository.save(log)\n}\n```\n\n```\njava.lang.RuntimeException: 7번째 강제 rollback\n```\n이번에도 자식 `log` transaction에서 강제로 예외를 발생시켰다. 부모 transaction 내에 있는 두개의 자식 transaction 중 `bread` 테이블은 모두 rollback 되었지만, `log` 테이블은 예외가 발생된 7번째 정보 전까지 1~6의 정보는 테이블에 남아있다. 이는 `REQUIRES_NEW` 설정에 의해 반복되는 save는 각각 transaction을 생성하고, 해당 transaction이 끝나면 모든 지점들을 commit 하기 때문이다. 이해관계가 있는 다른 transaction에서 실패가 나더라도 자신은 꼭 입력정보를 남겨야할때 사용하면 좋다. 특히 log 기록과 같은 히스토리성 정보에 적합할 수 있다.\n\n### MANDATORY\n무조건 부모 transaction에 합류시킨다. 부모 transaction이 존재하지 않는다면 예외를 발생시킨다.\n\n```kotlin\n@Transactional\nfun bulkSave() {\n    (1..10).forEach {\n        val bread = breadService.saveBread(it)\n        breadLogService.saveLog(bread)\n    }\n}\n```\n\n```kotlin\n@Transactional\nfun saveBread(key: Int): Bread {\n    return breadRepository.save(Bread(key, \"bread$key\"))\n}\n```\n\n```kotlin\n@Transactional(propagation = Propagation.MANDATORY)\nfun saveLog(bread: Bread) {\n    if (bread.id % 7 == 0) throw RuntimeException(\"7번째 강제 rollback\")\n\n    val log = BreadLog(log = BreadConverter.toResponse(bread).toString())\n    breadLogRepository.save(log)\n}\n```\n\n```\norg.springframework.transaction.IllegalTransactionStateException: No existing transaction found for transaction marked with propagation 'mandatory'\n```\n\n이전과는 결과가 달라졌다. 의무적이라는 뜻 그대로 `MANDATORY`는 부모 trasaction 없이 단독적으로 trasaction을 생성할 경우 예외를 발생시켜, 이를 강제로 막을 수 있는 설정이다. 만약 부모 trasaction이 있다면 `REQUIRED`와 동일하게 동작한다. 특정 입력 기능을 단독적으로 사용하지 못하도록 강제화 할 수 있는 효과가 필요할 때 사용하면 좋다.\n\n### NESTED\n`NESTED`라는 단어 그대로 중첩이 있는 transaction의 중첩이 있는 경우 사용한다. \n\n```kotlin\n@Transactional\nfun bulkSave() {\n    (1..10).forEach {\n        val bread = breadService.saveBread(it)\n        breadLogService.saveLog(bread)\n    }\n}\n```\n\n```kotlin\n@Transactional\nfun saveBread(key: Int): Bread {\n    return breadRepository.save(Bread(key, \"bread$key\"))\n}\n```\n\n```kotlin\n@Transactional(propagation = Propagation.NESTED)\nfun saveLog(bread: Bread) {\n    if (bread.id % 7 == 0) throw RuntimeException(\"7번째 강제 rollback\")\n\n    val log = BreadLog(log = BreadConverter.toResponse(bread).toString())\n    breadLogRepository.save(log)\n}\n```\n\n```\nJpaDialect does not support savepoints - check your JPA provider's capabilities\n```\n띠용. 갑자기 JPA 에러는 무엇인가? `NESTED`는 JDBC 3.0 이후부터 적용된다 라는 특징이 있으며, JPA를 사용하는 경우 dirty check와 같은 변경감지를 통해서 update를 최대한 지연해서 발행하는 방식을 사용하기 때문에 중첩된 transaction 경계를 설정할 수 없어 지원하지 못한다고 한다. 관련해서는 부가설명으로 이해를 조금 도울 수 있도록 한다.\n* 부모 transaction이 없다면 자식 transaction이 새로운 transaction을 생성함\n* 부모 transaction이 있다면 중첩 transaction을 생성함\n* 중첩 transaction이 끝나도 모든 commit은 부모 transaction의 끝에서 시행됨\n* 중첩 transaction의 내부에서 예외가 발생되어도 부모 transaction까지 rollback을 전파하지 않음\n* 부모 transaction의 내부에서 예외가 발생하면 모든 transaction은 rollback함\n\n즉, 먼저 시작된 부모 transaction은 내부 transaction에게 commit, rollback에 영향을 줄 수 있지만 내부 transaction의 예외가 부모에게 영향을 끼치진 않는다는 것이다.\n\n### SUPPORTS\n간단하게 말로 설명될 것 같은 설정이다. `SUPPORTS`는 부모 transaction이 있다면 합류하는 의미로, 진행중인 부모 transaction이 없다면 transaction을 생성하지 않는다. \n이와 반대로 `NOT_SUPPORTED`는 부모 transaction이 있던 말던 transaction 없이 진행한다.\n\n### NAVER\n말그대로 transaction을 생성하지 않는다. 부모 transaction이 존재한다면 예외를 발생시킨다.\n\n```kotlin\n@Transactional\nfun bulkSave() {\n    (1..10).forEach {\n        val bread = breadService.saveBread(it)\n        breadLogService.saveLog(bread)\n    }\n}\n```\n\n```kotlin\n@Transactional\nfun saveBread(key: Int): Bread {\n    return breadRepository.save(Bread(key, \"bread$key\"))\n}\n```\n\n```kotlin\n@Transactional(propagation = Propagation.NEVER)\nfun saveLog(bread: Bread) {\n    if (bread.id % 7 == 0) throw RuntimeException(\"7번째 강제 rollback\")\n\n    val log = BreadLog(log = BreadConverter.toResponse(bread).toString())\n    breadLogRepository.save(log)\n}\n```\n\n```\norg.springframework.transaction.IllegalTransactionStateException: Existing transaction found for transaction marked with propagation 'never'\n```\n한번도 실무에서 사용해본 적은 없다. 이론상 transaction 처리가 절대 발생하면 안되는 메소드에 실수로 transaction에 합류 되는 것을 방지하기 위함으로 보인다.\n\n## isolation\nisolaction은 먼저 언급한 ACID 속성중 하나이다. 격리성 또는 고립성 이라고 부르는 isolation은 말그대로 transaction끼리 서로에게 얼마나 격리되어 있는지를 나타낸다. 쉽게 얘기하면 transaction이 다른 transaction에서 변경한 데이터를 어느정도 수준에서 볼 수 있도록 할 지 결정하는 요소이다. DB는 ACID의 특징에 따라 각 transaction이 독립적인 수행을 할 수 있도록 `locking`을 통해 transaction의 수행간에 다른 transaction이 관여하지 못하도록 제어한다. locking을 하게되면 동시처리 능력이 떨어지므로 결국 전체적인 성능이 떨어질 수 밖에 없고, 너무 느슨하게 lock의 범위를 줄인다면 잘못된 값을 읽고 쓰는 문제가 발생할 수 있다. 이에따라 ANSI/ISO 표준에는 4가지의 isolation level을 정의했다.\n\n### READ_UNCOMMITTED\nlevel0의 가장 낮은 transaction 격리 수준이며 대부분의 DBMS가 사용하지 않거나 권장하지 않는다.\nselect가 실행할 때 shared lock이 걸리지 않는다.\n\n`dirty read` 현상이 발생될 수 있다.\n\n>dirty read: transaction의 변경 내용이 commit, rollback에 관계없이 다른 transaction에 적용됨\n\n* A transaction에서 wookey의 성적을 80점 -> 95점으로 변경\n* B transaction에서 학점을 정정하기 위해 wookey의 성적을 95점으로 조회하여 처리(dirty read)\n* 이때 A transaction에 예외가 발생하여 A transaction이 rollback 됨\n* 하지만 여전히 B transaction은 wookey의 성적을 95점으로 생각하고 이후 비즈니스 로직을 계속 수행\n\n\n### READ_COMMITTED\nlevel1의 transaction 격리 수준이며 대부분의 DBMS, Oracle 등에서 기본적으로 사용한다.\nselect가 실행할 때 shared lock이 걸린다.\n한 transaction의 내용이 commit 되어야만 다른 transaction에서 조회가 가능하여, dirty read는 발생하지 않는다. \nselect시 실제 테이블 값이 아니라 undo 영역의 backup recode를 가져온다. 동일한 transaction에서 select 쿼리를 실행했을 때 항상 같은 결과를 보장해야 한다는 `repeatable read` 정합성에 어긋나는 `non repeatable read` 현상이 발생될 수 있다.\n\n> non repeatable read: 같은 transaction 내 동일한 값에 대해 commit이 일어나기 전과 commit 후 값이 달라짐\n\n* A transaction에서 wookey의 성적을 조회하니 80점으로 나옴\n* B transaction에서 wookey의 성적을 80점 -> 95점으로 변경(commit 완료)\n* A transaction에서 wookey의 성적을 다시 조회하니 90점으로 나옴\n\n얼핏보면 맞는 동작처럼 보일 수 있다. 하지만 한 transaction 내에서 select에 대한 일관된 데이터를 반환하지 않는다는 것은 문제를 발생시킬 수 있다. 하나의 transaction 내에서 동일한 데이터를 여러번 읽고 변경하는 비즈니스 로직이 있다면 데이터 일관성이 깨질 수도 있다.\n\n\n### REPEATABLE_READ\nlevel2의 transaction 격리 수준이며 mysql DBMS에서 사용한다.\ntransaction이 시작되기 전 commit 된 정보에 대해서만 select가 가능하여 transaction이 끝날때 까지 select가 실행할 때 shared lock이 걸린다. 그래서 transaction 범위 내에서 조회한 내용이 항상 동일함을 보장함으로 dirty, non repeatable read은 발생하지 않는다. 다만 transaction의 시작 시점의 데이터를 계속 관리하고 일관성을 보장해야하기 때문에 transaction의 시간이 길수록 다중 버전 동시성 제어인 MVCC(multi-version concurrency control)를 관리해야 해야 하므로 성능적 단점이 생긴다. 또한 `phantom read`이 발생될 수 있다.\n\n> phantom read: 한 transaction에서 일정 범위의 레코드를 두번 이상 읽을때 처음에 없던 결과가 추가/삭제 되어 결과가 달라져 보이는 현상\n\n* A transaction에서 성적이 80점 이상인 집단을 조회하니 13명이 나옴(남학생: 6명 / 여학생: 7명)\n* B transaction에서 남학생인 wookey의 성적을 80점 -> 75점으로 변경(commit 완료)\n* A transaction에서 성적이 80점 이상인 집단의 남학생을 조회하니 5명이 나옴\n\n이 또한 얼핏 맞는 동작처럼 보일 수 있다. 하지만 시작 전 select 동일한 정보에 대해서는 일관성을 유지하지만 B transaction이 commit 되어 A transaction에 조회 범위에 영향을 주어 한 transaction 내에서 마치 결과가 삭제(상황에 따라 추가)된 것 같이 동작되어 보이는 phantom read를 발생 시킬 수 있다.\n\n### SERIALIZABLE\nlevel3의 가장 높은 transaction 격리 수준이며 거의 사용하지 않는다.\nselect, write 실행에 모두 lock을 선점한다. dirty read, non repeatable read, phantom read와 같은 문제가 발생하지 않으며, 일관성을 유지시킬 수 있는 가장 강력한 방법이다. 그 만큼 lock을 최대한으로 사용하기 때문에 동시 처리능력이 급격하게 떨어지고 결국 성능에 문제가 발생될 수 있다.\n\n\n## 결론\n![](spring-transactional-01.png)\n\n그래서 `@Transactional`은 spring에서 편리하게 transaction 처리를 적용할 수 있는 매우 유용한 방법이며, DB 관련 로직에서는 떼놓을 수 없는 손님이다.\n> @Transactional은 본인이 사용하는 DBMS와 처리 로직에 따라 전파수준과 고립수준을 잘 고려하여 사용하자.\n\n##\n***\n###\n* <https://akasai.space/db/about_isolation/>\n* <http://wiki.gurubee.net/pages/viewpage.action?pageId=21200923>"},{"excerpt":"redis cluster redis cluster은 redis 3.0 버전 이상부터 추가되었으며 데이터 동기화, 복제, failover 등을 지원할 수 있는 기능이 추가된 향상된 redis라고 생각하면 된다. 특히 failover 관점에서 node의 장애 또는 통신 문제 등 master-slave 및 replica 기능을 통해 수준높은 가용성을 제공할 수…","fields":{"slug":"/redis-consistent-hashing/"},"frontmatter":{"date":"January 30, 2023","title":"redis cluster의 동작과 hash slot","tags":["redis","redis cluster","hash slot","consistent hashing"],"series":"redis"},"rawMarkdownBody":"\n\n## redis cluster\nredis cluster은 redis 3.0 버전 이상부터 추가되었으며 데이터 동기화, 복제, failover 등을 지원할 수 있는 기능이 추가된 향상된 redis라고 생각하면 된다. 특히 failover 관점에서 node의 장애 또는 통신 문제 등 master-slave 및 replica 기능을 통해 수준높은 가용성을 제공할 수 있다.\n\nnosql은 각 node에 key를 할당할 때 특정 node에 집중되지 않고 분산처리를 위해 `consistent hashing` 이라고 하는 파티셔닝 방법을 대게 사용한다. consistent hashing은 redis 3.0 이전에는 다양한 버전에서 채택했다. 이후 redis cluster가 자리잡으면서 `hash slot` 이라는 방법을 선택했다. \n\n## hashing\n분산처리 key 분배 시 기본적으로 hasing에 의해 값을 결정하고 목적에 따라 일부 알고리즘을 변경해서 사용한다. 일단 redis cluster hash slot 설명에 앞서 key 분산처리를 위한 일반적인 hashing 및 consistent hashing을 먼저 알아보자.\n\n### general hashing\n먼저 일반적인 hashing 방법에 의해 key를 분산하면 어떻게 될까? 간단하게 알아보자.\n\n![](redis-consistent-hashing-01.png)\n* node: 3(nodeA~C)\n* key: 9(key1~9)\n\nkey가 유입되면 특정 hash(key) 함수의 결과에 의해 특정 node로 결정된다고 가정한다. 3개의 node에 9개 key를 분산 시켰을 때 모습을 보자. 일단 아름답게 잘 분산되어 있도록 가정했다. 편-안\n\n![](redis-consistent-hashing-02.png)\n\n만약 nodeC가 장애 또는 서버통신 문제로 제기능을 할 수 없는 상태가 되었다고 하자. 그렇다면 nodeC에 분산된 key는 어떻게 될 것인가? 마음같아선 nodeA, B에 동일하게 하나씩 나눠주고 싶겠지만 결국 최초 정해진 분산 방법에 따라 전체 재해싱을 진행할 수 밖에 없다. 재해싱 후 nodeB, B의 평화에 곧 엄청난 불균형이 찾아왔다. 이는 곧 재해싱 만으로도 server에 부하를 가져오지만, 각 node 간의 key 불균형도 피할 수 없다. \n그래서 고안된 방법 중 하나인 `consistent hashing` 을 소개한다. 관련 논문은 <ins>[이곳](https://en.wikipedia.org/wiki/Consistent_hashing#History)</ins>에서 볼 수 있다.\n\n### consistent hashing\nconsistent hashing은 node의 수에 의존하지 않고 추가/삭제된 node가 있을때 재분산 해야하는 key의 수를 최소화 하기 위한 방법이다. hash ring이라 불리는 추상적인 원 또는 링 형태에 CRC-32(2^32)라고 하는 hash 연산의 결과에 따라 node를 할당하고, 인입되는 key에 대해서 동일한 hash 연산을 통해 어떤 node에 배치할 지 결정해주는 key 분산 처리 방법이다. 코드와 시나리오를 보며 이해 해보자.\n\n```kotlin\ndata class Node(val id: String)\n\nclass ConsistentHash(private val numberOfReplicas: Int, private val nodes: Set<Node>) {\n    private val circle = HashMap<BigInteger, Node>()\n\n    init {\n        for (node in nodes) {\n            add(node)\n        }\n    }\n\n    fun add(node: Node) {\n        for (i in 0 until numberOfReplicas) {\n            val digest = MessageDigest.getInstance(\"MD5\").digest((node.toString() + i).toByteArray())\n            val hash = BigInteger(1, digest).mod(BigInteger.valueOf(2).pow(32))\n            circle[hash] = node\n        }\n    }\n\n    fun remove(node: Node) {\n        for (i in 0 until numberOfReplicas) {\n            val digest = MessageDigest.getInstance(\"MD5\").digest((node.toString() + i).toByteArray())\n            val hash = BigInteger(1, digest).mod(BigInteger.valueOf(2).pow(32))\n            circle.remove(hash)\n        }\n    }\n\n    fun getNode(key: String): Node {\n        if (circle.isEmpty()) return throw BadRequestException(\"circle is empty.\")\n\n        val digest = MessageDigest.getInstance(\"MD5\").digest(key.toByteArray())\n        val hash = BigInteger(1, digest).mod(BigInteger.valueOf(2).pow(32))\n\n        val nodes = circle.keys.sorted()\n        var node = nodes.firstOrNull { it >= hash }\n        if (node == null) node = nodes.first()\n\n        return circle[node]!!\n    }\n}\n\nfun main() {\n    val ch = ConsistentHash(\n        numberOfReplicas = 1,\n        nodes = setOf(\n            Node(\"A\"),\n            Node(\"B\"),\n            Node(\"C\"),\n        )\n    )\n    val nodeOfKey = mutableMapOf<Node, MutableSet<String>>()\n\n    (1..9).forEach {\n        val key = \"key$it\"\n        val node = ch.getNode(key)\n        if (nodeOfKey.containsKey(node)) {\n            nodeOfKey[node]!!.add(key)\n        } else {\n            nodeOfKey[node] = mutableSetOf(key)\n        }\n    }\n\n    val sortedMap = nodeOfKey.toSortedMap(compareBy { it.id })\n    sortedMap.forEach {\n        println(\"${it.key.id}: ${it.value}\")\n    }\n}\n```\n\n* node: 3(nodeA~C)\n* key: 9(key1~9)\n* replica: 1(여기서 1은 별도의 복제 없이 node의 수와 동일함을 뜻함)\n\n![](redis-consistent-hashing-03.png)\n\n```\nnodeA: [key4, key7]\nnodeB: [key1, key2, key5, key8, key9]\nnodeC: [key3, key6]\n```\n코드의 실행결과는 print 값은 위와 같으며, 이를 그림으로 표현한 모습이다. 원리는 간단하다. \n코드에 표현되어 있듯, 입력된  `position = hash (key) mod (2 ^ 32)` 연산에 의해 위치가 결정되며, 이때의 위치는 시계방향 기준으로 가까운 node를 따라가도록 되어있다. \n그리고 hash 값이 가장큰 nodeC의 값을 넘을 경우 첫번째 nodeA를 바라보도록 되어있기 때문에 결국 원형 또는 링의 모습을 띄도록 그릴 수 있는 것이다. \n그렇다면 이번에도 nodeC가 장애 또는 네트워크 이슈로 인해 key의 재분산이 필요하다면 어떠할까?\n\n* node: 2(C는 장애)\n* key: 9\n* replica: 1\n\n![](redis-consistent-hashing-04.png)\n\n```\nnodeA: [key4, key7]\nnodeB: [key1, key2, key3, key5, key6, key8, key9]\n```\n\n결과는 어느정도 예상해볼 수 있다. 시계방향으로 위치할 node가 결정나므로 key3, 6은 자연스럽게 nodeB에 재분산 된 모습이다. \n하지만 결과론적으로 안타깝지만 일반적인 hashing과 같이 nodeA, B는 또다시 불균형을 피하지 못했다. \n그래도 다행이라면 재해싱 및 재분산이 아닌 서버의 추가/장애에 영향을 받는 node의 key만 재분산 하면 된다. 모두 고생할 필요는 없다.\n그렇게 어느정도의 부하는 줄일 수 있었지만 여전히 불균형이 존재한다. 이를 위해 고안된 방법이 바로 가상의 복제 node(vnode)를 배치하는 방법이다.\nreplica의 수를 3으로 설정하여 기존 node들의 가상 복제본을 각각 2쌍 추가하며, 동일한 hash 연산에 따라 replica node를 위치한다.\n\n* node: 2(C는 장애)\n* key: 9\n* replica: 3\n\n![](redis-consistent-hashing-05.png)\n\n```\nnodeA: [key4, key7, key8, key9]\nnodeB: [key1, key2, key3, key5, key6]\n```\n\nreplica node들에 의해 다시 균형이 찾아왔다. print 결과를 보면 제대로 분산 되어 있다. nodeA, B 집군에 복제된 A1~2, B1~2가 각각 hash 결과에 따라 위치하여 원형링에서 분산 node의 역할을 수행하게 된다. \nreplica의 수가 증가하면 node의 간격은 더더욱 촘촘해져, key 분산 배포는 더욱 균일해질 확률이 높다. 그렇다고 무조건 높다고 좋다는 것은 아니다. 이에 대한 설명은 따로 하지 않겠다. (과유불급)\n\n이렇듯 consistent hashing에서는 node의 추가/장애 간에 발생할 수 있는 key 불균형을 가상의 복제본 서버를 도입하는 방법으로 해결할 수 있으며, 이를 통해 cache node 수의 변경에 상관 없이 높은 수준의 히트율과 고가용성을 보장한다. 이는 분산 캐시, 분산 스토리지, 분산 요청 등 다양한 영역에서 사용된다. \nredis 3.0 이후 redis cluster가 도입되면서 `hash slot`에 의해 key를 관리하게 된다. 그렇다면 hash slot은 어떻게 동작할까?\n\n\n## hash slot\nhash slot은 consistent hashing과 비슷한 개념을 redis cluster에서 일컫는 방법이라 생각하면 된다. 하지만 구체적인 구현에는 조금 차이가 있다.\n> HASH_SLOT = CRC16(key) mod 16384\n\nredis cluster는 총 16384개의 key space를 갖고, 이를 위해 16384 mode 연산의 결과로 key를 slot에 할당한다. \nslot의 갯수를 16384로 제한한 이유는 <ins>[이곳](https://github.com/redis/redis/issues/2576#issuecomment-101257195)</ins>에서 설명하고 있으며, 결국 효율적인 key 분산을 위한 설정으로 보인다.\n이에따라 cluster는 최대 1000개의 master node를 갖을 수 있도록 제한하고 있다. 그렇다면 hash slot은 어떻게 node와 key를 관리하는지 확인해보자.\n\n* node(master): 3\n* replica(slave): 1\n\n![](redis-consistent-hashing-06.png)\n\nredis cluster는 node의 갯수에 따라 16384라는 정해진 slot을 node갯수만큼 나누어(N빵) 각 key에 대한 hash연산 결과에 따라 slot에 기록한다. \n예시를 위해 master node는 3개 세팅하였다. 실제로 0~16384의 slot을 가진 하나의 node로 구성해도 무관하다.\n다만 redis cluster에서는 master node에 하나 이상의 slave node를 배치해야한다. 이번에는 replica를 1로 하여 하나의 salve만 구성한다.\n이렇게 redis cluster의 replica를 구성하게 되면 slave node는 자신의 master와 다른 slot에서 각자의 master node를 바라보도록 구성한다.\n\n\n![](redis-consistent-hashing-07.png)\n\n그렇다면 이번에도 node 하나가 장애가 발생하면 어떻게 될까? redis cluster는 서로 node들 간에 통신을 하며 연결되어 있고, 지속적으로 서로의 상태를 살피며 cluster을 관리한다.\n그러므로 장애 발생시 상황을 전파받고, 해당 장애가 발생한 node의 slot을 파악한 후, slave에게 master의 역할을 승격하여 failover 할 수 있도록 구성되어있다.\n이후 해당 node의 조치가 완료되면 다시 원래 상태로 돌아온다. 하지만 장애가 발생한 slot의 master, slave가 모두 장애가 발생한다면 이때는 재기능을 못할 수 있다. 이것은 redis cluster의 failover와 별개로 node를 잘 구성해야하는 문제다.\n이렇듯 redis cluster는 서로간에 통신하며 master/slave 자가복구 기능이 있어 `sentinel`과 같은 HA(high availability) 도구가 필요 없다.\n\n![](redis-consistent-hashing-08.png)\n\n장애난 node가 복구되고, node 한대를 추가한다고 하자. 총 4개의 node가 slot을 할당받은 모습이 그려진다. 이는 node의 slot이 이제 `slot range = 16384 / 4` 의 결과로 재구성할 수 있게 되는것이다.\n그렇다면 기존에 존재한 key는 전부 재분산 처리를 해야하는가? 아니다. 결국 동일한 hash 연산에 mod 16384 이라는 정해진 slot 갯수로 나누기 때문에 이미 slot을 할당 받은 key의 hash값은 변하지 않는다. \n즉 최초에 slot이 1429로 정해진 key는 1번 node에 위치할 것이며, node가 추가되어도 연산 결과가 바뀌지 않아 slot의 위치는 동일하다는 뜻이다.\n그외 추가된 node에 의해 영역의 갭이 생긴 4094개의 slot의 key들만 영향을 받을 수 있다. 이렇게 redis cluster에서는 key의 전체 재분산을 하지 않고 node가 추가 되었을때 최소한의 분산을 지원할 수 있다.\n그리고 slot 전체를 재분산하려면 `reblance` 명령어를 통해 slot간에 key 재분산이 가능하다.\n\n## 결론\n구체적인 구현 방식에서 차이는 조금 있지만 redis cluster의 hash slot과 consistent hashing은 둘 다 key-value 쌍을 관리하는 분산 캐시 시스템에서 사용되는 hashing 기법이다. \n> 결국 분산 캐시 시스템에서의 핵심은 hash. 적절한 hash function을 통한 연산 결과 값을 어떻게 다루느냐 성능과 가용성을 좌우한다.\n\n\n##\n***\n###\n* <https://severalnines.com/blog/hash-slot-vs-consistent-hashing-redis/>\n* <https://en.wikipedia.org/wiki/Consistent_hashing#History>"},{"excerpt":"shard \nshard는 mysql과 같은 RDB를 기준으로 partition과 같은 의미로, 데이터를 저장할 때 나누어진 조각 단위라고 생각하면 된다. 즉 shard의 데이터는 복사본이 아닌 저장한 데이터 그 자체이다. elasticsearch에서는 충분히 크기가 큰 데이터를 가진 index의 데이터를 특정한 파티션 단위로 나누며, 이를 shard라고 …","fields":{"slug":"/elasticsearch-shard-replica/"},"frontmatter":{"date":"January 29, 2023","title":"elasticsearch shard, replica 값은 어떻게 설정할까?","tags":["elasticsearch","shard","replica"],"series":"elasticsearch"},"rawMarkdownBody":"\n\n## shard\n![](elasticsearch-shard-replica-02.png )\nshard는 mysql과 같은 RDB를 기준으로 partition과 같은 의미로, 데이터를 저장할 때 나누어진 조각 단위라고 생각하면 된다. 즉 shard의 데이터는 복사본이 아닌 저장한 데이터 그 자체이다. elasticsearch에서는 충분히 크기가 큰 데이터를 가진 index의 데이터를 특정한 파티션 단위로 나누며, 이를 shard라고 부른다. 각 document 문서는 해당 문서의 hash 값을 통해 계산된 shard로 라우팅 된다. 그리고 일반적으로 `shard`라고 하는 것이 primary shard를 뜻한다. 복사되지 않은 CRUD의 주체가 되는 실제 원본 데이터를 뜻한다.\n\n### shard 값 설정\nshard 하나의 크기는 일반적으로 최대 50GB이하, 통상적으로 20~40GB 정도 선을 유지하기를 권고하고 있다. 이는 elasticsearch 공식 문서에서 가이드한 값이기도 하며 통상적으로 많은 개발자들이 검증을 한 값이므로 신뢰도가 높다. 하지만 무엇이든 본인의 상황에 맞게 대입하면 된다. 적은량의 데이터를 핸들링할 경우 최소 2개 이상의 node에 shard를 1대만 두고 replica만 세팅해도 상관은 없는 것이다. 다만 primary shard를 결정하는 shard의 값만 많이 설정하고, replica를 적절히 설정하지 않으면 장애발생에 대한 fail-over에 대응이 불가할 수 있으며, 각 node별 검색성능에 좋지않을 수 있다. 그렇다면 replica shard의 갯수를 결정하는 replica 값은 어떻게 설정하고, 어떠한 역할을 하는 것일까?\n\n## replica\n![](elasticsearch-shard-replica-03.png )\nreplica를 한 마디로 정의하면 `shard의 복제된 갯수` 로 정의 할 수 있다. 만약 primary shard가 3일때, replica를 2로 설정하면 replica shard의 갯수는 6개로, 총 9개의 shard가 존재한다는 뜻이다. 이때 replica shard는 절대 primary shard와 동일한 데이터를 갖도록 node 내에서 존재 할 수 없다. 그래서 위 그림 처럼 초록색의 primary shard와 다른 번호로 주황색의 replica shard들이 각 node에 배치된 모습을 볼 수 있다.\n\nreplica shard는 각 node에 분산된 primary shard의 복제 역할을 함으로써 두가지 장점의 기능을 갖게 된다. 먼저 특정 node로부터 온 요청사항을 다른 node에 찾는 번거로움 없이 primary shard와 함께 온전히 지원할 수 있음으로써 검색성능 향상(search performance)을 기대할 수 있다. 그리고 node 자체에 장애가 발생하더라도 서비스에는 문제 없도록 장애복구(fail-over) 역할을 할 수 있다. 위 그림에도 node 1~3중 하나가 문제 생기더라도 primary, replica shard 관계없이 각각의 node의 shard가 전체 데이터인 0~2번까지 모두 서비스 될 수 있기 때문이다. 만약 위 상황에서 3개의 node중 2개가 모두 장애가 발생한다면 자연스럽게 남은 하나의 node에 있는 replica shard들이 모든 primary shard의 역할을 하는것이다. \n\n### replica 값 설정\n위 내용을 유추해보면 node는 결국 최소 2개는 있어야 하나의 node가 장애가 났을때 최소한의 fail-over이 가능하며, 이때 replica는 최소 1이상 설정해야 primary shard의 역할을 대신 할 수 있다.\n즉 replica 값은 아래와 같이 정리할 수 있다. 물론 디테일한 설정은 서비스 운용 상황에 따라 모두 다르다.\n> replica의 최소 값은 1, 최대 값은 전체 node 갯수 - 1\n\nreplica 수가 많다고 무조건 좋은건 아니다. replica가 많아질 수록 색인 성능은 떨어지고, 읽기 성능은 좋아진다. 복제된 공간만큼 데이터 정보를 채워 넣어야하니 색인(indexing)성능은 자연스럽게 떨어지며, 특정 node에 온 요청을 해당 node의 shard에서 모두 처리 가능하게 설정함으로써 읽기 검색성능 향상을 기대할 수 있다.\n\n## 실제 설정 예시\n그렇다면 실제 적용한 예시(index, ip, node는 임의로 변경) 상황을 보자. shard 수를 몇개씩 설정할 정도로 꼭 수십기가의 데이터를 저장한 예시가 아닌, 정말 작은 데이터에서도 elasticsearch를 활용하기 위해 색인을 한 경우다.\n\n```\nGET _cat/shards/index-v2?pretty&v\n```\n간단한 shard 상태를 조회하는 qeury를 통해 현재 샤드의 상태 및 정보들을 알 수 있다. \n\n```\nindex    shard prirep state   docs  store  ip       node\nindex-v2 0     p      STARTED 24008   25mb x.x.x.x  node1\nindex-v2 0     r      STARTED 24008 25.1mb x.x.x.x  node3\nindex-v2 0     r      STARTED 24008   25mb x.x.x.x  node10\nindex-v2 0     r      STARTED 24008   25mb x.x.x.x  node6\nindex-v2 0     r      STARTED 24008   25mb x.x.x.x  node4\nindex-v2 0     r      STARTED 24008 24.9mb x.x.x.x  node9\nindex-v2 0     r      STARTED 24008 25.1mb x.x.x.x  node7\nindex-v2 0     r      STARTED 24008 25.1mb x.x.x.x  node5\nindex-v2 0     r      STARTED 24008 25.2mb x.x.x.x  node8\nindex-v2 0     r      STARTED 24008 25.1mb x.x.x.x  node2\n```\n\n결과로 나온 `index-v2` index의 shard에 대한 현재 스펙은 아래와 같다. \n* node: 10개\n* shard(primary): 1\n* replica: 9\n* doument: 24,008개\n* store(avg): 25mb\n\n공식 문서나 블로그에 예시로 많이 설명되는 정보와 다르게 매우 작은 2만5천개의 문서인 25메가바이트 정보로도 elasticsearch의 장점을 활용하기 위해 index를 만들어 활용하고 있다. shard의 갯수가 1인것은 당연한 이유이다. 용량이 매우 적기 때문이다. 그렇다면 replica 수는 왜 9개나 되는것일까? 사실 이보다 적어도 상관 없다. 다만 현재 운용중인 node의 갯수가 10개이며, primary shard를 제외하고 남는 node에 모두 검색성능 향상을 위해 replica를 두고 싶은 이유이다. \n\n![](elasticsearch-shard-replica-04.png )\n\n그림으로 보면 이런 느낌이 아닐까 싶다. 되게 어색해 보일 수 있지만 현재 운용중인 10개의 node를 최대한 활용하여 검색성능은 최대로 끌어올릴 수 있다. 또한 primary shard가 자리잡은 node1이 장애가 발생하더라도 나머지 9개의 node들이 replica shard에 의해 primary shard 역할을 할 수 있는 형태이다. 그렇다면 위에서 언급한대로 replica의 수가 너무 많으면 색인 속도가 늦어질 수 있지 않는가? 그럴순 있다. 하지만 이 또한 서비스 운용에 따라 선택하면 된다. 해당 서비스의 index 색인은 빈번하게 일어나지 않는 도메인이기 때문이다. 그저 색인 성능에 상관없이 검색성능과 운영 관점에 초점을 맞추어 replica 갯수를 설정했기 때문이다.\n\n\n\n## 결론\nshard와 replica는 운영 관점에서 매우 중요한 역할을 한다. 어떻게 값을 설정하느냐에 따라 검색속도나 운영에서 미치는 영향이 매우크다. 그래서 elasticsearch의 shard와 replica 값을 설정함에 있어서 정리하자면 아래와 같다.\n>어느정도 가이드된 범위 내에서 서비스 도메인 별로 검색성능과 fail-over 관점을 잘 고려하여 각자 운영에 맞는 입맛대로 설정하면 된다.\n\n##\n***\n###\n* <https://aws.amazon.com/ko/blogs/database/get-started-with-amazon-elasticsearch-service-how-many-shards-do-i-need/>\n* <https://brunch.co.kr/@alden/39>\n* <https://fdv.gitbooks.io/elasticsearch-cluster-design-the-definitive-guide/content/a-few-things-you-need-to-know-about-lucene.html>\n* <https://esbook.kimjmin.net/03-cluster/3.2-index-and-shards>\n\n\n"},{"excerpt":"Data class java의 lombok도 편하지만 kotlin data class는 기본적인 메소드들을 만들기 진짜 세상 편하다. 하지만 상속을 할때에는 꼭 유의해야하는 사항이 있다. 차근차근 알아보자. hash code 먼저 data class를 선언 했을때 컴파일러가 만들어주는 hash code 메소드를 살펴보자. 간단한  객체를 만들었다. 그리고…","fields":{"slug":"/kotlin-data-class/"},"frontmatter":{"date":"January 28, 2023","title":"kotlin data class 상속","tags":["kotlin"],"series":"kotlin"},"rawMarkdownBody":"\n## Data class\njava의 lombok도 편하지만 kotlin data class는 기본적인 메소드들을 만들기 진짜 세상 편하다. 하지만 상속을 할때에는 꼭 유의해야하는 사항이 있다. 차근차근 알아보자.\n\n### hash code\n먼저 data class를 선언 했을때 컴파일러가 만들어주는 hash code 메소드를 살펴보자. 간단한 `Person` 객체를 만들었다. 그리고 java 코드로 decompile하여 `hashCode()`만 가져왔다.\n\n`kotlin`\n```kotlin\ndata class DataClassPerson(\n    val name: String,\n    val age: Int,\n    val phone: String\n)\n```\n\n`java`\n```java\npublic int hashCode() {\n    String var10000 = this.name;\n    int var1 = ((var10000 != null ? var10000.hashCode() : 0) * 31 + Integer.hashCode(this.age)) * 31;\n    String var10001 = this.phone;\n    return var1 + (var10001 != null ? var10001.hashCode() : 0);\n}\n```\n\n`hashCode()`를 살펴보면 단순히 정의된 변수의 값으로만 hash값을 만들고 있다. 즉 선언된 객체의 변수값들이 같으면 같은 hashcode를 갖는다는 것이다. 바로 한번 확인해보자.\n\n`kotlin`\n```kotlin\nfun main() {\n    val a = DataClassPerson(\"A\", 30, \"010-1234-5678\")\n    val a1 = DataClassPerson(\"A\", 30, \"010-1234-5678\")\n    val b = DataClassPerson(\"B\", 30, \"010-1234-5678\")\n\n    println(a.hashCode() == a1.hashCode())\n    println(a.hashCode() == b.hashCode())\n}\n```\n\n```\ntrue\nfalse\n```\n\n예상대로 위 경우 a, a1에 대해 객체의 값이 모두 같으므로 hash code 비교결과가 `true`로 나온다. 또한 a, b에 대해 name값이 다르므로 hash code 비교 결과가 `false`이다. 단순히 변수값만 비교한 값이므로 당연한 결과이다. 그렇다면 data class가 아닌 일반 class는 어떨까?\n\n`kotlin`\n```kotlin\nclass NormalClassPerson(\n    val name: String,\n    val age: Int,\n    val phone: String\n)\n\nfun main() {\n    val a = NormalClassPerson(\"A\", 30, \"010-1234-5678\")\n    val a1 = NormalClassPerson(\"A\", 30, \"010-1234-5678\")\n\n    println(a.hashCode() == a1.hashCode())\n}\n```\n```\nfalse\n```\na, a1은 hashcode가 같지 않다는 `false` 결과를 바로 확인 할 수 있다.\n\n## Data class 상속\ndata class의 부모객체(SuperClass)를 하나 설정해보자. \n\n`kotlin`\n```kotlin\ndata class SuperClass(\n    val superData: String = \"\"\n)\n\ndata class DataClassPerson(\n    val name: String,\n    val age: Int,\n    val phone: String,\n): SuperClass()\n```\n\n일단 위 코드는 컴파일 되지 않는다. data class끼리 상속하거나 받을순 없다. 이유는 간단하다. \n* decompile java 코드를 보면 data class는 기본적으로 `final` 클래스로 정의 되어있기에 상속을 막아뒀다.\n* 만약 억지로 상속한다 해도 data class에서 만들어주는 기본 메소드들을 부모와 자식것 중 어떤걸로 선택해야할지 정의할 수 없을 것이다. 그렇다고 강제로 어느것으로 정의하기에도 좀...\n\n그래서 애초에 막아뒀다고 생각한다. 그렇다면 부모 객체 및 변수에 상속 가능한 `open` 키워드를 붙이고, `hashCode()` 까지 재정의하여 data class에 상속을 해보자.\n\n`kotlin`\n```kotlin\nopen class SuperClass(\n    open var superData: String = \"\"\n) {\n    override fun hashCode(): Int {\n        return 1\n    }\n}\n\ndata class DataClassPerson(\n    val name: String,\n    val age: Int,\n    val phone: String,\n): SuperClass()\n\nfun main() {\n    val a = DataClassPerson(\"A\", 30, \"010-1234-5678\")\n    val a1 = DataClassPerson(\"A\", 30, \"010-1234-5678\").apply { superData = \"super\" }\n\n    println(a.hashCode() == a1.hashCode())\n}\n```\n```\ntrue\n```\na1에 상속받은 클래스의 `superData` 값을 변경했지만 a, a1의 hashCode는 같다. 이유는 간단하다. kotlin에서는 상속을 받을 때 이미 자식 객체에서 기본 메소드가 정의 되어있다면 이는 재정의 하지 않기 때문이다. 그래서 a, a1은 `DataClassPerson`에 정의된 변수만 가지고 hashcode 값을 정의한다. 그렇다면 상속받은 두 객체 a, a1의 hashcode는 어떻게 구분할 수 있는가? 답은 간단하다. 상속은 상속답게 `override`로 부모 변수를 받아서 재정의 하면 된다.\n\n`kotlin`\n```kotlin\ndata class DataClassPerson(\n    val name: String,\n    val age: Int,\n    val phone: String,\n    override var superData: String = \"\"\n): SuperClass()\n\nfun main() {\n    val a = DataClassPerson(\"A\", 30, \"010-1234-5678\")\n    val a1 = DataClassPerson(\"A\", 30, \"010-1234-5678\").apply { superData = \"super\" }\n\n    println(a.hashCode() == a1.hashCode())\n}\n```\n```\nfalse\n```\n\n## 결론\njava, kotlin 할 것 없이 상속은 간단하고 자주 사용되는 기본적인 문법이지만, 항상 주의를 기울여야한다. 그래서 kotlin 상속시 다음 유의 사항들은 살펴보면 좋을것 같다.\n> 상속한 객체의 변수는 가능한 override 해서 사용할것.<br>\n> 반드시 부모객체의 정보를 받아야는게 아니라면, 상속이 아닌 interface를 활용하여 재정의 할것."},{"excerpt":"inline kotlin 함수에 붙는  키워드는 말 그대로 호출되는 특정 코드 line 사이에 특정 inline 키워드가 붙은 함수의 코드를 넣을(in) 수 있도록 지원하는 키워드이다.\n 키워드는 객체(클래스)와 함수 레벨에서 사용할 수 있다. 예시는 객체 레벨이 아닌 함수 레벨에서 설명한다. inline 함수 간단하게 아래 코드로 살펴보자. 아주 inl…","fields":{"slug":"/kotlin-inline/"},"frontmatter":{"date":"January 23, 2023","title":"kotlin inline 알아보기","tags":["kotlin","java","inline"],"series":"kotlin"},"rawMarkdownBody":"\n\n## inline\nkotlin 함수에 붙는 `inline` 키워드는 말 그대로 호출되는 특정 코드 line 사이에 특정 inline 키워드가 붙은 함수의 코드를 넣을(in) 수 있도록 지원하는 키워드이다.\n`inline` 키워드는 객체(클래스)와 함수 레벨에서 사용할 수 있다. 예시는 객체 레벨이 아닌 함수 레벨에서 설명한다.\n\n### inline 함수\n\n간단하게 아래 코드로 살펴보자. 아주 inline이 붙은 코드를 호출한 위치에 넣어주는 단순 역할 그 잡채이다.\n\n\n`Kotlin`\n```kotlin\nfun main(args: Array<String>) {\n    println(\"print1\")\n    print2and3()\n    println(\"print4\")\n    print5 { \"print5\" }\n}\n\nfun print2and3() {\n    println(\"print2\")\n    println(\"print3\")\n}\n\nfun print5(lambda: () -> String) {\n    println(lambda.invoke())\n}\n```\n\n`Java`\n```java\npublic static final void main() {\n    String var0 = \"print1\";\n    System.out.println(var0);\n    print2and3();\n    var0 = \"print4\";\n    System.out.println(var0);\n    int $i$f$print5 = false;\n    String var1 = \"print5\";\n    System.out.println(var1);\n}\n\npublic static void main(String[] var0) {\n    main();\n}\n\npublic static final void print2and3() {\n    String var0 = \"print2\";\n    System.out.println(var0);\n    var0 = \"print3\";\n    System.out.println(var0);\n}\n\npublic static final void print5() {\n    int $i$f$print5 = 0;\n    String var1 = \"print5\";\n    System.out.println(var1);\n}\n```\n\n```\nprint1\nprint2\nprint3\nprint4\nprint5\n```\n\nkotlin 코드에는 2개의 print는 직접 처리하며, 2개의 print는 함수를 호출해서 출력되는 것으로 보인다. 하지만 이를 java 코드로 변환한 결과를 보면 다소 충격적이다. 실제로 `print5` 함수는 선언만 되어 있을뿐 호출하지 않는다. 내가 만든 함수가 호출되지 않다니! 하지만 해당 함수에 있는 모든 코드가 main문 안에 그대로 들어가 있는 모습이 보인다. 이것이 `inline` 키워드의 역할이다. 그렇다면 이렇게 본래 함수와 호출부에 들어간 코드까지, 코드량을 2배로 만들게 하는 `inline` 키워드가 왜 필요할까?\n\n### inline 고차함수\n\n위 예제의 `print5` 함수의 파라미터만 lambda 고차함수로 바꿔보자.\n\n`Kotlin`\n```kotlin\nfun main(args: ArrayList<String>) {\n    println(\"print1\")\n    print2and3()\n    println(\"print4\")\n    print5 { \"print5\" }\n}\n\nfun print2and3() {\n    println(\"print2\")\n    println(\"print3\")\n}\n\nfun print5(lambda: () -> String) {\n    println(lambda.invoke())\n}\n```\n\n`Java`\n```java\npublic static final void main(@NotNull ArrayList args) {\n    Intrinsics.checkNotNullParameter(args, \"args\");\n    String var1 = \"print1\";\n    System.out.println(var1);\n    print2and3();\n    var1 = \"print4\";\n    System.out.println(var1);\n    print5((Function0)null.INSTANCE);\n}\n\npublic static final void print2and3() {\n    String var0 = \"print2\";\n    System.out.println(var0);\n    var0 = \"print3\";\n    System.out.println(var0);\n}\n\npublic static final void print5(@NotNull Function0 lambda) {\n    Intrinsics.checkNotNullParameter(lambda, \"lambda\");\n    Object var1 = lambda.invoke();\n    System.out.println(var1);\n}\n```\n\njava의 main 함수에서 `print5` 함수를 호출하는 부분을 보면 `(Function0)null.INSTANCE` 부분이 있다. 새로운 Function 익명 클래스 객체를 생성하는 것이다. 즉, 불필요한 객체생성 및 메모리 낭비를 초래할 수 있다는 것이다. `print5` 함수에 inline 키워드만 붙인 java 코드는 아래와 같다.\n\n`Kotlin`\n```kotlin\ninline fun print5(lambda: () -> String) {\n    println(lambda.invoke())\n}\n```\n\n`Java`\n```java\npublic static final void main(@NotNull ArrayList args) {\n    Intrinsics.checkNotNullParameter(args, \"args\");\n    String var1 = \"print1\";\n    System.out.println(var1);\n    print2and3();\n    var1 = \"print4\";\n    System.out.println(var1);\n    int $i$f$print5 = false;\n    int var2 = false;\n    String var4 = \"print5\";\n    System.out.println(var4);\n}\n\npublic static final void print2and3() {\n    String var0 = \"print2\";\n    System.out.println(var0);\n    var0 = \"print3\";\n    System.out.println(var0);\n}\n\npublic static final void print5(@NotNull Function0 lambda) {\n    int $i$f$print5 = 0;\n    Intrinsics.checkNotNullParameter(lambda, \"lambda\");\n    Object var2 = lambda.invoke();\n    System.out.println(var2);\n}\n```\n\n별도의 익명클래스 생성 없이 `print5` 함수 내 로직들이 main안으로 inline 되어있는 모습이다. 이로써 경우 inline 키워드가 주는 장점을 확인 할 수 있었다.\n\n## noinline\n`noinline` 키워드는 `inline` 키워드가 붙어 있는 객체 또는 함수 내에 파라미터 레벨에서 특정 파라미터에 `inline`을 적용하지 않고 싶을때 사용한다. 고차함수를 파라미터로 2개 받는 `print5and6` 함수를 만들었고, 이때 첫번째 파라미터에는 `noinline` 키워드를 붙이고 java 코드로 변경해보았다.\n\n`Kotlin`\n```kotlin\nfun main(args: Array<String>) {\n    println(\"print1\")\n    print2and3()\n    println(\"print4\")\n    print5and6({ \"print5\" }, { \"print6\" })\n}\n\nfun print2and3() {\n    println(\"print2\")\n    println(\"print3\")\n}\n\ninline fun print5and6(noinline lambda: () -> String, lambda2: () -> String) {\n    println(lambda.invoke())\n    println(lambda2.invoke())\n}\n```\n\n`Java`\n```java\npublic static final void main(@NotNull String[] args) {\n    Intrinsics.checkNotNullParameter(args, \"args\");\n    String var1 = \"print1\";\n    System.out.println(var1);\n    print2and3();\n    var1 = \"print4\";\n    System.out.println(var1);\n    Function0 lambda$iv = (Function0)null.INSTANCE;\n    int $i$f$print5and6 = false;\n    Object var3 = lambda$iv.invoke();\n    System.out.println(var3);\n    int var4 = false;\n    String var6 = \"print6\";\n    System.out.println(var6);\n}\n\npublic static final void print2and3() {\n    String var0 = \"print2\";\n    System.out.println(var0);\n    var0 = \"print3\";\n    System.out.println(var0);\n}\n\npublic static final void print5and6(@NotNull Function0 lambda, @NotNull Function0 lambda2) {\n    int $i$f$print5and6 = 0;\n    Intrinsics.checkNotNullParameter(lambda, \"lambda\");\n    Intrinsics.checkNotNullParameter(lambda2, \"lambda2\");\n    Object var3 = lambda.invoke();\n    System.out.println(var3);\n    var3 = lambda2.invoke();\n    System.out.println(var3);\n}\n```\n\njava 코드의 결과를 보면 `noinline`을 적용한 첫번째 고차함수는 익명클래스를 생성하고 있고, 변수에 별도 키워드 없는 두번째 파라미터는 `inline`이 적용된 모습을 볼수 있다.\n\n## 결론\n모든 함수는 `inline`으로 처리하는게 좋을까? 당연히 정답은 X이다. `inline` 키워드에 대해 정리해보자.\n\n`inline` 키워드는 고차함수를 파라미터로 받게되어, 불필요한 익명 클래스 생성을 막을 수 있도록 처리할 때 사용하면 좋다는 것을 알았다. 사실 이또한 객체 하나를 생성하는 비용보다 해당 고차함수를 파라미터로 받은 함수 자체의 로직이 크다면 의미가 없다. 왜냐면 `inline` 키워드가 붙은 함수의 코드를 옮겨오기 때문에 코드량이 2배가 되어 처리해야할 byte량이 많아진다. \n\n결국 아래와 같은 타겟에 `inline` 키워드를 적용 하는게 가장 효과적이라 할 수 있다.\n> 고차함수를 파라미터로 받는 적은량의 코드를 가진 함수\n\n##\n***\n###\n* <https://amitshekhar.me/blog/inline-function-in-kotlin>"},{"excerpt":"Kotlin의 매력 포인트 Null Safe 필요성에 대해서는 두말하면 잔소리다. null에 대한 지원만으로도 너무 행복하다.  java는 null에 취약하며, 언제 어느순간에 NullPointerException이 발생할지 예측할 수 없다. 그래서 늘 null과의 싸움을 하게된다. 떄로는 비즈니스 로직보다 null 체크 로직이 더 많을때도 있다. 물론 …","fields":{"slug":"/kotlin-vs-java/"},"frontmatter":{"date":"January 16, 2023","title":"java로 되돌아갈 수 없는 kotlin의 매력","tags":["kotlin","java"],"series":"kotlin"},"rawMarkdownBody":"\n\n## Kotlin의 매력 포인트\n\n### Null Safe\n필요성에 대해서는 두말하면 잔소리다. null에 대한 지원만으로도 너무 행복하다. \n\njava는 null에 취약하며, 언제 어느순간에 NullPointerException이 발생할지 예측할 수 없다. 그래서 늘 null과의 싸움을 하게된다. 떄로는 비즈니스 로직보다 null 체크 로직이 더 많을때도 있다. 물론 java8 이후에는 Optional을 활용하여 null safe하게 개발 할 수 있지만 불필요한 코드량과 가독성 측면에서는 여전히 아쉬운게 많다.\n\nkotlin은 기본적으로 모든 변수가 null을 허용하지 않는다. non-null 변수에 null을 할당하려하면 컴파일 단계에서 실패한다. 필요에 따라 null이 필요할땐 `?` 키워드로 nullable을 표현할 수 있다. 또한 타입 추론을 지원하기 때문에 별도의 타입 정의 없이 nullable 변수를  컴파일 시점에서 체크할 수 있다. 추가적으로 ``` if null else ... ``` 을 한번에 표현할 수 있는 `let` 스코프 함수와 null이 아닐때를 표현하는 `?:` 엘비스 연산자(엘비스 프레슬리 헤어스타일을 닮아서...)를 함께 활용하면 더욱 간결하고 null safe하게 개발이 가능하다.\n\n`Kotlin`\n```kt\nfun nonNullReturnFunction(): Int {\n    val num = 1\n    val numOfNullable = nullReturnFunction()\n\n    return numOfNullable?.let { it + num } ?: 0\n}\n\nfun nullReturnFunction(): Int? {\n    val list = listOf(1, 2, 3, 4)\n    return list.firstOrNull { it < 1 }\n}\n```\n\n### Extention\n공통적으로 사용되는 범용성 코드를 잘 만들었을때 뽕맛은 개발자라면 공감할 듯하다.\n\nkotlin에서는 extention 확장함수를 지원한다. 어떤 클래스에 함수를 추가하는 기능이며, extention을 붙여놓은 객체에서 내가 만든 메소드를 사용할 수 있기에 마치 라이브러리를 만든 느낌을 받을 수 있다. json를 다루거나, 자주쓰이는 String 기능을 만들거나 등 불필요한 코드 또는 공통의 기능을 만들때 사용하면 좋다. 좋은 기능이나 자유도가 높기에 무차별하게 사용하면 욕먹기 딱 좋을 수 있다. 특정 클래스에서만 사용하거나 특정 컬렉션에서만 사용하는 등 개인적인 이유로 사용하기에는 일반 비즈니스 함수로 명확하게 개발하는것을 추천한다.\n\n`Java`\n```java\npublic static int firstPlusNum(Collection<Integer> collection, int num) {\n    return collection.stream().findFirst().get() + num;\n}\n\npublic static void main(String[] args) {\n    List<Integer> list = Arrays.asList(1, 2, 3, 4);\n    int result = firstPlusNum(list, 100);\n    System.out.println(result); // 101\n}\n```\n\n아래 kotlin 코드를 java 코드로 변환하면 위와 같다. extention은 결국 static 메소드를 생성한다. static 메소드는 GC의 대상이 되지 못하고 어플리케이션이 기동되는 동안에는 메모리에 남아있다. 결국 무분별하게 extention을 사용할 경우 결국 메모리 낭비를 초래할 것이다. 역시 뭐든 적절하게 필요에 따라 사용하는 것이 건강에 좋다.\n\n`Kotlin`\n```kotlin\nfun List<Int>.firstPlusNum(num: Int): Int {\n    return this.first() + num\n}\n\nfun main() {\n    val list = listOf(1, 2, 3, 4)\n    val result = list.firstPlusNum(100)\n    println(result) // 101\n}\n```\n\nkotlin에서는 특정 Object 하위의 모든 클래스에는 extention이 적용가능하다. 예시로는 Int타입 List의 첫번째 element에 파라미터로 받은 num값을 더해서 반환하도록 작성했으며, 마치 Collection에서 지원하는 메소드인것 처럼 보여지고 있다. 코드를 읽는 입장에서 심신이 편-안하다. 물론 실무에서 특정 컬렉션 구현체에 제너럴하지 못한 타입으로 extention을 만들어 사용하는 일은 드물다. 예제 코드 정도로만 생각했으면 좋겠다.\n\n\n### Checked Exception\n왜지? 라고 의문을 들 수 있는 kotlin의 특징이 있다. checked exception을 지원하지 않는 것이다. 하지만 이유가 납득된다면 이를 kotlin을 선택한 이유로 꼽을 수 있다. \n\n`Java`\n```java\ntry {\n    Thread.sleep(1000);\n} catch (InterruptedException e) {\n    throw new RuntimeException(e);\n}\n```\n\n`Kotlin`\n```kotlin\nThread.sleep(1000)\n```\n\nkotlin에서는 Thread에 대한 처리에 대해 묻지도 따지지도 않고 실행 가능하다.\n\n\njava에서는 `Thread.sleep(1000);` 까지만 입력하면 sleep에 redline과 함께 컴파일 에러가 발생한다. java는 Thread를 핸들링하거나 Databse, File, Stream 등 IO에 관련된 영역이나 그외 다방면으로 checked exception을 컴파일 단계에서 처리하도록 강제화한다. 하지만 코틀린은 이를 과감하게 포기했다. 이유는 아래와 같다.\n* checked exception은 비즈니스 로직을 매우 지저분하게 만든다.\n* exception을 강제화 해도 대부분의 개발자는 유의미한 exeption 핸들링을 하지않는다.\n\n어찌보면 발생할 수 있는 exception 위험에 열려있는것 같아 보인다. 무의미하게 throw 처리를 해놓을바엔 필요에따라 적절한 exception 처리를 유도한 것이다. 불필요한 checked exeption을 제거함으로써 얻은 가독성 효과는 확실하다. 다만 java를 사용해보지 않고 kotlin로 입문한 개발자는 어떠한 구문에서 checked exception이 발생될 수 있는지 조차 모를 수 있겠다. 같이 협업하면 조금 난감할지도...\n\n### Coroutines\n비동기 처리가 제일 쉬웠어요. (위험할 소리..😇)\n\ncorutine은 비동기 처리를 굉장히 쉽게 처리 할 수 있도록 지원하는 kotlin 라이브러리다. java에서는 Thread, Callable, Runnable, CompletableFuture 등 다양하게 비동기 개발 방법이 있지만, 예시에서는 CompletableFuture과 비교한다. 비동기 처리시 함께 고민해야할 자원 관리, 동시성 제어, 트랜잭션 처리 등의 내용은 다루지 않는다. just corutine의 편리함만 다룬다.\n\n\n`Java`\n```java\nclass Pizza {\n    final String name;\n    final int minute;\n\n    public Pizza(String name, int minute) {\n        this.name = name;\n        this.minute = minute;\n    }\n\n    public Pizza makePizza() {\n        try {\n            Thread.sleep(this.minute); // make pizza time\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n        System.out.println(this.name + \"를 \" + this.minute + \"분만에 완성했습니다.\");\n\n        return this;\n    }\n}\n\npublic class AsyncTest {\n    public static void makePizzaAsync(List<Pizza> pizzas) {\n        List<CompletableFuture<Pizza>> futures = pizzas.stream()\n                .map(pizza -> CompletableFuture.supplyAsync(() -> pizza.makePizza()))\n                .collect(Collectors.toList());\n\n        futures.stream()\n                .map(CompletableFuture::join)\n                .collect(Collectors.toList());\n    }\n\n    public static void main(String[] args) {\n        final List<Pizza> pizzas = Arrays.asList(\n                new Pizza(\"페퍼로니 피자\", 10),\n                new Pizza(\"불고기 피자\", 40),\n                new Pizza(\"하와이언 피자\", 30),\n                new Pizza(\"콰트로치즈 피자\", 20)\n        );\n\n        makePizzaAsync(pizzas);\n    }\n}\n```\n\n\n`Kotlin`\n```kotlin\nfun main() {\n    val pizzas = listOf(\n        Pizza(\"페퍼로니 피자\", 10),\n        Pizza(\"불고기 피자\", 40),\n        Pizza(\"하와이언 피자\", 30),\n        Pizza(\"콰트로치즈 피자\", 20)\n    )\n\n    makePizzaAsync(pizzas)\n}\n\nfun makePizzaAsync(pizzas: List<Pizza>) {\n    runBlocking(Dispatchers.IO) {\n        val defer = pizzas.map {async { it.makePizza() }}\n        defer.awaitAll()\n    }\n}\n\ndata class Pizza(\n    val name: String,\n    val minute: Int\n) {\n    fun makePizza(): Pizza {\n        Thread.sleep(this.minute.toLong())\n        println(this.name + \"를 \" + this.minute + \"분만에 완성했습니다.\");\n        return this\n    }\n}\n```\n\n```\n페퍼로니 피자를 10분만에 완성했습니다.\n콰트로치즈 피자를 20분만에 완성했습니다.\n하와이언 피자를 30분만에 완성했습니다.\n불고기 피자를 40분만에 완성했습니다.\n```\n\n두 언어 모두 결과는 위와같이 로직상 Thread sleep time 순으로 동일하게 프린트된다. main 메소드나 Pizza 객체부를 제외하고 `makePizzaAsync` 메소드를 보면 비동기 처리를 얼마나 간편하게 처리할 수 있는지 알 수 있다.\n\n### Smart Casts\n\n이젠 스마트폰 없이 안되는 세상, 캐스팅도 스마트 캐스팅 시대. 코드의 `ability` 메소드를 보면 바로 직감할 것이다.\n\n`Java`\n```java\ninterface Animal { String getName(); }\n\nclass Dog implements Animal {\n    private final String name;\n\n    Dog(String name) {this.name = name;}\n\n    @Override\n    public String getName() {return this.name;}\n    public String running() {return \"달려요.\";}\n}\n\nclass Bird implements Animal {\n    private final String name;\n\n    Bird(String name) {this.name = name;}\n\n    @Override\n    public String getName() {return this.name;}\n    public String flying() {return \"날아요.\";}\n}\n\npublic class SmartCastTest {\n    public static void main(String[] args) {\n        Dog dog = new Dog(\"개\");\n        Bird bird = new Bird(\"새\");\n\n        List<Animal> animals = Arrays.asList(dog, bird);\n        animals.forEach(animal -> {\n            System.out.println(animal.getName() + \"는 \" + ability(animal));\n        });\n    }\n\n    public static String ability(Animal animal) {\n        if (animal instanceof Dog) {\n            Dog dog = (Dog)animal;\n            return dog.running();\n        }\n\n        if (animal instanceof Bird) {\n            Bird dog = (Bird)animal;\n            return dog.flying();\n        }\n\n        throw new RuntimeException(\"동물이 아닙니다.\");\n    }\n}\n```\n\n`Kotlin`\n```kotlin\ninterface Animal { val name: String }\nclass Dog(override val name: String) : Animal { fun running(): String = \"달려요.\" }\nclass Bird(override val name: String) : Animal { fun flying(): String = \"날아요.\" }\n\nfun ability(animal: Animal): String {\n    return when (animal) {\n        is Dog -> animal.running()\n        is Bird -> animal.flying()\n        else -> throw RuntimeException(\"동물을 입력하세요.\")\n    }\n}\n\nfun main() {\n    val dog = Dog(\"개\")\n    val bird = Bird(\"새\")\n\n    val animals = listOf(dog, bird)\n    animals.forEach {\n        println(\"${it.name}는 ${ability(it)}\")\n    }\n}\n```\n\njava는 `instanceof` 이후에도 직접 Animal의 구현체로 down casting 해줘야한다. 하지만 kotlin은 `is` 키워드와 함께 캐스팅된 결과를 받고, 이를 바로 사용할 수 있다. 타입 체크와 변환까지 한번에 지원되는 기능이며 `is` 라는 키워드 자체가 가독성 측면에서도 너무 직관적이고 명확하다. 코드길이 차이는 두말할 것 없다.\n\n### First Class\n\n함수형 프로그래밍을 공부하거나 한번쯤 사용해봤다면 `일급객체` `일급함수` 라는 단어를 봤을 것이다. 아니라면 지금부터 알면된다.\n일급시민(First-class citizen)이 될 수 있는 객체를 일급객체(First-class object), 함수를 일급함수(First-class funcation)으로 지칭할 수 있다.\n일급시민이란 아래 요소를 모두 만족하는 대상을 뜻한다. 아래에는 함수를 예제로 작성한다.\n\n1. 변수에 할당할 수 있다.\n2. 객체의 인자로 넘길 수 있다.\n3. 객체의 반환값으로 반환할 수 있다.\n\n`Kotlin`\n```kotlin\nfun main() {\n    // 1. 변수에 할당할 수 있다.\n    val sum = { x: Int, y: Int -> x + y }\n    println(sum(1, 2))\n\n    val sum2 = sumFun1(sum)\n    println(sum2)\n\n    val sum3 = sumFun2(sum2)\n    println(sum3.invoke())\n}\n\n// 2. 객체의 인자로 넘길 수 있다.\nfun sumFun1(firstClass: (x: Int, y: Int) -> Int): Int {\n    return firstClass.invoke(3, 4)\n}\n\n// 3. 객체의 반환값으로 반환할 수 있다.\nfun sumFun2(sum: Int): () -> Int {\n    return { sum + 5 }\n}\n```\n\n그렇다면 java는 어떨까? kotlin에서는 기본적으로 지원하는 lambda가 java에서는 java8부터 지원하며, 이를 이용하면 비슷한 느낌으로는 만들 수 있다.\n\n`Java`\n```java\n@FunctionalInterface\ninterface Lambda {\n    int sum(int a, int b);\n}\n\n@FunctionalInterface\ninterface Lambda2 {\n    int justReturn();\n}\n\npublic class FirstClassJava {\n    public static void main(String[] args) {\n\n        Lambda sum1 = (int a, int b) -> a + b;\n        System.out.println(sum1.sum(1, 2));\n\n        int sum2 = sumFun1(sum1);\n        System.out.println(sum2);\n\n        Lambda2 sum3 = sumFun2(sum2);\n        System.out.println(sum3.justReturn());\n    }\n\n    public static int sumFun1(Lambda lambdaSum) {\n        return lambdaSum.sum(3, 4);\n    }\n\n    public static Lambda2 sumFun2(int sum) {\n        Lambda2 justReturn = () -> sum + 5;\n        return justReturn;\n    }\n}\n```\n\n```\n3\n7\n12\n```\n\n두 언어 모두 같은 결과를 얻을 수 있다. 하지만 java의 경우 일급시민의 조건을 만족하지 않는다. 하나하나 짚어보자면, `sum1`은 마치 변수에 함수를 할당한 것 처럼 보이지만 이는 java에서 lambda를 할당하기 위해서 interface를 만들도록 강제화 되어있다. `sumFun1`의 파라미터로 `Lambda` 객체를 넘겨야하며, 함수(lambda)를 넘길 순 없다. `sumFun2`의 반환형으로 함수(lambda)를 반환할 수 없으며 `Lambda2`를 반환 해야한다. 즉, java에서 lambda를 이용하여 kotlin과 구조적으로 비슷한 형태로 개발할 수 있지만 java는 일급시민(함수, 객체)이 될 수 없는 언어라는 점이다.\n\n금융회사 재직당시 특정 프로젝트에서 java 1.6을 사용하는 곳을 보았지만, 이런 경우는 어쩔 수 없이 사용할 수 없을것이다. 하지만 java8 이상을 사용하면서도 lambda, stream 등의 함수형 프로그래밍 지식을 습득하지 못하여 거부감을 느껴하는 케이스도 보았다. kotlin에서는 언어 레벨에서 간결하고 쉽게 사용할 수 있도록 지원되어 가장 큰 장점이라 생각되었다.\n\n### Immutable\n\n언어 레벨에서 지원하는 불변성의 효과는 실로 기가막히다.\n\n`Java`\n```java\nclass Person {\n    private String name;\n    private int age;\n\n    public Person(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getName() {\n        return name;\n    }\n}\n\npublic class FirstClassJava {\n    public static void main(String[] args) {\n        Person person = new Person(\"wookey\", 30);\n        System.out.println(changeName1(person).getName());\n    }\n\n    public static Person changeName1(Person person) {\n        person.setName(person.getName() + \"변경1\");\n        return changeName2(person);\n    }\n\n    public static Person changeName2(Person person) {\n        person.setName(person.getName() + \"변경2\");\n        return changeName3(person);\n    }\n\n    public static Person changeName3(Person person) {\n        person.setName(person.getName() + \"변경3\");\n        return person;\n    }\n}\n```\n\n실무에서 이렇게 극단적인 코드는 없을것 같다고 생각될 것이다. 하지만 실제로 실무 코드에도 수개의 메소드의 파라미터에 레퍼런스를 받고 이를 변경하고 최종적으로 결과를 받는 형태의 코드는 상당히 많다. 그것도 예제 코드처럼 단순한 변경이 아닌, 수많은 비즈니스 로직과 얽히고 엮여 레퍼런스의 값을 계속 변경, 조작하는 코드들 말이다.\n\n`Kotlin`\n```kotlin\ndata class Person(val name: String, val age: Int)\n\nfun main() {\n    val person = Person(\"wookey\", 30)\n    println(changeName1(person).name)\n}\n\nfun changeName1(person: Person): Person {\n    person.name = person.name + \"변경1\"\n    return changeName2(person)\n}\n\nfun changeName2(person: Person): Person {\n    person.name = person.name + \"변경2\"\n    return changeName3(person)\n}\n\nfun changeName3(person: Person): Person {\n    person.name = person.name + \"변경3\"\n    return person\n}\n```\n\n예제 java코드를 kotlin으로 옮기면 위와 같다. 정확히 말하자면 느낌만 옮긴것이다. 위 kotlin 코드는 컴파일되지 않는다. 언어레벨에서 main문에 선언한 `Person` 객체에 선언한 `name` 필드를 `val` 이라는 키워드로 변경불가능한 immutable(final) 변수로 만들었기 때문이다. 어찌보면 `name` 필드의 키워드를 `val`에서 `var`로 변경만 하면 컴파일될 뿐 아니라 java 코드와 동일한 결과를 가져 올 수 있다. 하지만 여기서 얻을 수 있는 인사이트가 있다. 왜 kotlin은 기본적으로 언어 레벨에서 final 키워드를 채택한 것일까? 만약 kotlin 코드에서 `var` 키워드로 바꾸지않고 동일한 결과를 가져 오려면 각 메소드마다 아래와 같이 작성해야할 것이다.\n\n```kotlin\nfun changeName1(person: Person): Person {\n    val newPerson = Person(person.name + \"변경1\", person.age)\n    return newPerson\n}\n```\n\n이는 사실상 결과만 같지 다른 코드이다. 레퍼런스의 값을 바꾸는게 아닌, 새로운 객체를 계속 만들어내는 방법이기 때문이다. 결과적으로 레퍼런스를 조작하는 코드는 결코 좋지못한 코드를 양산해낼 가능성이 높다. 즉, kotlin은 레퍼런스의 변경을 최대한 막고 하나의 메소드는 자신의 역할만 충실히 하도록 개발할 수 있도록 언어레벨에서 지원하는 것이다. 이는 결국 OOP원칙 중 SRP(Single Responsibility Principle)에 굉장히 충실할 수 있다고 생각한다. 결과론적으로 immutable의 지원은 유지보수 좋은 코드, 생산성 있는 코드를 만들 수 있다고 생각한다.\n\n\n## Kotlin은 단점이 없는가?\n\n결론부터 말하면 아니다. 모든 언어에는 특징이 있으며, 자신의 입맛도 중요하지만 시장의 수요도 중요하다. 기술적으로만 보았을때 kotlin은 java 기반으로 만들어졌고 동일하게 JVM 아래에서 돌아간다. java의 불편한 단점들을 보완하기 위해 태어난 언어이므로 기술적인 부분보다는 그 외적 이유로 단점을 꼽아 볼 수 있다.\n\n* 새로운 언어이므로 개발자 커뮤니티가 작을 수 있다. \n* 대한민국은 java 공화국이라는 별명이 있을정도로 java에 대한 애착심이 높다. 그렇다면 취업의 입장에서 수요 차이는 분명할 수 있다.\n* kotlin은 java와 100% 호환되는 언어라고 제작사에서 언급한다. `SomeClass::class.java` 와 같은 리플렉션 문법은 `KClass` 라는 kotlin 클래스로 랩핑된다. 이와 같은 사용은 모호한 java 문법과의 호환이 있어 보인다.\n* 시간이 해결해줄 것 같지만, 아직까지 완벽 지원되지 않는 라이브러리나 개발툴(IDE)가 있다. 특히 kotlin은 intellij IDE 개발사인 jetbranin에서 만든 언어이므로 다양한 IDE가 나오기 전까진 특정 IDE에 특화된 언어라는 제약이 있다.\n* 함수형 언어라는 패러다임 자체를 긍정적으로 이해하지 못하는 집단들에게 선택받지 못할 수 있다.\n* 개발 공부 자체를 처음 배우는 입문자에게 추천하기 어려울 것 같다. 아무래도 kotlin의 기본 base는 JVM java이며, 특징을 모른채 개발하게 된다면 기본적이고 중요한 지식을 많이 놓칠 수 있다고 생각된다.\n\n\n## 결론\n기존 java의 사용자라면 충분히 메리트를 느끼고 kotlin에게 매력을 느낄 수 있을 것이다. 나도 학부생 시절 포함하여 개발자 커리어 전부를 java로 개발했다. 하지만 익숙하면서도 많은 변화를 가져다준 kotlin의 릴리즈를 지켜보며 과감하게 주 언어를 변경할 수 있었다. 포스트에 언급하지 않은 kotlin의 장점과 단점은 더 많이 있겠지만 kotlin을 주 개발 언어로 선택한 이유를 요약하면 아래와 같이 정리 할 수 있을것 같다.\n\n* Concise (간결성)\n* Safe (안정성)\n* Interoperable (상호운용가능성)\n\n결국 아래와 같은 타겟에게 kotlin을 추천한다.\n> java 실무 경험이 있으며, 간결하고 명료한 jvm 기반의 코드를 원하는 개발자\n\n\n##\n***\n###\n* <https://www.makeuseof.com/kotlin-vs-java/#code-volume-amp-speed-of-coding>\n* <https://kotlinlang.org/docs/comparison-to-java.html#what-kotlin-has-that-java-does-not>"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}