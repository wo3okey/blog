{"componentChunkName":"component---src-pages-index-jsx","path":"/","result":{"data":{"site":{"siteMetadata":{"title":"wookey-devlog"}},"allMarkdownRemark":{"group":[{"fieldValue":"aws","totalCount":1},{"fieldValue":"consistent hashing","totalCount":1},{"fieldValue":"cs","totalCount":1},{"fieldValue":"elasticsearch","totalCount":2},{"fieldValue":"hash slot","totalCount":1},{"fieldValue":"http","totalCount":1},{"fieldValue":"inline","totalCount":1},{"fieldValue":"java","totalCount":2},{"fieldValue":"kafka","totalCount":1},{"fieldValue":"kinesis","totalCount":1},{"fieldValue":"kotlin","totalCount":3},{"fieldValue":"lucene","totalCount":1},{"fieldValue":"redis","totalCount":1},{"fieldValue":"redis cluster","totalCount":1},{"fieldValue":"replica","totalCount":1},{"fieldValue":"servelt","totalCount":1},{"fieldValue":"shard","totalCount":2},{"fieldValue":"spring","totalCount":2},{"fieldValue":"traffic","totalCount":1},{"fieldValue":"transactional","totalCount":1}],"nodes":[{"excerpt":"대용량 트래픽 처리 은 말 그대로 단위 시간의 수 많은 요청을 뜻한다. 구글이나 페이스북과 같은 기업들은 초당 수십억 건 이상의 요청이 올 수 있으며, 일반 국내 기업에서도 초당 수천에서 수만 이상의 요청이 올 수 있다. 어느정도 트래픽이 대용량일지 정의한 수치는 따로 없다. 그냥 내 개인적인 생각이라면, 인프라 또는 데브옵스 조직이 있는 회사라면 어느정…","fields":{"slug":"/high-traffic/"},"frontmatter":{"date":"August 19, 2023","update":"Aug 19, 2023","title":"말도 많고 탈도 많은 대용량 트래픽는 대체 어떻게 처리할까?","description":" 대용량 트래픽 처리는 서버 개발자들의 면접 단골 질문이자, 서버 개발자들이라면 한번쯤 고민해보는 그 주제이다. 사실 주어진 환경과 시스템에 따라 처리할 수 있는 방향과 방법이 무궁무진하다. 때로는 매우 쉬운 조치만으로도 가능해질 수 있다면, 때로는 시스템 아키텍처 전체를 뒤엎어야 하는 대공사를 해야할 수 있다. 일반적으로 고려하면 좋을 방법들을 알아보자. ","tags":["cs","traffic"],"series":"cs"}},{"excerpt":"servelt 클라이언트의 HTTP request에 대해 response 처리를 담당하는 java 프로그램이다. 정적인 웹 서버에서 동적인 페이지를 제공할 수 있도록 도와주는 어플리케이션이라 보면 된다. 서블릿은 절대 spring을 위해 만들어진 개념이 아니다. 웹 애플리케이션 개발 시 불필요한 request, reponse 로직을 추상화하고 개발자들이 …","fields":{"slug":"/servelt/"},"frontmatter":{"date":"July 05, 2023","update":"Jul 05, 2023","title":"spring servelt은 무엇인가?","description":" spring boot로 개발을 시작하거나 또는 오래 하다보면 `servlet`의 개념을 놓치기 쉽다. 간단하게 정리해보자. ","tags":["spring","servelt"],"series":"spring"}},{"excerpt":"TPC/UDP 먼저 HTTP 관련 정보에 단골로 등장하는 내용인 TPC/UDP를 아주 얕게 설명한다. TPC/UDP의 동작 방식이나 차이점 등은 교수님 강의에서도 필수로 등장한다. 간단하게 그림으로 살펴보자.  TCP 통신에는 라고 부르는 과정이 데이터 통신에 선행된다. 이는 서버와 클라이언트 간에 와 패킷을 통해 서로의 연결에 대한 신뢰성을 확보하는 과…","fields":{"slug":"/http-protocol/"},"frontmatter":{"date":"June 18, 2023","update":"Jun 18, 2023","title":"HTTP 프로토콜 진화 과정","description":" HTTP 프로토콜은 TCP기반의 HTTP 0.9, 1.1, 2.0 그리고 UDP기반의 QUIC까지 계속 진화하고 있다. 각 버전마다 발생되는 단점을 다음 버전에서 극복하며, 지속적으로 HTTP 통신 속도를 높여가고 있다. HTTP의 발자취를 함께 따라가보자. ","tags":["http"],"series":"cs"}},{"excerpt":"kinesis 란 는 대규모의 실시간 데이터 스트리밍 처리를 지원하는 pub/sub 모델을 구현한 AWS 관리형 서비스이다. data strems kinesis data streams의 아키텍처 구조이다. 용어를 정리하면서 간단히 알아보자.  구성 설명 producer - data stream에 데이터를 보내는 주체의 서버 또는 애플리케이션 consume…","fields":{"slug":"/AWS-kinesis/"},"frontmatter":{"date":"May 29, 2023","update":"May 29, 2023","title":"AWS kinesis basic","description":" AWS에서는 실시간 데이터 스트리밍을 처리할 수 있는 kinesis를 서비스한다. kafka와 마찬가지로 로그 수집 파이프라인, 이벤트 메세지 큐, 스트리밍 서비스 등에 사용되고 있다. 간략하게 알아보자. ","tags":["aws","kinesis"],"series":"aws"}},{"excerpt":"lucene lucene은 elasticsearch의 핵심이 되는 검색엔진 그 자체이며, java로 만들어진 고성능 정보검색 오픈소스 라이브러리이다. 결국 elasticsearch는 검색 및 색인 기능은 직접 구현한게 아닌 lucene을 사용한 것이다. 그 외 REST api, 분산처리, 고가용성을 위한 shard/replica 등의 시스템을 추가하여 지…","fields":{"slug":"/elasticsearch-change-shard/"},"frontmatter":{"date":"May 13, 2023","update":"May 13, 2023","title":"elasticsearch shard 값은 왜 변경이 불가할까?","description":"결론부터 얘기하면 기생성된 index의 shard 값을 변경하지 못하는 이유는 lucene(루씬) 때문이다. lucene과 이를 구성하고 있는 segment shard와 함께 얘기한다. ","tags":["elasticsearch","shard","lucene"],"series":"elasticsearch"}},{"excerpt":"kafka 란 는 LinkedIn 에서 개발한 대용량 처리를 위한 분산형 스트리밍 플랫폼이다.  특징 높은 처리량과 낮은 지연시간 batch 처리 시스템을 통해 대량의 데이터를 높은 처리량으로 처리할 수 있도록 설계됨 메세지의 지연 시간이 매우 낮아 실시간 데이터 처리에 적합함 타 시스템과 비교하여 kafka의 producer, consumer 모두 압도…","fields":{"slug":"/kafka-basic/"},"frontmatter":{"date":"April 02, 2023","update":"Apr 02, 2023","title":"kafka basic","description":"kafka는 대량의 데이터를 높은 처리량으로 실시간으로 처리할 수 있도록 설계되어 있으며, 분산 시스템의 높은 가용성과 유연성을 활용하여 안정적이고 데이터 손실 없이 데이터를 전송할 수 있다. 이는 다양한 서비스에서 활용되며, 웹 사이트의 대규모 로그 데이터 수집, 이벤트 처리, 메세지 큐, 스트리밍 등의 용도로 여러 기업 및 서비스에서 사용하고 있다. kafka가 다양하게 사용되는 이유는 여러가지 특징적인 이유를 알아본다. ","tags":["kafka"],"series":"kafka"}},{"excerpt":"@Transactional은 spring에서 각 transaction를 묶어주고 관리해주는 역할을 하는 선언적 방법이다. @Transactional는 여러가지 속성과 옵션을 제공하며, 예시 코드들과 함께 알아본다.  transaction transaction은 DB의 상태 변경을 뜻한다. 코드도 git에 commit 하듯 DB도 변경점에 대한 savepo…","fields":{"slug":"/spring-transactional/"},"frontmatter":{"date":"March 11, 2023","update":"Mar 11, 2023","title":"spring @Transactional 조금더 알아보기","description":"@Transactional은 spring에서 각 transaction를 묶어주고 관리해주는 역할을 하는 선언적 방법이다. @Transactional는 여러가지 속성과 옵션을 제공하며, 예시 코드들과 함께 알아본다.  ","tags":["spring","transactional"],"series":"spring"}},{"excerpt":"redis cluster redis cluster은 redis 3.0 버전 이상부터 추가되었으며 데이터 동기화, 복제, failover 등을 지원할 수 있는 기능이 추가된 향상된 redis라고 생각하면 된다. 특히 failover 관점에서 node의 장애 또는 통신 문제 등 master-slave 및 replica 기능을 통해 수준높은 가용성을 제공할 수…","fields":{"slug":"/redis-consistent-hashing/"},"frontmatter":{"date":"January 30, 2023","update":"Jan 30, 2023","title":"redis cluster의 동작과 hash slot","description":"hash slot은 redis cluster의 node간에 key 분산 방법이다. nosql의 key 분산 방법의 기초가 되는 consistent hashing도 함께 알아본다. ","tags":["redis","redis cluster","hash slot","consistent hashing"],"series":"redis"}},{"excerpt":"shard \nshard는 mysql과 같은 RDB를 기준으로 partition과 같은 의미로, 데이터를 저장할 때 나누어진 조각 단위라고 생각하면 된다. 즉 shard의 데이터는 복사본이 아닌 저장한 데이터 그 자체이다. elasticsearch에서는 충분히 크기가 큰 데이터를 가진 index의 데이터를 특정한 파티션 단위로 나누며, 이를 shard라고 …","fields":{"slug":"/elasticsearch-shard-replica/"},"frontmatter":{"date":"January 29, 2023","update":"Jan 29, 2023","title":"elasticsearch shard, replica 값은 어떻게 설정할까?","description":" elasticsearch를 운영하기 위해서는 shard와 replica 갯수를 적절히 설정해야한다. 또한 index에 설정된 shard 수는 한번 설정하면 변경이 불가하기 때문에 운영중에 index를 변경하는 번거로움을 덜기 위해서는 적절하게 갯수를 선정하는 것이 중요하다. 그렇다고 한번 설정한 shard는 정답이 아니다. 시스템이 커지고 변경됨에 따라 언제든 변경의 여지를 두고 지켜봐야할 대상이다. 그래서 shard와 replia의 값 설정 기준에 대한 이야기를 한다. ","tags":["elasticsearch","shard","replica"],"series":"elasticsearch"}},{"excerpt":"Data class java의 lombok도 편하지만 kotlin data class는 기본적인 메소드들을 만들기 진짜 세상 편하다. 하지만 상속을 할때에는 꼭 유의해야하는 사항이 있다. 차근차근 알아보자. hash code 먼저 data class를 선언 했을때 컴파일러가 만들어주는 hash code 메소드를 살펴보자. 간단한  객체를 만들었다. 그리고…","fields":{"slug":"/kotlin-data-class/"},"frontmatter":{"date":"January 28, 2023","update":"Jan 28, 2023","title":"kotlin data class 상속","description":" java의 lombok을 사용할 필요 없도록 잘 설계된 kotlin의 data class의 활용성은 한번 사용해본 개발자라면 공감할 것이다. data class를 상속의 관점에서 알아본다. ","tags":["kotlin"],"series":"kotlin"}},{"excerpt":"inline kotlin 함수에 붙는  키워드는 말 그대로 호출되는 특정 코드 line 사이에 특정 inline 키워드가 붙은 함수의 코드를 넣을(in) 수 있도록 지원하는 키워드이다.\n 키워드는 객체(클래스)와 함수 레벨에서 사용할 수 있다. 예시는 객체 레벨이 아닌 함수 레벨에서 설명한다. inline 함수 간단하게 아래 코드로 살펴보자. 아주 inl…","fields":{"slug":"/kotlin-inline/"},"frontmatter":{"date":"January 23, 2023","update":"Jan 23, 2023","title":"kotlin inline 알아보기","description":"inline 키워드는 kotlin에서 만들어진 함수 아래 단위에서 사용할 수 있는 키워드 문법이다. 장단점을 비교하고 목적성에 대해 정리한다. ","tags":["kotlin","java","inline"],"series":"kotlin"}},{"excerpt":"Kotlin의 매력 포인트 Null Safe 필요성에 대해서는 두말하면 잔소리다. null에 대한 지원만으로도 너무 행복하다.  java는 null에 취약하며, 언제 어느순간에 NullPointerException이 발생할지 예측할 수 없다. 그래서 늘 null과의 싸움을 하게된다. 떄로는 비즈니스 로직보다 null 체크 로직이 더 많을때도 있다. 물론 …","fields":{"slug":"/kotlin-vs-java/"},"frontmatter":{"date":"January 16, 2023","update":"Jan 16, 2023","title":"java로 되돌아갈 수 없는 kotlin의 매력","description":"kotlin으로 프로젝트를 진행한지 어느덧 1년 정도가 되었다. 하지만 한번도 java와 비교하여 kotlin의 장점을 깊이 생각해본 적은 없는 것 같다. java와 비교하여 현재 back-end main language로 kotlin을 선택한 이유를 얘기 해본다. 참고로 언어의 기본적인 문법은 다루지 않는다. ","tags":["kotlin","java"],"series":"kotlin"}}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}